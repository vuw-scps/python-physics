{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to MkDocs For full documentation visit mkdocs.org . Commands mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit. Project layout mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files. Bx = sintheta cosphi Br + costheta np.cos(phi) Bt - sinphi Bp By = sintheta sinphi Br + costheta sinphi Bt + cosphi Bp Bz = costheta Br - sintheta Bt","title":"Welcome to MkDocs"},{"location":"#welcome-to-mkdocs","text":"For full documentation visit mkdocs.org .","title":"Welcome to MkDocs"},{"location":"#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit.","title":"Commands"},{"location":"#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files. Bx = sintheta cosphi Br + costheta np.cos(phi) Bt - sinphi Bp By = sintheta sinphi Br + costheta sinphi Bt + cosphi Bp Bz = costheta Br - sintheta Bt","title":"Project layout"},{"location":"differential-equations/first-order/","text":"First Order Equations import numpy as np import matplotlib.pyplot as plt Definitions A differential equation is an equation involving an unknown function y(t) y(t) (with independent variable t t ) and its derivatives y' y' , y'' y'' , y''' y''' , etc. The order of a differential equation refers to the highest order derivative of the unknown function y(t) y(t) appearing in the equation. A differential equation is linear if it is of the form a_n(t) y^{(n)} + a_{n_1}(t) y^{(n-1)} + \\cdots + a_1(t) y' + a_0(t) y_0 = f(t) a_n(t) y^{(n)} + a_{n_1}(t) y^{(n-1)} + \\cdots + a_1(t) y' + a_0(t) y_0 = f(t) where a_n, \\dots, a_0, f a_n, \\dots, a_0, f are functions of the independent variable t t only. For example, the equation y'' + ty' + y^2 = t y'' + ty' + y^2 = t is second order non-linear, and the equation y' + ty = t^2 y' + ty = t^2 is first order linear. Most differential equations are impossible to solve explicitly however we can always use numerical methods to approximate solutions. Euler's Method The simplest numerical method for approximating solutions of differential equations is Euler's method . Consider a first order differential equation with an initial condition: y' = f(y,y) \\ , \\ \\ y(t_0)=y_0 y' = f(y,y) \\ , \\ \\ y(t_0)=y_0 The procedure for Euler's method is as follows: Contruct the equation of the tangent line to the unknown function y(t) y(t) at t=t_0 t=t_0 : y = y(t_0) + f(y_0,t_0)(t - t_0) y = y(t_0) + f(y_0,t_0)(t - t_0) where y'(t_0) = f(y_0,t_0) y'(t_0) = f(y_0,t_0) is the slope of y(t) y(t) at t=t_0 t=t_0 . Use the tangent line to approximate y(t) y(t) at a small time step t_1 = t_0 + h t_1 = t_0 + h : $$ y_1 = y_0 + f(y_0,t_0)(t_1 - t_0) $$ where y_1 \\approx y(t_1) y_1 \\approx y(t_1) . Construct the tangent line at the point (t_1,y_1) (t_1,y_1) and repeat. The formula for Euler's method defines a recursive sequence: y_{n+1} = y_n + f(y_n,t_n)(t_{n+1} - t_n) \\ , \\ \\ y_0 = y(t_0) y_{n+1} = y_n + f(y_n,t_n)(t_{n+1} - t_n) \\ , \\ \\ y_0 = y(t_0) where y_n \\approx y(t_n) y_n \\approx y(t_n) for each n n . If we choose equally spaced t t values then the formula becomes y_{n+1} = y_n + f(y_n,t_n)h \\ \\ , \\ \\ y_0 = y(t_0) \\ , \\ \\ t_n = t_0 + nh y_{n+1} = y_n + f(y_n,t_n)h \\ \\ , \\ \\ y_0 = y(t_0) \\ , \\ \\ t_n = t_0 + nh with time step h = t_{n+1} - t_n h = t_{n+1} - t_n . Note two very important things about Euler's method and numerical methods in general: A smaller time step h h reduces the error in the approximation. A smaller time step h h requires more computations! Implementation Let's write a function called odeEuler which takes 3 input parameters f , y0 and t where: f is a function of 2 variables which represents the right side of a first order differential equation y' = f(y,t) t is a 1D NumPy array of t t values where we are approximating y y values y0 is an intial value y(t_0)=y_0 y(t_0)=y_0 where t_0 t_0 is the entry at index 0 of the array t The function odeEuler returns a 1D NumPy array of y y values which approximate the solution y(t) y(t) of the differential equation y' = f(y,t) \\ , \\ \\ y(t_0)=y_0 y' = f(y,t) \\ , \\ \\ y(t_0)=y_0 by Euler's method. Notice that we don't specify a time step value h h . Instead, the function odeEuler takes an array of t t values and returns y y values approximating the solution y(t) y(t) by the formula y_{n+1} = y_n + f(y_n,t_n)(t_{n+1} - t_n) y_{n+1} = y_n + f(y_n,t_n)(t_{n+1} - t_n) def odeEuler(f,y0,t): '''Approximate the solution of y'=f(y,t) by Euler's method. Parameters ---------- f : function Right-hand side of the differential equation y'=f(t,y), y(t_0)=y_0 y0 : number Initial value y(t0)=y0 wher t0 is the entry at index 0 in the array t t : array 1D NumPy array of t values where we approximate y values. Time step at each iteration is given by t[n+1] - t[n]. Returns ------- y : 1D NumPy array Approximation y[n] of the solution y(t_n) computed by Euler's method. ''' y = np.zeros(len(t)) y[0] = y0 for n in range(0,len(t)-1): y[n+1] = y[n] + f(y[n],t[n])*(t[n+1] - t[n]) return y Examples Exponential Equation Let's implement Euler's method to approximate solutions of y' = y y' = y for t \\in [0,2] t \\in [0,2] . We know the solution is y(t) = e^t y(t) = e^t in this case and so we can compare the approximation by Euler's method to the true solution. t = np.linspace(0,2,21) y0 = 1 f = lambda y,t: y y = odeEuler(f,y0,t) y_true = np.exp(t) plt.plot(t,y,'b.-',t,y_true,'r-') plt.legend(['Euler','True']) plt.axis([0,2,0,9]) plt.grid(True) plt.title(\"Solution of $y'=y , y(0)=1$\") plt.show() Non-Linear Equation Let's plot an approximation of y'=y^2 y'=y^2 for y(0)=-1 y(0)=-1 . We know the solution is y(t) = \\frac{-1}{t+1} y(t) = \\frac{-1}{t+1} t = np.linspace(0,5,16) y0 = -1 f = lambda y,t: y**2 y = odeEuler(f,y0,t) t_true = np.linspace(0,5,100) y_true = -1/(t_true + 1) plt.plot(t,y,'r.-',t_true,y_true) plt.legend(['Euler','True']) plt.grid(True) plt.axis([0,5,-1,0]) plt.title(\"Solution of $y'=y^2 , y(0)=1$\") plt.show() Autonomous Equation Let's do an example where we know that it would be impossible to find the true solution. Let's approximate the solution of y' = \\sin(y^2) y' = \\sin(y^2) for each initial condition y(0)=-3,-2.75,-2.5,...,2.5,2.75 y(0)=-3,-2.75,-2.5,...,2.5,2.75 and plot all the results together. Note that y'=0 y'=0 when y=\\pm \\sqrt{k \\pi} y=\\pm \\sqrt{k \\pi} for k=0,1,2,3,4,... k=0,1,2,3,4,... . These points are called equilibrium points of the equation and represent steady state (or constant) solutions. t0 = 0; tf = 3; h = 0.1; f = lambda y,t: np.sin(y**2) t = np.arange(t0,tf+h,h) for y0 in np.arange(-3,3,0.25): y = odeEuler(f,y0,t) plt.plot(t,y,'b') for k in range(0,3): y_eq = np.sqrt(k*np.pi) plt.plot([t0,tf],[y_eq,y_eq],'r--') plt.plot([t0,tf],[-y_eq,-y_eq],'r--') plt.grid(True) plt.axis([0,3,-3,3.5]) plt.title(\"Equilibrium solutions of $y'=\\sin(y^2)$\") plt.show() Slope Fields Under construction Exercises Under construction","title":"First Order Equations"},{"location":"differential-equations/first-order/#first-order-equations","text":"import numpy as np import matplotlib.pyplot as plt","title":"First Order Equations"},{"location":"differential-equations/first-order/#definitions","text":"A differential equation is an equation involving an unknown function y(t) y(t) (with independent variable t t ) and its derivatives y' y' , y'' y'' , y''' y''' , etc. The order of a differential equation refers to the highest order derivative of the unknown function y(t) y(t) appearing in the equation. A differential equation is linear if it is of the form a_n(t) y^{(n)} + a_{n_1}(t) y^{(n-1)} + \\cdots + a_1(t) y' + a_0(t) y_0 = f(t) a_n(t) y^{(n)} + a_{n_1}(t) y^{(n-1)} + \\cdots + a_1(t) y' + a_0(t) y_0 = f(t) where a_n, \\dots, a_0, f a_n, \\dots, a_0, f are functions of the independent variable t t only. For example, the equation y'' + ty' + y^2 = t y'' + ty' + y^2 = t is second order non-linear, and the equation y' + ty = t^2 y' + ty = t^2 is first order linear. Most differential equations are impossible to solve explicitly however we can always use numerical methods to approximate solutions.","title":"Definitions"},{"location":"differential-equations/first-order/#eulers-method","text":"The simplest numerical method for approximating solutions of differential equations is Euler's method . Consider a first order differential equation with an initial condition: y' = f(y,y) \\ , \\ \\ y(t_0)=y_0 y' = f(y,y) \\ , \\ \\ y(t_0)=y_0 The procedure for Euler's method is as follows: Contruct the equation of the tangent line to the unknown function y(t) y(t) at t=t_0 t=t_0 : y = y(t_0) + f(y_0,t_0)(t - t_0) y = y(t_0) + f(y_0,t_0)(t - t_0) where y'(t_0) = f(y_0,t_0) y'(t_0) = f(y_0,t_0) is the slope of y(t) y(t) at t=t_0 t=t_0 . Use the tangent line to approximate y(t) y(t) at a small time step t_1 = t_0 + h t_1 = t_0 + h : $$ y_1 = y_0 + f(y_0,t_0)(t_1 - t_0) $$ where y_1 \\approx y(t_1) y_1 \\approx y(t_1) . Construct the tangent line at the point (t_1,y_1) (t_1,y_1) and repeat. The formula for Euler's method defines a recursive sequence: y_{n+1} = y_n + f(y_n,t_n)(t_{n+1} - t_n) \\ , \\ \\ y_0 = y(t_0) y_{n+1} = y_n + f(y_n,t_n)(t_{n+1} - t_n) \\ , \\ \\ y_0 = y(t_0) where y_n \\approx y(t_n) y_n \\approx y(t_n) for each n n . If we choose equally spaced t t values then the formula becomes y_{n+1} = y_n + f(y_n,t_n)h \\ \\ , \\ \\ y_0 = y(t_0) \\ , \\ \\ t_n = t_0 + nh y_{n+1} = y_n + f(y_n,t_n)h \\ \\ , \\ \\ y_0 = y(t_0) \\ , \\ \\ t_n = t_0 + nh with time step h = t_{n+1} - t_n h = t_{n+1} - t_n . Note two very important things about Euler's method and numerical methods in general: A smaller time step h h reduces the error in the approximation. A smaller time step h h requires more computations!","title":"Euler's Method"},{"location":"differential-equations/first-order/#implementation","text":"Let's write a function called odeEuler which takes 3 input parameters f , y0 and t where: f is a function of 2 variables which represents the right side of a first order differential equation y' = f(y,t) t is a 1D NumPy array of t t values where we are approximating y y values y0 is an intial value y(t_0)=y_0 y(t_0)=y_0 where t_0 t_0 is the entry at index 0 of the array t The function odeEuler returns a 1D NumPy array of y y values which approximate the solution y(t) y(t) of the differential equation y' = f(y,t) \\ , \\ \\ y(t_0)=y_0 y' = f(y,t) \\ , \\ \\ y(t_0)=y_0 by Euler's method. Notice that we don't specify a time step value h h . Instead, the function odeEuler takes an array of t t values and returns y y values approximating the solution y(t) y(t) by the formula y_{n+1} = y_n + f(y_n,t_n)(t_{n+1} - t_n) y_{n+1} = y_n + f(y_n,t_n)(t_{n+1} - t_n) def odeEuler(f,y0,t): '''Approximate the solution of y'=f(y,t) by Euler's method. Parameters ---------- f : function Right-hand side of the differential equation y'=f(t,y), y(t_0)=y_0 y0 : number Initial value y(t0)=y0 wher t0 is the entry at index 0 in the array t t : array 1D NumPy array of t values where we approximate y values. Time step at each iteration is given by t[n+1] - t[n]. Returns ------- y : 1D NumPy array Approximation y[n] of the solution y(t_n) computed by Euler's method. ''' y = np.zeros(len(t)) y[0] = y0 for n in range(0,len(t)-1): y[n+1] = y[n] + f(y[n],t[n])*(t[n+1] - t[n]) return y","title":"Implementation"},{"location":"differential-equations/first-order/#examples","text":"","title":"Examples"},{"location":"differential-equations/first-order/#exponential-equation","text":"Let's implement Euler's method to approximate solutions of y' = y y' = y for t \\in [0,2] t \\in [0,2] . We know the solution is y(t) = e^t y(t) = e^t in this case and so we can compare the approximation by Euler's method to the true solution. t = np.linspace(0,2,21) y0 = 1 f = lambda y,t: y y = odeEuler(f,y0,t) y_true = np.exp(t) plt.plot(t,y,'b.-',t,y_true,'r-') plt.legend(['Euler','True']) plt.axis([0,2,0,9]) plt.grid(True) plt.title(\"Solution of $y'=y , y(0)=1$\") plt.show()","title":"Exponential Equation"},{"location":"differential-equations/first-order/#non-linear-equation","text":"Let's plot an approximation of y'=y^2 y'=y^2 for y(0)=-1 y(0)=-1 . We know the solution is y(t) = \\frac{-1}{t+1} y(t) = \\frac{-1}{t+1} t = np.linspace(0,5,16) y0 = -1 f = lambda y,t: y**2 y = odeEuler(f,y0,t) t_true = np.linspace(0,5,100) y_true = -1/(t_true + 1) plt.plot(t,y,'r.-',t_true,y_true) plt.legend(['Euler','True']) plt.grid(True) plt.axis([0,5,-1,0]) plt.title(\"Solution of $y'=y^2 , y(0)=1$\") plt.show()","title":"Non-Linear Equation"},{"location":"differential-equations/first-order/#autonomous-equation","text":"Let's do an example where we know that it would be impossible to find the true solution. Let's approximate the solution of y' = \\sin(y^2) y' = \\sin(y^2) for each initial condition y(0)=-3,-2.75,-2.5,...,2.5,2.75 y(0)=-3,-2.75,-2.5,...,2.5,2.75 and plot all the results together. Note that y'=0 y'=0 when y=\\pm \\sqrt{k \\pi} y=\\pm \\sqrt{k \\pi} for k=0,1,2,3,4,... k=0,1,2,3,4,... . These points are called equilibrium points of the equation and represent steady state (or constant) solutions. t0 = 0; tf = 3; h = 0.1; f = lambda y,t: np.sin(y**2) t = np.arange(t0,tf+h,h) for y0 in np.arange(-3,3,0.25): y = odeEuler(f,y0,t) plt.plot(t,y,'b') for k in range(0,3): y_eq = np.sqrt(k*np.pi) plt.plot([t0,tf],[y_eq,y_eq],'r--') plt.plot([t0,tf],[-y_eq,-y_eq],'r--') plt.grid(True) plt.axis([0,3,-3,3.5]) plt.title(\"Equilibrium solutions of $y'=\\sin(y^2)$\") plt.show()","title":"Autonomous Equation"},{"location":"differential-equations/first-order/#slope-fields","text":"Under construction","title":"Slope Fields"},{"location":"differential-equations/first-order/#exercises","text":"Under construction","title":"Exercises"},{"location":"differentiation/differentiation/","text":"Numerical Differentiation import numpy as np import matplotlib.pyplot as plt %matplotlib inline Derivative The derivative of a function f(x) f(x) at x=a x=a is the limit f'(a) = \\lim_{h \\to 0} \\frac{f(a+h) - f(a)}{h} f'(a) = \\lim_{h \\to 0} \\frac{f(a+h) - f(a)}{h} Difference Formulas There are 3 main difference formulas for numerically approximating derivatives. The forward difference formula with step size h h is f'(a) \\approx \\frac{f(a + h) - f(a)}{h} f'(a) \\approx \\frac{f(a + h) - f(a)}{h} The backward difference formula with step size h h is f'(a) \\approx \\frac{f(a) - f(a - h)}{h} f'(a) \\approx \\frac{f(a) - f(a - h)}{h} The central difference formula with step size h h is the average of the forward and backwards difference formulas f'(a) \\approx \\frac{1}{2} \\left( \\frac{f(a + h) - f(a)}{h} + \\frac{f(a) - f(a - h)}{h} \\right) = \\frac{f(a + h) - f(a - h)}{2h} f'(a) \\approx \\frac{1}{2} \\left( \\frac{f(a + h) - f(a)}{h} + \\frac{f(a) - f(a - h)}{h} \\right) = \\frac{f(a + h) - f(a - h)}{2h} Implementation Let's write a function called derivative which takes input parameters f , a , method and h (with default values method='central' and h=0.01 ) and returns the corresponding difference formula for f'(a) f'(a) with step size h h . def derivative(f,a,method='central',h=0.01): '''Compute the difference formula for f'(a) with step size h. Parameters ---------- f : function Vectorized function of one variable a : number Compute derivative at x = a method : string Difference formula: 'forward', 'backward' or 'central' h : number Step size in difference formula Returns ------- float Difference formula: central: f(a+h) - f(a-h))/2h forward: f(a+h) - f(a))/h backward: f(a) - f(a-h))/h ''' if method == 'central': return (f(a + h) - f(a - h))/(2*h) elif method == 'forward': return (f(a + h) - f(a))/h elif method == 'backward': return (f(a) - f(a - h))/h else: raise ValueError(\"Method must be 'central', 'forward' or 'backward'.\") Let's test our function on some simple functions. For example, we know \\left. \\frac{d}{dx} \\left( \\cos x \\right) \\, \\right|_{x=0} = -\\sin(0) = 0 \\left. \\frac{d}{dx} \\left( \\cos x \\right) \\, \\right|_{x=0} = -\\sin(0) = 0 and we compute derivative(np.cos,0) 0.0 derivative(np.cos,0,method='forward',h=1e-8) 0.0 We also know \\left. \\frac{d}{dx} \\left( e^x \\right) \\, \\right|_{x=0} = e^0 = 1 \\left. \\frac{d}{dx} \\left( e^x \\right) \\, \\right|_{x=0} = e^0 = 1 and we compute derivative(np.exp,0,h=0.0001) 1.0000000016668897 derivative(np.exp,0,method='backward',h=0.0001) 0.9999500016666385 Notice that our function can take an array of inputs for a a and return the derivatives for each a a value. For example, we can plot the derivative of \\sin(x) \\sin(x) : x = np.linspace(0,5*np.pi,100) dydx = derivative(np.sin,x) dYdx = np.cos(x) plt.figure(figsize=(12,5)) plt.plot(x,dydx,'r.',label='Central Difference') plt.plot(x,dYdx,'b',label='True Value') plt.title('Central Difference Derivative of y = cos(x)') plt.legend(loc='best') plt.show() Let's compute and plot the derivative of a complicated function y=\\left(\\frac{4x^2+2x+1}{x+2e^x}\\right)^x y=\\left(\\frac{4x^2+2x+1}{x+2e^x}\\right)^x x = np.linspace(0,6,100) f = lambda x: ((4*x**2 + 2*x + 1)/(x + 2*np.exp(x)))**x y = f(x) dydx = derivative(f,x) plt.figure(figsize=(12,5)) plt.plot(x,y,label='y=f(x)') plt.plot(x,dydx,label=\"Central Difference y=f'(x)\") plt.legend() plt.grid(True) plt.show() Error Formulas Natural questions arise: how good are the approximations given by the forward, backwards and central difference formulas? We derive the error formulas from Taylor's Theorem . Theorem. The degree n n Taylor polynomial of f(x) f(x) at x=a x=a with remainder term is f(x) = f(a) + f'(a)(x - a) + \\frac{f''(a)}{2}(x-a)^2 + \\cdots + \\frac{f^{(n)}(a)}{n!}(x-a)^n + \\frac{f^{(n+1)}(c)}{(n+1)!}(x-a)^{n+1} f(x) = f(a) + f'(a)(x - a) + \\frac{f''(a)}{2}(x-a)^2 + \\cdots + \\frac{f^{(n)}(a)}{n!}(x-a)^n + \\frac{f^{(n+1)}(c)}{(n+1)!}(x-a)^{n+1} for some value c c between x x and a a . Theorem. The forward difference formula error is \\left| \\, \\frac{f(a+h) - f(a)}{h} - f'(a) \\, \\right| \\leq \\frac{hK_2}{2} \\left| \\, \\frac{f(a+h) - f(a)}{h} - f'(a) \\, \\right| \\leq \\frac{hK_2}{2} where \\left| \\, f''(x) \\, \\right| \\leq K_2 \\left| \\, f''(x) \\, \\right| \\leq K_2 for all x \\in [a,a+h] x \\in [a,a+h] . The same error fomula holds for the backward difference formula. Proof . Look at the degree 1 Taylor formula: f(x) = f(a) + f'(a)(x-a) + \\frac{f''(c)}{2}(x-a)^{2} f(x) = f(a) + f'(a)(x-a) + \\frac{f''(c)}{2}(x-a)^{2} Let x = a+h x = a+h and manipulate the formula \\begin{align} f(a+h) &= f(a) + f'(a)h + \\frac{f''(c)}{2}h^{2} \\\\\\ f(a+h) - f(a) &= f'(a)h + \\frac{f''(c)}{2}h^{2} \\\\\\ \\frac{f(a+h) - f(a)}{h} &= f'(a) + \\frac{f''(c)}{2}h \\\\\\ \\frac{f(a+h) - f(a)}{h} - f'(a) &= \\frac{f''(c)}{2}h \\end{align} \\begin{align} f(a+h) &= f(a) + f'(a)h + \\frac{f''(c)}{2}h^{2} \\\\\\ f(a+h) - f(a) &= f'(a)h + \\frac{f''(c)}{2}h^{2} \\\\\\ \\frac{f(a+h) - f(a)}{h} &= f'(a) + \\frac{f''(c)}{2}h \\\\\\ \\frac{f(a+h) - f(a)}{h} - f'(a) &= \\frac{f''(c)}{2}h \\end{align} Let K_2 K_2 such that \\left| \\, f''(x) \\, \\right| \\leq K_2 \\left| \\, f''(x) \\, \\right| \\leq K_2 for all x \\in [a,a+h] x \\in [a,a+h] and we see the result. Theorem. The central difference formula error is: \\left| \\frac{f(a+h) - f(a-h)}{2h} - f'(a) \\right| \\leq \\frac{h^2K_3}{6} \\left| \\frac{f(a+h) - f(a-h)}{2h} - f'(a) \\right| \\leq \\frac{h^2K_3}{6} where |f'''(x)| \\leq K_3 |f'''(x)| \\leq K_3 for all x \\in [a-h,a+h] x \\in [a-h,a+h] . Proof . Look at the Taylor polynomial of degree 2: f(x) = f(a) + f'(a)(x-a) + \\frac{f''(a)}{2}(x-a)^2 + \\frac{f'''(c)}{6}(x-a)^{3} f(x) = f(a) + f'(a)(x-a) + \\frac{f''(a)}{2}(x-a)^2 + \\frac{f'''(c)}{6}(x-a)^{3} Let x = a + h x = a + h and also x = a - h x = a - h and write: \\begin{align} f(a+h) &= f(a) + f'(a)h + \\frac{f''(a)}{2}h^2 + \\frac{f'''(c_1)}{6}h^{3} \\\\\\ f(a-h) &= f(a) - f'(a)h + \\frac{f''(a)}{2}h^2 - \\frac{f'''(c_2)}{6}h^{3} \\\\\\ f(a+h) - f(a-h) &= 2 f'(a)h + \\frac{f'''(c_1)}{6}h^{3} + \\frac{f'''(c_2)}{6}h^{3} \\\\\\ \\frac{f(a+h) - f(a-h)}{2h} - f'(a) &= \\frac{f'''(c_1) + f'''(c_2)}{12}h^{2} \\end{align} \\begin{align} f(a+h) &= f(a) + f'(a)h + \\frac{f''(a)}{2}h^2 + \\frac{f'''(c_1)}{6}h^{3} \\\\\\ f(a-h) &= f(a) - f'(a)h + \\frac{f''(a)}{2}h^2 - \\frac{f'''(c_2)}{6}h^{3} \\\\\\ f(a+h) - f(a-h) &= 2 f'(a)h + \\frac{f'''(c_1)}{6}h^{3} + \\frac{f'''(c_2)}{6}h^{3} \\\\\\ \\frac{f(a+h) - f(a-h)}{2h} - f'(a) &= \\frac{f'''(c_1) + f'''(c_2)}{12}h^{2} \\end{align} Notice that f'''(x) f'''(x) is continuous (by assumption) and (f'''(c_1) + f'''(c_2))/2 (f'''(c_1) + f'''(c_2))/2 is between f'''(c_1) f'''(c_1) and f'''(c_2) f'''(c_2) and so there exists some c c between c_1 c_1 and c_2 c_2 such that f'''(c) = \\frac{f'''(c_1) + f'''(c_2)}{2} f'''(c) = \\frac{f'''(c_1) + f'''(c_2)}{2} by the Intermediate Value Theorem. Let K_3 K_3 such that \\left| \\, f'''(x) \\, \\right| \\leq K_3 \\left| \\, f'''(x) \\, \\right| \\leq K_3 for all x \\in [a-h,a+h] x \\in [a-h,a+h] and we see the result. scipy.misc.derivative The SciPy function scipy.misc.derivative computes derivatives using the central difference formula. from scipy.misc import derivative x = np.arange(0,5) derivative(np.exp,x,dx=0.1) array([ 1.0016675 , 2.72281456, 7.40137735, 20.11902956, 54.68919246]) Higher Order Derivatives Under construction Examples Taylor series Let's plot the Taylor polynomial T_3(x) T_3(x) of degree 3 centered at x=0 x=0 for f(x) = \\frac{3e^x}{x^2 + x + 1} f(x) = \\frac{3e^x}{x^2 + x + 1} over the interval x \\in [-3,3] x \\in [-3,3] . First, let's plot the graph y=f(x) y=f(x) : x = np.linspace(-3,3,100) f = lambda x: 3*np.exp(x) / (x**2 + x + 1) y = f(x) plt.plot(x,y); plt.show() Let's compute the coefficients a_n = \\frac{f^{(n)}(0)}{n!} a_n = \\frac{f^{(n)}(0)}{n!} for n=0,1,2,3 n=0,1,2,3 : a0 = f(0) a1 = derivative(f,0,dx=0.001,n=1) a2 = derivative(f,0,dx=0.001,n=2) / 2 a3 = derivative(f,0,dx=0.001,n=3,order=5) / 6 # The parameter order specifies the number of points to use # The value order must be odd and at least n + 1 print(a0,a1,a2,a3) 3.0 1.9999983891239026e-06 -1.50000037502096 1.9999920608526622 Finally, let's plot f(x) f(x) and T_3(x) T_3(x) together: T3 = a0 + a1*x + a2*x**2 + a3*x**3 plt.plot(x,y,x,T3), plt.xlim([-3,3]), plt.ylim([0,5]); plt.show() Arc length Write a function called arc_length which takes parameters f , a , b , h and N and returns an approximation of the arc length of f(x) f(x) from a a to b b L \\approx \\int_a^b \\sqrt{ 1 + \\left( f'(x) \\right)^2 } dx L \\approx \\int_a^b \\sqrt{ 1 + \\left( f'(x) \\right)^2 } dx The function uses the trapezoid rule ( scipy.integrate.trapz ) to estimate the integral and the central difference formula to approximate f'(x) f'(x) . Note that we can't use the central difference formula at the endpoints because they use x x values outside the interval [a,b] [a,b] and our function may not be defined there. import scipy.integrate as spi def arc_length(f,a,b,h=0.001,N=1000): '''Approximate the arc length of y=f(x) from x=a to x=b. Parameters ---------- f : (vectorized) function of one variable a,b : numbers defining the interval [a,b] h : step size to use in difference formulas N : number of subintervals in trapezoid method Returns ------- Approximation of the integral \\int_a^b \\sqrt{1 + (f'(x))^2} dx representing the arc length of y=f(x) from x=a to x=b. ''' x = np.linspace(a,b,N+1) y = f(x) # Compute central difference formula for x_k for 1 &lt;= k &lt;= N-1 h = np.min([h,(b-a)/N]) # Make sure that h is smaller than the size of the subintervals x_interior = x[1:-1] df_interior = (f(x_interior + h) - f(x_interior - h))/(2*h) # Use forward/backward difference formula at the endpoints df_a = (f(a + h) - f(a))/h df_b = (f(b) - f(b - h))/h df = np.hstack([[df_a],df_interior,[df_b]]) # Compute values of the integrand in arc length formula y = np.sqrt(1 + df**2) # Compute the integral L = spi.trapz(y,x) return L Let's test our function with input where we know the exact output. For example, the arc length of f(x)=x f(x)=x from a=0 a=0 to b=1 b=1 is L=\\sqrt{2} L=\\sqrt{2} and we compute arc_length(lambda x: x,0,1) 1.4142135623730958 and compare with the exact value np.sqrt(2) 1.4142135623730951 The arc length of f(x)=\\sqrt{1 - x^2} f(x)=\\sqrt{1 - x^2} from a=0 a=0 to b=\\frac{1}{\\sqrt{2}} b=\\frac{1}{\\sqrt{2}} is L=\\frac{\\pi}{4} L=\\frac{\\pi}{4} and we compute arc_length(lambda x: np.sqrt(1 - x**2),0,1/np.sqrt(2)) 0.7853980801486478 and compare to the exact value np.pi/4 0.7853981633974483 The arc length of f(x)=\\frac{2x^{3/2}}{3} f(x)=\\frac{2x^{3/2}}{3} from a=0 a=0 to b=1 b=1 is L = \\frac{2}{3}\\left( 2^{3/2} - 1 \\right) L = \\frac{2}{3}\\left( 2^{3/2} - 1 \\right) and we compute arc_length(lambda x: 2*(x**(3/2))/3,0,1,h=10**(-10),N=10**5) 1.2189514473615233 and compare to the exact value (2/3)*(2**(3/2) - 1) 1.2189514164974602 Exercises Use derivative to compute values and then plot the derivative f'(x) f'(x) of the function f(x) = \\frac{7x^3-5x+1}{2x^4+x^2+1} \\ , \\ x \\in [-5,5] f(x) = \\frac{7x^3-5x+1}{2x^4+x^2+1} \\ , \\ x \\in [-5,5] Compute the derivative of f(x) f(x) by hand (using the quotient rule), plot the formula for f'(x) f'(x) and compare to the numerical approximation above. Plot the Taylor polynomial T_4(x) T_4(x) of degree 4 centered at x=0 x=0 of the function f(x) = \\cos(x) + \\sin(2x) f(x) = \\cos(x) + \\sin(2x) over the interval x \\in [-\\pi,\\pi] x \\in [-\\pi,\\pi] .","title":"Numerical Differentiation"},{"location":"differentiation/differentiation/#numerical-differentiation","text":"import numpy as np import matplotlib.pyplot as plt %matplotlib inline","title":"Numerical Differentiation"},{"location":"differentiation/differentiation/#derivative","text":"The derivative of a function f(x) f(x) at x=a x=a is the limit f'(a) = \\lim_{h \\to 0} \\frac{f(a+h) - f(a)}{h} f'(a) = \\lim_{h \\to 0} \\frac{f(a+h) - f(a)}{h}","title":"Derivative"},{"location":"differentiation/differentiation/#difference-formulas","text":"There are 3 main difference formulas for numerically approximating derivatives. The forward difference formula with step size h h is f'(a) \\approx \\frac{f(a + h) - f(a)}{h} f'(a) \\approx \\frac{f(a + h) - f(a)}{h} The backward difference formula with step size h h is f'(a) \\approx \\frac{f(a) - f(a - h)}{h} f'(a) \\approx \\frac{f(a) - f(a - h)}{h} The central difference formula with step size h h is the average of the forward and backwards difference formulas f'(a) \\approx \\frac{1}{2} \\left( \\frac{f(a + h) - f(a)}{h} + \\frac{f(a) - f(a - h)}{h} \\right) = \\frac{f(a + h) - f(a - h)}{2h} f'(a) \\approx \\frac{1}{2} \\left( \\frac{f(a + h) - f(a)}{h} + \\frac{f(a) - f(a - h)}{h} \\right) = \\frac{f(a + h) - f(a - h)}{2h}","title":"Difference Formulas"},{"location":"differentiation/differentiation/#implementation","text":"Let's write a function called derivative which takes input parameters f , a , method and h (with default values method='central' and h=0.01 ) and returns the corresponding difference formula for f'(a) f'(a) with step size h h . def derivative(f,a,method='central',h=0.01): '''Compute the difference formula for f'(a) with step size h. Parameters ---------- f : function Vectorized function of one variable a : number Compute derivative at x = a method : string Difference formula: 'forward', 'backward' or 'central' h : number Step size in difference formula Returns ------- float Difference formula: central: f(a+h) - f(a-h))/2h forward: f(a+h) - f(a))/h backward: f(a) - f(a-h))/h ''' if method == 'central': return (f(a + h) - f(a - h))/(2*h) elif method == 'forward': return (f(a + h) - f(a))/h elif method == 'backward': return (f(a) - f(a - h))/h else: raise ValueError(\"Method must be 'central', 'forward' or 'backward'.\") Let's test our function on some simple functions. For example, we know \\left. \\frac{d}{dx} \\left( \\cos x \\right) \\, \\right|_{x=0} = -\\sin(0) = 0 \\left. \\frac{d}{dx} \\left( \\cos x \\right) \\, \\right|_{x=0} = -\\sin(0) = 0 and we compute derivative(np.cos,0) 0.0 derivative(np.cos,0,method='forward',h=1e-8) 0.0 We also know \\left. \\frac{d}{dx} \\left( e^x \\right) \\, \\right|_{x=0} = e^0 = 1 \\left. \\frac{d}{dx} \\left( e^x \\right) \\, \\right|_{x=0} = e^0 = 1 and we compute derivative(np.exp,0,h=0.0001) 1.0000000016668897 derivative(np.exp,0,method='backward',h=0.0001) 0.9999500016666385 Notice that our function can take an array of inputs for a a and return the derivatives for each a a value. For example, we can plot the derivative of \\sin(x) \\sin(x) : x = np.linspace(0,5*np.pi,100) dydx = derivative(np.sin,x) dYdx = np.cos(x) plt.figure(figsize=(12,5)) plt.plot(x,dydx,'r.',label='Central Difference') plt.plot(x,dYdx,'b',label='True Value') plt.title('Central Difference Derivative of y = cos(x)') plt.legend(loc='best') plt.show() Let's compute and plot the derivative of a complicated function y=\\left(\\frac{4x^2+2x+1}{x+2e^x}\\right)^x y=\\left(\\frac{4x^2+2x+1}{x+2e^x}\\right)^x x = np.linspace(0,6,100) f = lambda x: ((4*x**2 + 2*x + 1)/(x + 2*np.exp(x)))**x y = f(x) dydx = derivative(f,x) plt.figure(figsize=(12,5)) plt.plot(x,y,label='y=f(x)') plt.plot(x,dydx,label=\"Central Difference y=f'(x)\") plt.legend() plt.grid(True) plt.show()","title":"Implementation"},{"location":"differentiation/differentiation/#error-formulas","text":"Natural questions arise: how good are the approximations given by the forward, backwards and central difference formulas? We derive the error formulas from Taylor's Theorem . Theorem. The degree n n Taylor polynomial of f(x) f(x) at x=a x=a with remainder term is f(x) = f(a) + f'(a)(x - a) + \\frac{f''(a)}{2}(x-a)^2 + \\cdots + \\frac{f^{(n)}(a)}{n!}(x-a)^n + \\frac{f^{(n+1)}(c)}{(n+1)!}(x-a)^{n+1} f(x) = f(a) + f'(a)(x - a) + \\frac{f''(a)}{2}(x-a)^2 + \\cdots + \\frac{f^{(n)}(a)}{n!}(x-a)^n + \\frac{f^{(n+1)}(c)}{(n+1)!}(x-a)^{n+1} for some value c c between x x and a a . Theorem. The forward difference formula error is \\left| \\, \\frac{f(a+h) - f(a)}{h} - f'(a) \\, \\right| \\leq \\frac{hK_2}{2} \\left| \\, \\frac{f(a+h) - f(a)}{h} - f'(a) \\, \\right| \\leq \\frac{hK_2}{2} where \\left| \\, f''(x) \\, \\right| \\leq K_2 \\left| \\, f''(x) \\, \\right| \\leq K_2 for all x \\in [a,a+h] x \\in [a,a+h] . The same error fomula holds for the backward difference formula. Proof . Look at the degree 1 Taylor formula: f(x) = f(a) + f'(a)(x-a) + \\frac{f''(c)}{2}(x-a)^{2} f(x) = f(a) + f'(a)(x-a) + \\frac{f''(c)}{2}(x-a)^{2} Let x = a+h x = a+h and manipulate the formula \\begin{align} f(a+h) &= f(a) + f'(a)h + \\frac{f''(c)}{2}h^{2} \\\\\\ f(a+h) - f(a) &= f'(a)h + \\frac{f''(c)}{2}h^{2} \\\\\\ \\frac{f(a+h) - f(a)}{h} &= f'(a) + \\frac{f''(c)}{2}h \\\\\\ \\frac{f(a+h) - f(a)}{h} - f'(a) &= \\frac{f''(c)}{2}h \\end{align} \\begin{align} f(a+h) &= f(a) + f'(a)h + \\frac{f''(c)}{2}h^{2} \\\\\\ f(a+h) - f(a) &= f'(a)h + \\frac{f''(c)}{2}h^{2} \\\\\\ \\frac{f(a+h) - f(a)}{h} &= f'(a) + \\frac{f''(c)}{2}h \\\\\\ \\frac{f(a+h) - f(a)}{h} - f'(a) &= \\frac{f''(c)}{2}h \\end{align} Let K_2 K_2 such that \\left| \\, f''(x) \\, \\right| \\leq K_2 \\left| \\, f''(x) \\, \\right| \\leq K_2 for all x \\in [a,a+h] x \\in [a,a+h] and we see the result. Theorem. The central difference formula error is: \\left| \\frac{f(a+h) - f(a-h)}{2h} - f'(a) \\right| \\leq \\frac{h^2K_3}{6} \\left| \\frac{f(a+h) - f(a-h)}{2h} - f'(a) \\right| \\leq \\frac{h^2K_3}{6} where |f'''(x)| \\leq K_3 |f'''(x)| \\leq K_3 for all x \\in [a-h,a+h] x \\in [a-h,a+h] . Proof . Look at the Taylor polynomial of degree 2: f(x) = f(a) + f'(a)(x-a) + \\frac{f''(a)}{2}(x-a)^2 + \\frac{f'''(c)}{6}(x-a)^{3} f(x) = f(a) + f'(a)(x-a) + \\frac{f''(a)}{2}(x-a)^2 + \\frac{f'''(c)}{6}(x-a)^{3} Let x = a + h x = a + h and also x = a - h x = a - h and write: \\begin{align} f(a+h) &= f(a) + f'(a)h + \\frac{f''(a)}{2}h^2 + \\frac{f'''(c_1)}{6}h^{3} \\\\\\ f(a-h) &= f(a) - f'(a)h + \\frac{f''(a)}{2}h^2 - \\frac{f'''(c_2)}{6}h^{3} \\\\\\ f(a+h) - f(a-h) &= 2 f'(a)h + \\frac{f'''(c_1)}{6}h^{3} + \\frac{f'''(c_2)}{6}h^{3} \\\\\\ \\frac{f(a+h) - f(a-h)}{2h} - f'(a) &= \\frac{f'''(c_1) + f'''(c_2)}{12}h^{2} \\end{align} \\begin{align} f(a+h) &= f(a) + f'(a)h + \\frac{f''(a)}{2}h^2 + \\frac{f'''(c_1)}{6}h^{3} \\\\\\ f(a-h) &= f(a) - f'(a)h + \\frac{f''(a)}{2}h^2 - \\frac{f'''(c_2)}{6}h^{3} \\\\\\ f(a+h) - f(a-h) &= 2 f'(a)h + \\frac{f'''(c_1)}{6}h^{3} + \\frac{f'''(c_2)}{6}h^{3} \\\\\\ \\frac{f(a+h) - f(a-h)}{2h} - f'(a) &= \\frac{f'''(c_1) + f'''(c_2)}{12}h^{2} \\end{align} Notice that f'''(x) f'''(x) is continuous (by assumption) and (f'''(c_1) + f'''(c_2))/2 (f'''(c_1) + f'''(c_2))/2 is between f'''(c_1) f'''(c_1) and f'''(c_2) f'''(c_2) and so there exists some c c between c_1 c_1 and c_2 c_2 such that f'''(c) = \\frac{f'''(c_1) + f'''(c_2)}{2} f'''(c) = \\frac{f'''(c_1) + f'''(c_2)}{2} by the Intermediate Value Theorem. Let K_3 K_3 such that \\left| \\, f'''(x) \\, \\right| \\leq K_3 \\left| \\, f'''(x) \\, \\right| \\leq K_3 for all x \\in [a-h,a+h] x \\in [a-h,a+h] and we see the result.","title":"Error Formulas"},{"location":"differentiation/differentiation/#scipymiscderivative","text":"The SciPy function scipy.misc.derivative computes derivatives using the central difference formula. from scipy.misc import derivative x = np.arange(0,5) derivative(np.exp,x,dx=0.1) array([ 1.0016675 , 2.72281456, 7.40137735, 20.11902956, 54.68919246])","title":"scipy.misc.derivative"},{"location":"differentiation/differentiation/#higher-order-derivatives","text":"Under construction","title":"Higher Order Derivatives"},{"location":"differentiation/differentiation/#examples","text":"","title":"Examples"},{"location":"differentiation/differentiation/#taylor-series","text":"Let's plot the Taylor polynomial T_3(x) T_3(x) of degree 3 centered at x=0 x=0 for f(x) = \\frac{3e^x}{x^2 + x + 1} f(x) = \\frac{3e^x}{x^2 + x + 1} over the interval x \\in [-3,3] x \\in [-3,3] . First, let's plot the graph y=f(x) y=f(x) : x = np.linspace(-3,3,100) f = lambda x: 3*np.exp(x) / (x**2 + x + 1) y = f(x) plt.plot(x,y); plt.show() Let's compute the coefficients a_n = \\frac{f^{(n)}(0)}{n!} a_n = \\frac{f^{(n)}(0)}{n!} for n=0,1,2,3 n=0,1,2,3 : a0 = f(0) a1 = derivative(f,0,dx=0.001,n=1) a2 = derivative(f,0,dx=0.001,n=2) / 2 a3 = derivative(f,0,dx=0.001,n=3,order=5) / 6 # The parameter order specifies the number of points to use # The value order must be odd and at least n + 1 print(a0,a1,a2,a3) 3.0 1.9999983891239026e-06 -1.50000037502096 1.9999920608526622 Finally, let's plot f(x) f(x) and T_3(x) T_3(x) together: T3 = a0 + a1*x + a2*x**2 + a3*x**3 plt.plot(x,y,x,T3), plt.xlim([-3,3]), plt.ylim([0,5]); plt.show()","title":"Taylor series"},{"location":"differentiation/differentiation/#arc-length","text":"Write a function called arc_length which takes parameters f , a , b , h and N and returns an approximation of the arc length of f(x) f(x) from a a to b b L \\approx \\int_a^b \\sqrt{ 1 + \\left( f'(x) \\right)^2 } dx L \\approx \\int_a^b \\sqrt{ 1 + \\left( f'(x) \\right)^2 } dx The function uses the trapezoid rule ( scipy.integrate.trapz ) to estimate the integral and the central difference formula to approximate f'(x) f'(x) . Note that we can't use the central difference formula at the endpoints because they use x x values outside the interval [a,b] [a,b] and our function may not be defined there. import scipy.integrate as spi def arc_length(f,a,b,h=0.001,N=1000): '''Approximate the arc length of y=f(x) from x=a to x=b. Parameters ---------- f : (vectorized) function of one variable a,b : numbers defining the interval [a,b] h : step size to use in difference formulas N : number of subintervals in trapezoid method Returns ------- Approximation of the integral \\int_a^b \\sqrt{1 + (f'(x))^2} dx representing the arc length of y=f(x) from x=a to x=b. ''' x = np.linspace(a,b,N+1) y = f(x) # Compute central difference formula for x_k for 1 &lt;= k &lt;= N-1 h = np.min([h,(b-a)/N]) # Make sure that h is smaller than the size of the subintervals x_interior = x[1:-1] df_interior = (f(x_interior + h) - f(x_interior - h))/(2*h) # Use forward/backward difference formula at the endpoints df_a = (f(a + h) - f(a))/h df_b = (f(b) - f(b - h))/h df = np.hstack([[df_a],df_interior,[df_b]]) # Compute values of the integrand in arc length formula y = np.sqrt(1 + df**2) # Compute the integral L = spi.trapz(y,x) return L Let's test our function with input where we know the exact output. For example, the arc length of f(x)=x f(x)=x from a=0 a=0 to b=1 b=1 is L=\\sqrt{2} L=\\sqrt{2} and we compute arc_length(lambda x: x,0,1) 1.4142135623730958 and compare with the exact value np.sqrt(2) 1.4142135623730951 The arc length of f(x)=\\sqrt{1 - x^2} f(x)=\\sqrt{1 - x^2} from a=0 a=0 to b=\\frac{1}{\\sqrt{2}} b=\\frac{1}{\\sqrt{2}} is L=\\frac{\\pi}{4} L=\\frac{\\pi}{4} and we compute arc_length(lambda x: np.sqrt(1 - x**2),0,1/np.sqrt(2)) 0.7853980801486478 and compare to the exact value np.pi/4 0.7853981633974483 The arc length of f(x)=\\frac{2x^{3/2}}{3} f(x)=\\frac{2x^{3/2}}{3} from a=0 a=0 to b=1 b=1 is L = \\frac{2}{3}\\left( 2^{3/2} - 1 \\right) L = \\frac{2}{3}\\left( 2^{3/2} - 1 \\right) and we compute arc_length(lambda x: 2*(x**(3/2))/3,0,1,h=10**(-10),N=10**5) 1.2189514473615233 and compare to the exact value (2/3)*(2**(3/2) - 1) 1.2189514164974602","title":"Arc length"},{"location":"differentiation/differentiation/#exercises","text":"Use derivative to compute values and then plot the derivative f'(x) f'(x) of the function f(x) = \\frac{7x^3-5x+1}{2x^4+x^2+1} \\ , \\ x \\in [-5,5] f(x) = \\frac{7x^3-5x+1}{2x^4+x^2+1} \\ , \\ x \\in [-5,5] Compute the derivative of f(x) f(x) by hand (using the quotient rule), plot the formula for f'(x) f'(x) and compare to the numerical approximation above. Plot the Taylor polynomial T_4(x) T_4(x) of degree 4 centered at x=0 x=0 of the function f(x) = \\cos(x) + \\sin(2x) f(x) = \\cos(x) + \\sin(2x) over the interval x \\in [-\\pi,\\pi] x \\in [-\\pi,\\pi] .","title":"Exercises"},{"location":"integration/integrals/","text":"Definite Integrals The definite integral of a function f(x) f(x) over an interval [a,b] [a,b] is the limit \\int_a^b f(x) \\, dx = \\lim_{N \\to \\infty} \\sum_{i=1}^N f(x_i^ * ) (x_i - x_{i-1}) \\ \\ , \\ x_i^* \\in [x_{i-1},x_i] \\int_a^b f(x) \\, dx = \\lim_{N \\to \\infty} \\sum_{i=1}^N f(x_i^ * ) (x_i - x_{i-1}) \\ \\ , \\ x_i^* \\in [x_{i-1},x_i] where, for each N N , x_0 = a < x_1 < \\cdots < x_N = b x_0 = a < x_1 < \\cdots < x_N = b is a partition of [a,b] [a,b] with N N subintervals and the values x_i^ * \\in [x_{i-1},x_i] x_i^ * \\in [x_{i-1},x_i] chosen in each subinterval is arbitrary. The formula in the definition is not very intuitive and almost impossible to use in practice but the basic idea is simple: \\int_a^b f(x) \\, dx = \\text{(net) area under the curve } y = f(x) \\text{ on } [a,b] \\int_a^b f(x) \\, dx = \\text{(net) area under the curve } y = f(x) \\text{ on } [a,b] The value of the definite integral represents the (net) area under the curve of the graph of y=f(x) y=f(x) on the interval [a,b] [a,b] . The term \"net\" means that area above the x x -axis is positive and the area under the x x -axis counts as negative area. For example, we can visualize the integral: \\int_{\\pi/2}^{3\\pi/2} \\left( \\sin(0.2 x) + \\sin(2x) + 1 \\right) dx \\int_{\\pi/2}^{3\\pi/2} \\left( \\sin(0.2 x) + \\sin(2x) + 1 \\right) dx import numpy as np import matplotlib.pyplot as plt %matplotlib inline f = lambda x: np.sin(0.2*x) + np.sin(2*x) + 1 x = np.linspace(0,2*np.pi,100) y = f(x) plt.plot(x,y) X = np.linspace(np.pi/2,3*np.pi/2,100) Y = f(X) plt.fill_between(X,Y) plt.xticks([np.pi/2,3*np.pi/2],['$\\pi/2$','$3\\pi/2$']); plt.yticks([]); plt.xlim([0,2*np.pi]); plt.ylim([0,3]); plt.show() In our introductory calculus courses, we focus on integrals which we can solve exactly by the Fundamental Theorem of Calculus such as \\int_0^{\\pi/2} \\cos(x) \\, dx = \\sin(\\pi/2) - \\sin(0) = 1 \\int_0^{\\pi/2} \\cos(x) \\, dx = \\sin(\\pi/2) - \\sin(0) = 1 However, most definite integrals are impossible to solve exactly. For example, the famous error function in probability \\mathrm{erf}(x) = \\frac{2}{\\sqrt{\\pi}} \\int_0^x e^{-t^2} dt \\mathrm{erf}(x) = \\frac{2}{\\sqrt{\\pi}} \\int_0^x e^{-t^2} dt is a definite integral for which there is no explicit formula. The idea behind numerical integration is to use simple geometric shapes to approximate the area under the curve y=f(x) y=f(x) to estimate definite integrals. In this section, we explore the simplest methods of numerical integration: Riemann sums, the trapezoid rule and Simpson's rule.","title":"Definite Integrals"},{"location":"integration/integrals/#definite-integrals","text":"The definite integral of a function f(x) f(x) over an interval [a,b] [a,b] is the limit \\int_a^b f(x) \\, dx = \\lim_{N \\to \\infty} \\sum_{i=1}^N f(x_i^ * ) (x_i - x_{i-1}) \\ \\ , \\ x_i^* \\in [x_{i-1},x_i] \\int_a^b f(x) \\, dx = \\lim_{N \\to \\infty} \\sum_{i=1}^N f(x_i^ * ) (x_i - x_{i-1}) \\ \\ , \\ x_i^* \\in [x_{i-1},x_i] where, for each N N , x_0 = a < x_1 < \\cdots < x_N = b x_0 = a < x_1 < \\cdots < x_N = b is a partition of [a,b] [a,b] with N N subintervals and the values x_i^ * \\in [x_{i-1},x_i] x_i^ * \\in [x_{i-1},x_i] chosen in each subinterval is arbitrary. The formula in the definition is not very intuitive and almost impossible to use in practice but the basic idea is simple: \\int_a^b f(x) \\, dx = \\text{(net) area under the curve } y = f(x) \\text{ on } [a,b] \\int_a^b f(x) \\, dx = \\text{(net) area under the curve } y = f(x) \\text{ on } [a,b] The value of the definite integral represents the (net) area under the curve of the graph of y=f(x) y=f(x) on the interval [a,b] [a,b] . The term \"net\" means that area above the x x -axis is positive and the area under the x x -axis counts as negative area. For example, we can visualize the integral: \\int_{\\pi/2}^{3\\pi/2} \\left( \\sin(0.2 x) + \\sin(2x) + 1 \\right) dx \\int_{\\pi/2}^{3\\pi/2} \\left( \\sin(0.2 x) + \\sin(2x) + 1 \\right) dx import numpy as np import matplotlib.pyplot as plt %matplotlib inline f = lambda x: np.sin(0.2*x) + np.sin(2*x) + 1 x = np.linspace(0,2*np.pi,100) y = f(x) plt.plot(x,y) X = np.linspace(np.pi/2,3*np.pi/2,100) Y = f(X) plt.fill_between(X,Y) plt.xticks([np.pi/2,3*np.pi/2],['$\\pi/2$','$3\\pi/2$']); plt.yticks([]); plt.xlim([0,2*np.pi]); plt.ylim([0,3]); plt.show() In our introductory calculus courses, we focus on integrals which we can solve exactly by the Fundamental Theorem of Calculus such as \\int_0^{\\pi/2} \\cos(x) \\, dx = \\sin(\\pi/2) - \\sin(0) = 1 \\int_0^{\\pi/2} \\cos(x) \\, dx = \\sin(\\pi/2) - \\sin(0) = 1 However, most definite integrals are impossible to solve exactly. For example, the famous error function in probability \\mathrm{erf}(x) = \\frac{2}{\\sqrt{\\pi}} \\int_0^x e^{-t^2} dt \\mathrm{erf}(x) = \\frac{2}{\\sqrt{\\pi}} \\int_0^x e^{-t^2} dt is a definite integral for which there is no explicit formula. The idea behind numerical integration is to use simple geometric shapes to approximate the area under the curve y=f(x) y=f(x) to estimate definite integrals. In this section, we explore the simplest methods of numerical integration: Riemann sums, the trapezoid rule and Simpson's rule.","title":"Definite Integrals"},{"location":"integration/riemann-sums/","text":"Riemann Sums import numpy as np import matplotlib.pyplot as plt %matplotlib inline Definition A Riemann sum of a function f(x) f(x) over a partition x_0 = a < x_1 < \\cdots < x_{N-1} < x_N = b x_0 = a < x_1 < \\cdots < x_{N-1} < x_N = b is a sum of the form \\sum_{i=1}^N f(x_i^ * ) (x_i - x_{i-1}) \\ \\ , \\ x_i^* \\in [x_{i-1},x_i] \\sum_{i=1}^N f(x_i^ * ) (x_i - x_{i-1}) \\ \\ , \\ x_i^* \\in [x_{i-1},x_i] where each value x_i^* \\in [x_{i-1},x_i] x_i^* \\in [x_{i-1},x_i] in each subinterval is arbitrary. Riemann sums are important because they provide an easy way to approximate a definite integral \\int_a^b f(x) \\, dx \\approx \\sum_{i=1}^N f(x_i^ * ) (x_i - x_{i-1}) \\ \\ , \\ x_i^* \\in [x_{i-1},x_i] \\int_a^b f(x) \\, dx \\approx \\sum_{i=1}^N f(x_i^ * ) (x_i - x_{i-1}) \\ \\ , \\ x_i^* \\in [x_{i-1},x_i] Notice that the product f(x_i^ * ) (x_i - x_{i-1}) f(x_i^ * ) (x_i - x_{i-1}) for each i i is the area of a rectangle of height f(x_i^ * ) f(x_i^ * ) and width x_i - x_{i-1} x_i - x_{i-1} . We can think of a Riemann sum as the area of N N rectangles with heights determined by the graph of y=f(x) y=f(x) . The value x_i^* x_i^* chosen in each subinterval is arbitrary however there are certain obvious choices: A left Riemann sum is when each x_i^* = x_{i-1} x_i^* = x_{i-1} is the left endpoint of the subinterval [x_{i-1},x_i] [x_{i-1},x_i] A right Riemann sum is when each x_i^* = x_i x_i^* = x_i is the right endpoint of the subinterval [x_{i-1},x_i] [x_{i-1},x_i] A midpoint Riemann sum is when each x_i^* = (x_{i-1} + x_i)/2 x_i^* = (x_{i-1} + x_i)/2 is the midpoint of the subinterval [x_{i-1},x_i] [x_{i-1},x_i] Let's visualize rectangles in the left, right and midpoint Riemann sums for the function f(x) = \\frac{1}{1 + x^2} f(x) = \\frac{1}{1 + x^2} over the interval [0,5] [0,5] with a partition of size N=10 N=10 . f = lambda x : 1/(1+x**2) a = 0; b = 5; N = 10 n = 10 # Use n*N+1 points to plot the function smoothly x = np.linspace(a,b,N+1) y = f(x) X = np.linspace(a,b,n*N+1) Y = f(X) plt.figure(figsize=(15,5)) plt.subplot(1,3,1) plt.plot(X,Y,'b') x_left = x[:-1] # Left endpoints y_left = y[:-1] plt.plot(x_left,y_left,'b.',markersize=10) plt.bar(x_left,y_left,width=(b-a)/N,alpha=0.2,align='edge',edgecolor='b') plt.title('Left Riemann Sum, N = {}'.format(N)) plt.subplot(1,3,2) plt.plot(X,Y,'b') x_mid = (x[:-1] + x[1:])/2 # Midpoints y_mid = f(x_mid) plt.plot(x_mid,y_mid,'b.',markersize=10) plt.bar(x_mid,y_mid,width=(b-a)/N,alpha=0.2,edgecolor='b') plt.title('Midpoint Riemann Sum, N = {}'.format(N)) plt.subplot(1,3,3) plt.plot(X,Y,'b') x_right = x[1:] # Left endpoints y_right = y[1:] plt.plot(x_right,y_right,'b.',markersize=10) plt.bar(x_right,y_right,width=-(b-a)/N,alpha=0.2,align='edge',edgecolor='b') plt.title('Right Riemann Sum, N = {}'.format(N)) plt.show() Notice that when the function f(x) f(x) is decreasing on [a,b] [a,b] the left endpoints give an overestimate of the integral \\int_a^b f(x) dx \\int_a^b f(x) dx and right endpoints give an underestimate. The opposite is true is when the function is increasing. Let's compute the value of each of the Riemann sums: dx = (b-a)/N x_left = np.linspace(a,b-dx,N) x_midpoint = np.linspace(dx/2,b - dx/2,N) x_right = np.linspace(dx,b,N) print(\"Partition with\",N,\"subintervals.\") left_riemann_sum = np.sum(f(x_left) * dx) print(\"Left Riemann Sum:\",left_riemann_sum) midpoint_riemann_sum = np.sum(f(x_midpoint) * dx) print(\"Midpoint Riemann Sum:\",midpoint_riemann_sum) right_riemann_sum = np.sum(f(x_right) * dx) print(\"Right Riemann Sum:\",right_riemann_sum) Partition with 10 subintervals. Left Riemann Sum: 1.613488696614725 Midpoint Riemann Sum: 1.373543428316664 Right Riemann Sum: 1.1327194658454942 We know the exact value \\int_0^5 \\frac{1}{1 + x^2} dx = \\arctan(5) \\int_0^5 \\frac{1}{1 + x^2} dx = \\arctan(5) and we can compare the Riemann sums to the value I = np.arctan(5) print(I) 1.373400766945016 print(\"Left Riemann Sum Error:\",np.abs(left_riemann_sum - I)) print(\"Midpoint Riemann Sum:\",np.abs(midpoint_riemann_sum - I)) print(\"Right Riemann Sum:\",np.abs(right_riemann_sum - I)) Left Riemann Sum Error: 0.24008792966970915 Midpoint Riemann Sum: 0.00014266137164820059 Right Riemann Sum: 0.24068130109952168 Error Formulas A Riemann sum is an approximation of a definite integral. A natural question arises: how good of an approximation is a Riemann sum? Theorem. Let L_N(f) L_N(f) denote the left Riemann sum L_N(f) = \\sum_{i=1}^N f(x_{i-1} ) \\Delta x L_N(f) = \\sum_{i=1}^N f(x_{i-1} ) \\Delta x where \\Delta x = (b-a)/N \\Delta x = (b-a)/N and x_i = a + i \\Delta x x_i = a + i \\Delta x . The error bound is E_N^{L}(f) = \\left| \\ \\int_a^b f(x) \\ dx - L_N(f) \\ \\right| \\leq \\frac{(b-a)^2}{2 N} K_1 E_N^{L}(f) = \\left| \\ \\int_a^b f(x) \\ dx - L_N(f) \\ \\right| \\leq \\frac{(b-a)^2}{2 N} K_1 where \\left| \\, f'(x) \\, \\right| \\leq K_1 \\left| \\, f'(x) \\, \\right| \\leq K_1 for all x \\in [a,b] x \\in [a,b] . Theorem. Let R_N(f) R_N(f) denote the right Riemann sum R_N(f) = \\sum_{i=1}^N f(x_{i} ) \\Delta x R_N(f) = \\sum_{i=1}^N f(x_{i} ) \\Delta x where \\Delta x = (b-a)/N \\Delta x = (b-a)/N and x_i = a + i \\Delta x x_i = a + i \\Delta x . The error bound is E_N^{R}(f) = \\left| \\ \\int_a^b f(x) \\ dx - R_N(f) \\ \\right| \\leq \\frac{(b-a)^2}{2 N} K_1 E_N^{R}(f) = \\left| \\ \\int_a^b f(x) \\ dx - R_N(f) \\ \\right| \\leq \\frac{(b-a)^2}{2 N} K_1 where \\left| \\, f'(x) \\, \\right| \\leq K_1 \\left| \\, f'(x) \\, \\right| \\leq K_1 for all x \\in [a,b] x \\in [a,b] . Theorem. Let M_N(f) M_N(f) denote the midpoint Riemann sum M_N(f) = \\sum_{i=1}^N f(x_i^* ) \\Delta x M_N(f) = \\sum_{i=1}^N f(x_i^* ) \\Delta x where \\Delta x = (b-a)/N \\Delta x = (b-a)/N and x_i^* = (x_{i-1} + x_i)/2 x_i^* = (x_{i-1} + x_i)/2 for x_i = a + i \\Delta x x_i = a + i \\Delta x . The error bound is E_N^{M}(f) = \\left| \\ \\int_a^b f(x) \\ dx - M_N(f) \\ \\right| \\leq \\frac{(b-a)^3}{24 N^2} K_2 E_N^{M}(f) = \\left| \\ \\int_a^b f(x) \\ dx - M_N(f) \\ \\right| \\leq \\frac{(b-a)^3}{24 N^2} K_2 where \\left| \\, f''(x) \\, \\right| \\leq K_2 \\left| \\, f''(x) \\, \\right| \\leq K_2 for all x \\in [a,b] x \\in [a,b] . There are several points to notice: Left and right Riemann sums have the same error bound which depends on the first derivative f'(x) f'(x) . Midpoint Riemann sum error bound depends on the second derivative f''(x) f''(x) . We expect the midpoint Riemann sum to give a better approximation as N \\to \\infty N \\to \\infty since its error bound is inversely proportional to N^2 N^2 but left/right Riemann sum error bound is inversely proportional only to N N . Implementation Let's write a function called riemann_sum which takes 5 input parameters f , a , b , N and method and returns the Riemann sum \\sum_{i=1}^N f(x_i^*) \\Delta x \\sum_{i=1}^N f(x_i^*) \\Delta x where \\Delta x = (b-a)/N \\Delta x = (b-a)/N and x_i = a + i\\Delta x x_i = a + i\\Delta x defines a partition with N N subintervals of equal length , and method determines whether we use left endpoints, right endpoints or midpoints (with midpoints as the default method). def riemann_sum(f,a,b,N,method='midpoint'): '''Compute the Riemann sum of f(x) over the interval [a,b]. Parameters ---------- f : function Vectorized function of one variable a , b : numbers Endpoints of the interval [a,b] N : integer Number of subintervals of equal length in the partition of [a,b] method : string Determines the kind of Riemann sum: right : Riemann sum using right endpoints left : Riemann sum using left endpoints midpoint (default) : Riemann sum using midpoints Returns ------- float Approximation of the integral given by the Riemann sum. ''' dx = (b - a)/N x = np.linspace(a,b,N+1) if method == 'left': x_left = x[:-1] return np.sum(f(x_left)*dx) elif method == 'right': x_right = x[1:] return np.sum(f(x_right)*dx) elif method == 'midpoint': x_mid = (x[:-1] + x[1:])/2 return np.sum(f(x_mid)*dx) else: raise ValueError(\"Method must be 'left', 'right' or 'midpoint'.\") Let's test our function with inputs where we know exactly what the output should be. For example, we know \\int_0^{\\pi/2} \\sin(x) \\, dx = 1 \\int_0^{\\pi/2} \\sin(x) \\, dx = 1 and, since \\sin(x) \\sin(x) is increasing on [0,\\pi/2] [0,\\pi/2] , we know that left endpoints will give an under-estimate, and right endpoints will give an over-estimate. riemann_sum(np.sin,0,np.pi/2,100) 1.0000102809119054 riemann_sum(np.sin,0,np.pi/2,100,'right') 1.007833419873582 riemann_sum(np.sin,0,np.pi/2,100,'left') 0.992125456605633 We also know that \\int_0^1 x \\, dx = 1/2 \\int_0^1 x \\, dx = 1/2 and midpoint should give the result exactly for any N N : riemann_sum(lambda x : x,0,1,1) 0.5 Examples Approximate Pi Find a value N N which guarantees the right Riemann sum of f(x)=\\frac{4}{1 + x^2} f(x)=\\frac{4}{1 + x^2} over [0,1] [0,1] is within 10^{-5} 10^{-5} of the exact value \\int_0^1 \\frac{4}{1 + x^2} dx = \\pi \\int_0^1 \\frac{4}{1 + x^2} dx = \\pi Compute f'(x) = -\\frac{8x}{(1+x^2)^2} f'(x) = -\\frac{8x}{(1+x^2)^2} Use brute force optimization to find a bound on \\left| f'(x) \\right| \\left| f'(x) \\right| on [0,1] [0,1] : x = np.linspace(0,1,1000) y = np.abs(-8*x/(1 + x**2)**2) np.max(y) 2.5980759093919907 Therefore, \\left| f'(x) \\right| \\leq 2.6 \\left| f'(x) \\right| \\leq 2.6 for x \\in [0,1] x \\in [0,1] . Use the error bound \\frac{(b-a)^2}{2 N} K_1 \\leq 10^{-5} \\ \\Rightarrow \\ \\frac{1.3}{N} \\leq 10^{-5} \\ \\Rightarrow \\ 130000 \\leq N \\frac{(b-a)^2}{2 N} K_1 \\leq 10^{-5} \\ \\Rightarrow \\ \\frac{1.3}{N} \\leq 10^{-5} \\ \\Rightarrow \\ 130000 \\leq N Let's compute the right Riemann sum for N=130000 N=130000 : approximation = riemann_sum(lambda x : 4/(1 + x**2),0,1,130000,method='right') print(approximation) 3.1415849612722386 Verify the accuracy of the approximation np.abs(approximation - np.pi) < 10**(-5) True Approximate ln(2) Find a value N N which guarantees the midpoint Riemann sum of f(x)=\\frac{1}{x} f(x)=\\frac{1}{x} over [1,2] [1,2] is within 10^{-8} 10^{-8} of the exact value \\int_1^2 \\frac{1}{x} dx = \\ln(2) \\int_1^2 \\frac{1}{x} dx = \\ln(2) Compute f''(x) = \\frac{2}{x^3} f''(x) = \\frac{2}{x^3} Since f''(x) f''(x) is decreasing for all x>0 x>0 we have \\left| \\, f''(x) \\, \\right| \\leq 2 \\left| \\, f''(x) \\, \\right| \\leq 2 for all x \\in [1,2] x \\in [1,2] . Use the error bound: \\frac{(b-a)^3}{24 N^2} K_2 \\leq 10^{-8} \\ \\Rightarrow \\ \\frac{1}{12 N^2} \\leq 10^{-8} \\ \\Rightarrow \\frac{10^4}{\\sqrt{12}} \\leq N \\frac{(b-a)^3}{24 N^2} K_2 \\leq 10^{-8} \\ \\Rightarrow \\ \\frac{1}{12 N^2} \\leq 10^{-8} \\ \\Rightarrow \\frac{10^4}{\\sqrt{12}} \\leq N 10**4 / np.sqrt(12) 2886.751345948129 Therefore a partition of size N=2887 N=2887 guarantees the desired accuracy: approximation = riemann_sum(lambda x : 1/x,1,2,2887,method='midpoint') print(approximation) 0.6931471768105913 Verify the accuracy of the approximation: np.abs(approximation - np.log(2)) < 10**(-8) True Exercises Consider the integral \\int_1^2 \\frac{dx}{1+x^3} \\int_1^2 \\frac{dx}{1+x^3} Without plotting the functions f(x) f(x) , f'(x) f'(x) or f''(x) f''(x) , find a value N N such that E_N^R(f) \\leq 10^{-5} E_N^R(f) \\leq 10^{-5} given f(x) = \\frac{1}{1 + x^3} \\ , \\ f'(x) = -\\frac{3 x^{2}}{\\left(x^{3} + 1\\right)^{2}} \\ , \\ f''(x) = \\frac{6 x \\left(2 x^{3} - 1\\right)}{\\left(x + 1\\right)^{3} \\left(x^{2} - x + 1\\right)^{3}} \\\\\\\\ f(x) = \\frac{1}{1 + x^3} \\ , \\ f'(x) = -\\frac{3 x^{2}}{\\left(x^{3} + 1\\right)^{2}} \\ , \\ f''(x) = \\frac{6 x \\left(2 x^{3} - 1\\right)}{\\left(x + 1\\right)^{3} \\left(x^{2} - x + 1\\right)^{3}} \\\\\\\\ Plot the function f''(x) f''(x) from the previous question on the interval [1,2] [1,2] and find a value N N such that E_N^M(f) \\leq 10^{-5} E_N^M(f) \\leq 10^{-5} for the integral in the previous question. Let f(x) = x^x f(x) = x^x and note that f'(x) = x^{x} \\left(\\log{\\left(x \\right)} + 1\\right) \\ , \\ f''(x) = x^{x} \\left(\\log{\\left(x \\right)} + 1\\right)^{2} + x^{x-1} f'(x) = x^{x} \\left(\\log{\\left(x \\right)} + 1\\right) \\ , \\ f''(x) = x^{x} \\left(\\log{\\left(x \\right)} + 1\\right)^{2} + x^{x-1} Plot the function f''(x) f''(x) and use that information to compute T_N(f) T_N(f) for the integral \\int_1^2 x^x \\, dx \\int_1^2 x^x \\, dx such that E_N^T(f) \\leq 10^{-3} E_N^T(f) \\leq 10^{-3} .","title":"Riemann Sums"},{"location":"integration/riemann-sums/#riemann-sums","text":"import numpy as np import matplotlib.pyplot as plt %matplotlib inline","title":"Riemann Sums"},{"location":"integration/riemann-sums/#definition","text":"A Riemann sum of a function f(x) f(x) over a partition x_0 = a < x_1 < \\cdots < x_{N-1} < x_N = b x_0 = a < x_1 < \\cdots < x_{N-1} < x_N = b is a sum of the form \\sum_{i=1}^N f(x_i^ * ) (x_i - x_{i-1}) \\ \\ , \\ x_i^* \\in [x_{i-1},x_i] \\sum_{i=1}^N f(x_i^ * ) (x_i - x_{i-1}) \\ \\ , \\ x_i^* \\in [x_{i-1},x_i] where each value x_i^* \\in [x_{i-1},x_i] x_i^* \\in [x_{i-1},x_i] in each subinterval is arbitrary. Riemann sums are important because they provide an easy way to approximate a definite integral \\int_a^b f(x) \\, dx \\approx \\sum_{i=1}^N f(x_i^ * ) (x_i - x_{i-1}) \\ \\ , \\ x_i^* \\in [x_{i-1},x_i] \\int_a^b f(x) \\, dx \\approx \\sum_{i=1}^N f(x_i^ * ) (x_i - x_{i-1}) \\ \\ , \\ x_i^* \\in [x_{i-1},x_i] Notice that the product f(x_i^ * ) (x_i - x_{i-1}) f(x_i^ * ) (x_i - x_{i-1}) for each i i is the area of a rectangle of height f(x_i^ * ) f(x_i^ * ) and width x_i - x_{i-1} x_i - x_{i-1} . We can think of a Riemann sum as the area of N N rectangles with heights determined by the graph of y=f(x) y=f(x) . The value x_i^* x_i^* chosen in each subinterval is arbitrary however there are certain obvious choices: A left Riemann sum is when each x_i^* = x_{i-1} x_i^* = x_{i-1} is the left endpoint of the subinterval [x_{i-1},x_i] [x_{i-1},x_i] A right Riemann sum is when each x_i^* = x_i x_i^* = x_i is the right endpoint of the subinterval [x_{i-1},x_i] [x_{i-1},x_i] A midpoint Riemann sum is when each x_i^* = (x_{i-1} + x_i)/2 x_i^* = (x_{i-1} + x_i)/2 is the midpoint of the subinterval [x_{i-1},x_i] [x_{i-1},x_i] Let's visualize rectangles in the left, right and midpoint Riemann sums for the function f(x) = \\frac{1}{1 + x^2} f(x) = \\frac{1}{1 + x^2} over the interval [0,5] [0,5] with a partition of size N=10 N=10 . f = lambda x : 1/(1+x**2) a = 0; b = 5; N = 10 n = 10 # Use n*N+1 points to plot the function smoothly x = np.linspace(a,b,N+1) y = f(x) X = np.linspace(a,b,n*N+1) Y = f(X) plt.figure(figsize=(15,5)) plt.subplot(1,3,1) plt.plot(X,Y,'b') x_left = x[:-1] # Left endpoints y_left = y[:-1] plt.plot(x_left,y_left,'b.',markersize=10) plt.bar(x_left,y_left,width=(b-a)/N,alpha=0.2,align='edge',edgecolor='b') plt.title('Left Riemann Sum, N = {}'.format(N)) plt.subplot(1,3,2) plt.plot(X,Y,'b') x_mid = (x[:-1] + x[1:])/2 # Midpoints y_mid = f(x_mid) plt.plot(x_mid,y_mid,'b.',markersize=10) plt.bar(x_mid,y_mid,width=(b-a)/N,alpha=0.2,edgecolor='b') plt.title('Midpoint Riemann Sum, N = {}'.format(N)) plt.subplot(1,3,3) plt.plot(X,Y,'b') x_right = x[1:] # Left endpoints y_right = y[1:] plt.plot(x_right,y_right,'b.',markersize=10) plt.bar(x_right,y_right,width=-(b-a)/N,alpha=0.2,align='edge',edgecolor='b') plt.title('Right Riemann Sum, N = {}'.format(N)) plt.show() Notice that when the function f(x) f(x) is decreasing on [a,b] [a,b] the left endpoints give an overestimate of the integral \\int_a^b f(x) dx \\int_a^b f(x) dx and right endpoints give an underestimate. The opposite is true is when the function is increasing. Let's compute the value of each of the Riemann sums: dx = (b-a)/N x_left = np.linspace(a,b-dx,N) x_midpoint = np.linspace(dx/2,b - dx/2,N) x_right = np.linspace(dx,b,N) print(\"Partition with\",N,\"subintervals.\") left_riemann_sum = np.sum(f(x_left) * dx) print(\"Left Riemann Sum:\",left_riemann_sum) midpoint_riemann_sum = np.sum(f(x_midpoint) * dx) print(\"Midpoint Riemann Sum:\",midpoint_riemann_sum) right_riemann_sum = np.sum(f(x_right) * dx) print(\"Right Riemann Sum:\",right_riemann_sum) Partition with 10 subintervals. Left Riemann Sum: 1.613488696614725 Midpoint Riemann Sum: 1.373543428316664 Right Riemann Sum: 1.1327194658454942 We know the exact value \\int_0^5 \\frac{1}{1 + x^2} dx = \\arctan(5) \\int_0^5 \\frac{1}{1 + x^2} dx = \\arctan(5) and we can compare the Riemann sums to the value I = np.arctan(5) print(I) 1.373400766945016 print(\"Left Riemann Sum Error:\",np.abs(left_riemann_sum - I)) print(\"Midpoint Riemann Sum:\",np.abs(midpoint_riemann_sum - I)) print(\"Right Riemann Sum:\",np.abs(right_riemann_sum - I)) Left Riemann Sum Error: 0.24008792966970915 Midpoint Riemann Sum: 0.00014266137164820059 Right Riemann Sum: 0.24068130109952168","title":"Definition"},{"location":"integration/riemann-sums/#error-formulas","text":"A Riemann sum is an approximation of a definite integral. A natural question arises: how good of an approximation is a Riemann sum? Theorem. Let L_N(f) L_N(f) denote the left Riemann sum L_N(f) = \\sum_{i=1}^N f(x_{i-1} ) \\Delta x L_N(f) = \\sum_{i=1}^N f(x_{i-1} ) \\Delta x where \\Delta x = (b-a)/N \\Delta x = (b-a)/N and x_i = a + i \\Delta x x_i = a + i \\Delta x . The error bound is E_N^{L}(f) = \\left| \\ \\int_a^b f(x) \\ dx - L_N(f) \\ \\right| \\leq \\frac{(b-a)^2}{2 N} K_1 E_N^{L}(f) = \\left| \\ \\int_a^b f(x) \\ dx - L_N(f) \\ \\right| \\leq \\frac{(b-a)^2}{2 N} K_1 where \\left| \\, f'(x) \\, \\right| \\leq K_1 \\left| \\, f'(x) \\, \\right| \\leq K_1 for all x \\in [a,b] x \\in [a,b] . Theorem. Let R_N(f) R_N(f) denote the right Riemann sum R_N(f) = \\sum_{i=1}^N f(x_{i} ) \\Delta x R_N(f) = \\sum_{i=1}^N f(x_{i} ) \\Delta x where \\Delta x = (b-a)/N \\Delta x = (b-a)/N and x_i = a + i \\Delta x x_i = a + i \\Delta x . The error bound is E_N^{R}(f) = \\left| \\ \\int_a^b f(x) \\ dx - R_N(f) \\ \\right| \\leq \\frac{(b-a)^2}{2 N} K_1 E_N^{R}(f) = \\left| \\ \\int_a^b f(x) \\ dx - R_N(f) \\ \\right| \\leq \\frac{(b-a)^2}{2 N} K_1 where \\left| \\, f'(x) \\, \\right| \\leq K_1 \\left| \\, f'(x) \\, \\right| \\leq K_1 for all x \\in [a,b] x \\in [a,b] . Theorem. Let M_N(f) M_N(f) denote the midpoint Riemann sum M_N(f) = \\sum_{i=1}^N f(x_i^* ) \\Delta x M_N(f) = \\sum_{i=1}^N f(x_i^* ) \\Delta x where \\Delta x = (b-a)/N \\Delta x = (b-a)/N and x_i^* = (x_{i-1} + x_i)/2 x_i^* = (x_{i-1} + x_i)/2 for x_i = a + i \\Delta x x_i = a + i \\Delta x . The error bound is E_N^{M}(f) = \\left| \\ \\int_a^b f(x) \\ dx - M_N(f) \\ \\right| \\leq \\frac{(b-a)^3}{24 N^2} K_2 E_N^{M}(f) = \\left| \\ \\int_a^b f(x) \\ dx - M_N(f) \\ \\right| \\leq \\frac{(b-a)^3}{24 N^2} K_2 where \\left| \\, f''(x) \\, \\right| \\leq K_2 \\left| \\, f''(x) \\, \\right| \\leq K_2 for all x \\in [a,b] x \\in [a,b] . There are several points to notice: Left and right Riemann sums have the same error bound which depends on the first derivative f'(x) f'(x) . Midpoint Riemann sum error bound depends on the second derivative f''(x) f''(x) . We expect the midpoint Riemann sum to give a better approximation as N \\to \\infty N \\to \\infty since its error bound is inversely proportional to N^2 N^2 but left/right Riemann sum error bound is inversely proportional only to N N .","title":"Error Formulas"},{"location":"integration/riemann-sums/#implementation","text":"Let's write a function called riemann_sum which takes 5 input parameters f , a , b , N and method and returns the Riemann sum \\sum_{i=1}^N f(x_i^*) \\Delta x \\sum_{i=1}^N f(x_i^*) \\Delta x where \\Delta x = (b-a)/N \\Delta x = (b-a)/N and x_i = a + i\\Delta x x_i = a + i\\Delta x defines a partition with N N subintervals of equal length , and method determines whether we use left endpoints, right endpoints or midpoints (with midpoints as the default method). def riemann_sum(f,a,b,N,method='midpoint'): '''Compute the Riemann sum of f(x) over the interval [a,b]. Parameters ---------- f : function Vectorized function of one variable a , b : numbers Endpoints of the interval [a,b] N : integer Number of subintervals of equal length in the partition of [a,b] method : string Determines the kind of Riemann sum: right : Riemann sum using right endpoints left : Riemann sum using left endpoints midpoint (default) : Riemann sum using midpoints Returns ------- float Approximation of the integral given by the Riemann sum. ''' dx = (b - a)/N x = np.linspace(a,b,N+1) if method == 'left': x_left = x[:-1] return np.sum(f(x_left)*dx) elif method == 'right': x_right = x[1:] return np.sum(f(x_right)*dx) elif method == 'midpoint': x_mid = (x[:-1] + x[1:])/2 return np.sum(f(x_mid)*dx) else: raise ValueError(\"Method must be 'left', 'right' or 'midpoint'.\") Let's test our function with inputs where we know exactly what the output should be. For example, we know \\int_0^{\\pi/2} \\sin(x) \\, dx = 1 \\int_0^{\\pi/2} \\sin(x) \\, dx = 1 and, since \\sin(x) \\sin(x) is increasing on [0,\\pi/2] [0,\\pi/2] , we know that left endpoints will give an under-estimate, and right endpoints will give an over-estimate. riemann_sum(np.sin,0,np.pi/2,100) 1.0000102809119054 riemann_sum(np.sin,0,np.pi/2,100,'right') 1.007833419873582 riemann_sum(np.sin,0,np.pi/2,100,'left') 0.992125456605633 We also know that \\int_0^1 x \\, dx = 1/2 \\int_0^1 x \\, dx = 1/2 and midpoint should give the result exactly for any N N : riemann_sum(lambda x : x,0,1,1) 0.5","title":"Implementation"},{"location":"integration/riemann-sums/#examples","text":"","title":"Examples"},{"location":"integration/riemann-sums/#approximate-pi","text":"Find a value N N which guarantees the right Riemann sum of f(x)=\\frac{4}{1 + x^2} f(x)=\\frac{4}{1 + x^2} over [0,1] [0,1] is within 10^{-5} 10^{-5} of the exact value \\int_0^1 \\frac{4}{1 + x^2} dx = \\pi \\int_0^1 \\frac{4}{1 + x^2} dx = \\pi Compute f'(x) = -\\frac{8x}{(1+x^2)^2} f'(x) = -\\frac{8x}{(1+x^2)^2} Use brute force optimization to find a bound on \\left| f'(x) \\right| \\left| f'(x) \\right| on [0,1] [0,1] : x = np.linspace(0,1,1000) y = np.abs(-8*x/(1 + x**2)**2) np.max(y) 2.5980759093919907 Therefore, \\left| f'(x) \\right| \\leq 2.6 \\left| f'(x) \\right| \\leq 2.6 for x \\in [0,1] x \\in [0,1] . Use the error bound \\frac{(b-a)^2}{2 N} K_1 \\leq 10^{-5} \\ \\Rightarrow \\ \\frac{1.3}{N} \\leq 10^{-5} \\ \\Rightarrow \\ 130000 \\leq N \\frac{(b-a)^2}{2 N} K_1 \\leq 10^{-5} \\ \\Rightarrow \\ \\frac{1.3}{N} \\leq 10^{-5} \\ \\Rightarrow \\ 130000 \\leq N Let's compute the right Riemann sum for N=130000 N=130000 : approximation = riemann_sum(lambda x : 4/(1 + x**2),0,1,130000,method='right') print(approximation) 3.1415849612722386 Verify the accuracy of the approximation np.abs(approximation - np.pi) < 10**(-5) True","title":"Approximate Pi"},{"location":"integration/riemann-sums/#approximate-ln2","text":"Find a value N N which guarantees the midpoint Riemann sum of f(x)=\\frac{1}{x} f(x)=\\frac{1}{x} over [1,2] [1,2] is within 10^{-8} 10^{-8} of the exact value \\int_1^2 \\frac{1}{x} dx = \\ln(2) \\int_1^2 \\frac{1}{x} dx = \\ln(2) Compute f''(x) = \\frac{2}{x^3} f''(x) = \\frac{2}{x^3} Since f''(x) f''(x) is decreasing for all x>0 x>0 we have \\left| \\, f''(x) \\, \\right| \\leq 2 \\left| \\, f''(x) \\, \\right| \\leq 2 for all x \\in [1,2] x \\in [1,2] . Use the error bound: \\frac{(b-a)^3}{24 N^2} K_2 \\leq 10^{-8} \\ \\Rightarrow \\ \\frac{1}{12 N^2} \\leq 10^{-8} \\ \\Rightarrow \\frac{10^4}{\\sqrt{12}} \\leq N \\frac{(b-a)^3}{24 N^2} K_2 \\leq 10^{-8} \\ \\Rightarrow \\ \\frac{1}{12 N^2} \\leq 10^{-8} \\ \\Rightarrow \\frac{10^4}{\\sqrt{12}} \\leq N 10**4 / np.sqrt(12) 2886.751345948129 Therefore a partition of size N=2887 N=2887 guarantees the desired accuracy: approximation = riemann_sum(lambda x : 1/x,1,2,2887,method='midpoint') print(approximation) 0.6931471768105913 Verify the accuracy of the approximation: np.abs(approximation - np.log(2)) < 10**(-8) True","title":"Approximate ln(2)"},{"location":"integration/riemann-sums/#exercises","text":"Consider the integral \\int_1^2 \\frac{dx}{1+x^3} \\int_1^2 \\frac{dx}{1+x^3} Without plotting the functions f(x) f(x) , f'(x) f'(x) or f''(x) f''(x) , find a value N N such that E_N^R(f) \\leq 10^{-5} E_N^R(f) \\leq 10^{-5} given f(x) = \\frac{1}{1 + x^3} \\ , \\ f'(x) = -\\frac{3 x^{2}}{\\left(x^{3} + 1\\right)^{2}} \\ , \\ f''(x) = \\frac{6 x \\left(2 x^{3} - 1\\right)}{\\left(x + 1\\right)^{3} \\left(x^{2} - x + 1\\right)^{3}} \\\\\\\\ f(x) = \\frac{1}{1 + x^3} \\ , \\ f'(x) = -\\frac{3 x^{2}}{\\left(x^{3} + 1\\right)^{2}} \\ , \\ f''(x) = \\frac{6 x \\left(2 x^{3} - 1\\right)}{\\left(x + 1\\right)^{3} \\left(x^{2} - x + 1\\right)^{3}} \\\\\\\\ Plot the function f''(x) f''(x) from the previous question on the interval [1,2] [1,2] and find a value N N such that E_N^M(f) \\leq 10^{-5} E_N^M(f) \\leq 10^{-5} for the integral in the previous question. Let f(x) = x^x f(x) = x^x and note that f'(x) = x^{x} \\left(\\log{\\left(x \\right)} + 1\\right) \\ , \\ f''(x) = x^{x} \\left(\\log{\\left(x \\right)} + 1\\right)^{2} + x^{x-1} f'(x) = x^{x} \\left(\\log{\\left(x \\right)} + 1\\right) \\ , \\ f''(x) = x^{x} \\left(\\log{\\left(x \\right)} + 1\\right)^{2} + x^{x-1} Plot the function f''(x) f''(x) and use that information to compute T_N(f) T_N(f) for the integral \\int_1^2 x^x \\, dx \\int_1^2 x^x \\, dx such that E_N^T(f) \\leq 10^{-3} E_N^T(f) \\leq 10^{-3} .","title":"Exercises"},{"location":"integration/simpsons-rule/","text":"Simpson's Rule import numpy as np import matplotlib.pyplot as plt %matplotlib inline Definition Simpson's rule uses a quadratic polynomial on each subinterval of a partition to approximate the function f(x) f(x) and to compute the definite integral. This is an improvement over the trapezoid rule which approximates f(x) f(x) by a straight line on each subinterval of a partition. The formula for Simpson's rule is S_N(f) = \\frac{\\Delta x}{3} \\sum_{i=1}^{N/2} \\left( f(x_{2i-2}) + 4 f(x_{2i-1}) + f(x_{2i}) \\right) S_N(f) = \\frac{\\Delta x}{3} \\sum_{i=1}^{N/2} \\left( f(x_{2i-2}) + 4 f(x_{2i-1}) + f(x_{2i}) \\right) where N N is an even number of subintervals of [a,b] [a,b] , \\Delta x = (b - a)/N \\Delta x = (b - a)/N and x_i = a + i \\Delta x x_i = a + i \\Delta x . Error Formula We have seen that the error in a Riemann sum is inversely proportional to the size of the partition N N and the trapezoid rule is inversely proportional to N^2 N^2 . The error formula in the theorem below shows that Simpson's rule is even better as the error is inversely proportional to N^4 N^4 . Theorem Let S_N(f) S_N(f) denote Simpson's rule S_N(f) = \\frac{\\Delta x}{3} \\sum_{i=1}^{N/2} \\left( f(x_{2i-2}) + 4 f(x_{2i-1}) + f(x_{2i}) \\right) S_N(f) = \\frac{\\Delta x}{3} \\sum_{i=1}^{N/2} \\left( f(x_{2i-2}) + 4 f(x_{2i-1}) + f(x_{2i}) \\right) where N N is an even number of subintervals of [a,b] [a,b] , \\Delta x = (b - a)/N \\Delta x = (b - a)/N and x_i = a + i \\Delta x x_i = a + i \\Delta x . The error bound is E_N^S(f) = \\left| \\ \\int_a^b f(x) \\, dx - S_N(f) \\ \\right| \\leq \\frac{(b-a)^5}{180N^4} K_4 E_N^S(f) = \\left| \\ \\int_a^b f(x) \\, dx - S_N(f) \\ \\right| \\leq \\frac{(b-a)^5}{180N^4} K_4 where \\left| \\ f^{(4)}(x) \\ \\right| \\leq K_4 \\left| \\ f^{(4)}(x) \\ \\right| \\leq K_4 for all x \\in [a,b] x \\in [a,b] . Implementation Let's write a function called simps which takes input parameters f f , a a , b b and N N and returns the approximation S_N(f) S_N(f) . Furthermore, let's assign a default value N=50 N=50 . def simps(f,a,b,N=50): '''Approximate the integral of f(x) from a to b by Simpson's rule. Simpson's rule approximates the integral \\int_a^b f(x) dx by the sum: (dx/3) \\sum_{k=1}^{N/2} (f(x_{2i-2} + 4f(x_{2i-1}) + f(x_{2i})) where x_i = a + i*dx and dx = (b - a)/N. Parameters ---------- f : function Vectorized function of a single variable a , b : numbers Interval of integration [a,b] N : (even) integer Number of subintervals of [a,b] Returns ------- float Approximation of the integral of f(x) from a to b using Simpson's rule with N subintervals of equal length. Examples -------- >>> simps(lambda x : 3*x**2,0,1,10) 1.0 ''' if N % 2 == 1: raise ValueError(\"N must be an even integer.\") dx = (b-a)/N x = np.linspace(a,b,N+1) y = f(x) S = dx/3 * np.sum(y[0:-1:2] + 4*y[1::2] + y[2::2]) return S Let's test our function on integrals for which we know the exact value. For example, we know \\int_0^1 3x^2 dx = 1 \\int_0^1 3x^2 dx = 1 simps(lambda x : 3*x**2,0,1,10) 1.0 Test our function again with the integral \\int_0^{\\pi/2} \\sin(x) dx = 1 \\int_0^{\\pi/2} \\sin(x) dx = 1 simps(np.sin,0,np.pi/2,100) 1.000000000338236 scipy.integrate.simps The SciPy subpackage scipy.integrate contains several functions for approximating definite integrals and numerically solving differential equations. Let's import the subpackage under the name spi . import scipy.integrate as spi The function scipy.integrate.simps computes the approximation of a definite integral by Simpson's rule. Consulting the documentation, we see that all we need to do it supply arrays of x x and y y values for the integrand and scipy.integrate.simps returns the approximation of the integral using Simpson's rule. Examples Approximate ln(2) Find a value N N which guarantees that Simpson's rule approximation S_N(f) S_N(f) of the integral \\int_1^2 \\frac{1}{x} dx \\int_1^2 \\frac{1}{x} dx satisfies E_N^S(f) \\leq 0.0001 E_N^S(f) \\leq 0.0001 . Compute f^{(4)}(x) = \\frac{24}{x^5} f^{(4)}(x) = \\frac{24}{x^5} therefore \\left| \\, f^{(4)}(x) \\, \\right| \\leq 24 \\left| \\, f^{(4)}(x) \\, \\right| \\leq 24 for all x \\in [1,2] x \\in [1,2] and so \\frac{1}{180N^4} 24 \\leq 0.0001 \\ \\Rightarrow \\ \\frac{20000}{15N^4} \\leq 1 \\ \\Rightarrow \\ \\left( \\frac{20000}{15} \\right)^{1/4} \\leq N \\frac{1}{180N^4} 24 \\leq 0.0001 \\ \\Rightarrow \\ \\frac{20000}{15N^4} \\leq 1 \\ \\Rightarrow \\ \\left( \\frac{20000}{15} \\right)^{1/4} \\leq N Compute (20000/15)**0.25 6.042750794713537 Compute Simpson's rule with N=8 N=8 (the smallest even integer greater than 6.04) approximation = simps(lambda x : 1/x,1,2,8) print(approximation) 0.6931545306545306 We could also use the function scipy.integrate.simps to compute the exact same result N = 8; a = 1; b = 2; x = np.linspace(a,b,N+1) y = 1/x approximation = spi.simps(y,x) print(approximation) 0.6931545306545306 Verify that E_N^S(f) \\leq 0.0001 E_N^S(f) \\leq 0.0001 np.abs(np.log(2) - approximation) <= 0.0001 True Exercises Under construction","title":"Simpson's Rule"},{"location":"integration/simpsons-rule/#simpsons-rule","text":"import numpy as np import matplotlib.pyplot as plt %matplotlib inline","title":"Simpson's Rule"},{"location":"integration/simpsons-rule/#definition","text":"Simpson's rule uses a quadratic polynomial on each subinterval of a partition to approximate the function f(x) f(x) and to compute the definite integral. This is an improvement over the trapezoid rule which approximates f(x) f(x) by a straight line on each subinterval of a partition. The formula for Simpson's rule is S_N(f) = \\frac{\\Delta x}{3} \\sum_{i=1}^{N/2} \\left( f(x_{2i-2}) + 4 f(x_{2i-1}) + f(x_{2i}) \\right) S_N(f) = \\frac{\\Delta x}{3} \\sum_{i=1}^{N/2} \\left( f(x_{2i-2}) + 4 f(x_{2i-1}) + f(x_{2i}) \\right) where N N is an even number of subintervals of [a,b] [a,b] , \\Delta x = (b - a)/N \\Delta x = (b - a)/N and x_i = a + i \\Delta x x_i = a + i \\Delta x .","title":"Definition"},{"location":"integration/simpsons-rule/#error-formula","text":"We have seen that the error in a Riemann sum is inversely proportional to the size of the partition N N and the trapezoid rule is inversely proportional to N^2 N^2 . The error formula in the theorem below shows that Simpson's rule is even better as the error is inversely proportional to N^4 N^4 . Theorem Let S_N(f) S_N(f) denote Simpson's rule S_N(f) = \\frac{\\Delta x}{3} \\sum_{i=1}^{N/2} \\left( f(x_{2i-2}) + 4 f(x_{2i-1}) + f(x_{2i}) \\right) S_N(f) = \\frac{\\Delta x}{3} \\sum_{i=1}^{N/2} \\left( f(x_{2i-2}) + 4 f(x_{2i-1}) + f(x_{2i}) \\right) where N N is an even number of subintervals of [a,b] [a,b] , \\Delta x = (b - a)/N \\Delta x = (b - a)/N and x_i = a + i \\Delta x x_i = a + i \\Delta x . The error bound is E_N^S(f) = \\left| \\ \\int_a^b f(x) \\, dx - S_N(f) \\ \\right| \\leq \\frac{(b-a)^5}{180N^4} K_4 E_N^S(f) = \\left| \\ \\int_a^b f(x) \\, dx - S_N(f) \\ \\right| \\leq \\frac{(b-a)^5}{180N^4} K_4 where \\left| \\ f^{(4)}(x) \\ \\right| \\leq K_4 \\left| \\ f^{(4)}(x) \\ \\right| \\leq K_4 for all x \\in [a,b] x \\in [a,b] .","title":"Error Formula"},{"location":"integration/simpsons-rule/#implementation","text":"Let's write a function called simps which takes input parameters f f , a a , b b and N N and returns the approximation S_N(f) S_N(f) . Furthermore, let's assign a default value N=50 N=50 . def simps(f,a,b,N=50): '''Approximate the integral of f(x) from a to b by Simpson's rule. Simpson's rule approximates the integral \\int_a^b f(x) dx by the sum: (dx/3) \\sum_{k=1}^{N/2} (f(x_{2i-2} + 4f(x_{2i-1}) + f(x_{2i})) where x_i = a + i*dx and dx = (b - a)/N. Parameters ---------- f : function Vectorized function of a single variable a , b : numbers Interval of integration [a,b] N : (even) integer Number of subintervals of [a,b] Returns ------- float Approximation of the integral of f(x) from a to b using Simpson's rule with N subintervals of equal length. Examples -------- >>> simps(lambda x : 3*x**2,0,1,10) 1.0 ''' if N % 2 == 1: raise ValueError(\"N must be an even integer.\") dx = (b-a)/N x = np.linspace(a,b,N+1) y = f(x) S = dx/3 * np.sum(y[0:-1:2] + 4*y[1::2] + y[2::2]) return S Let's test our function on integrals for which we know the exact value. For example, we know \\int_0^1 3x^2 dx = 1 \\int_0^1 3x^2 dx = 1 simps(lambda x : 3*x**2,0,1,10) 1.0 Test our function again with the integral \\int_0^{\\pi/2} \\sin(x) dx = 1 \\int_0^{\\pi/2} \\sin(x) dx = 1 simps(np.sin,0,np.pi/2,100) 1.000000000338236","title":"Implementation"},{"location":"integration/simpsons-rule/#scipyintegratesimps","text":"The SciPy subpackage scipy.integrate contains several functions for approximating definite integrals and numerically solving differential equations. Let's import the subpackage under the name spi . import scipy.integrate as spi The function scipy.integrate.simps computes the approximation of a definite integral by Simpson's rule. Consulting the documentation, we see that all we need to do it supply arrays of x x and y y values for the integrand and scipy.integrate.simps returns the approximation of the integral using Simpson's rule.","title":"scipy.integrate.simps"},{"location":"integration/simpsons-rule/#examples","text":"","title":"Examples"},{"location":"integration/simpsons-rule/#approximate-ln2","text":"Find a value N N which guarantees that Simpson's rule approximation S_N(f) S_N(f) of the integral \\int_1^2 \\frac{1}{x} dx \\int_1^2 \\frac{1}{x} dx satisfies E_N^S(f) \\leq 0.0001 E_N^S(f) \\leq 0.0001 . Compute f^{(4)}(x) = \\frac{24}{x^5} f^{(4)}(x) = \\frac{24}{x^5} therefore \\left| \\, f^{(4)}(x) \\, \\right| \\leq 24 \\left| \\, f^{(4)}(x) \\, \\right| \\leq 24 for all x \\in [1,2] x \\in [1,2] and so \\frac{1}{180N^4} 24 \\leq 0.0001 \\ \\Rightarrow \\ \\frac{20000}{15N^4} \\leq 1 \\ \\Rightarrow \\ \\left( \\frac{20000}{15} \\right)^{1/4} \\leq N \\frac{1}{180N^4} 24 \\leq 0.0001 \\ \\Rightarrow \\ \\frac{20000}{15N^4} \\leq 1 \\ \\Rightarrow \\ \\left( \\frac{20000}{15} \\right)^{1/4} \\leq N Compute (20000/15)**0.25 6.042750794713537 Compute Simpson's rule with N=8 N=8 (the smallest even integer greater than 6.04) approximation = simps(lambda x : 1/x,1,2,8) print(approximation) 0.6931545306545306 We could also use the function scipy.integrate.simps to compute the exact same result N = 8; a = 1; b = 2; x = np.linspace(a,b,N+1) y = 1/x approximation = spi.simps(y,x) print(approximation) 0.6931545306545306 Verify that E_N^S(f) \\leq 0.0001 E_N^S(f) \\leq 0.0001 np.abs(np.log(2) - approximation) <= 0.0001 True","title":"Approximate ln(2)"},{"location":"integration/simpsons-rule/#exercises","text":"Under construction","title":"Exercises"},{"location":"integration/trapezoid-rule/","text":"Trapezoid Rule import numpy as np import matplotlib.pyplot as plt %matplotlib inline Trapezoids The definite integral of f(x) f(x) is equal to the (net) area under the curve y=f(x) y=f(x) over the interval [a,b] [a,b] . Riemann sums approximate definite integrals by using sums of rectangles to approximate the area. The trapezoid rule gives a better approximation of a definite integral by summing the areas of the trapezoids connecting the points (x_{i-1},0), (x_i,0), (x_{i-1},f(x_{i-1})), (x_i,f(x_i)) (x_{i-1},0), (x_i,0), (x_{i-1},f(x_{i-1})), (x_i,f(x_i)) for each subinterval [x_{i-1},x_i] [x_{i-1},x_i] of a partition. Note that the area of each trapezoid is the sum of a rectangle and a triangle (x_i - x_{i-1}) f(x_{i-1}) + \\frac{1}{2}(x_i - x_{i-1}) (f(x_i) - f(x_{i-1})) = \\frac{1}{2}(f(x_i) + f(x_{i-1}))(x_i - x_{i-1}) (x_i - x_{i-1}) f(x_{i-1}) + \\frac{1}{2}(x_i - x_{i-1}) (f(x_i) - f(x_{i-1})) = \\frac{1}{2}(f(x_i) + f(x_{i-1}))(x_i - x_{i-1}) For example, we can use a single trapezoid to approximate: \\int_0^1 e^{-x^2} \\, dx \\int_0^1 e^{-x^2} \\, dx First, let's plot the curve y = e^{-x^2} y = e^{-x^2} and the trapezoid on the interval [0,1] [0,1] : x = np.linspace(-0.5,1.5,100) y = np.exp(-x**2) plt.plot(x,y) x0 = 0; x1 = 1; y0 = np.exp(-x0**2); y1 = np.exp(-x1**2); plt.fill_between([x0,x1],[y0,y1]) plt.xlim([-0.5,1.5]); plt.ylim([0,1.5]); plt.show() Approximate the integral by the area of the trapezoid: A = 0.5*(y1 + y0)*(x1 - x0) print(\"Trapezoid area:\", A) Trapezoid area: 0.6839397205857212 Definition The trapezoid rule for N N subintervals of [a,b] [a,b] of equal length is T_N(f) = \\frac{\\Delta x}{2} \\sum_{i=1}^N (f(x_i) + f(x_{i-1})) T_N(f) = \\frac{\\Delta x}{2} \\sum_{i=1}^N (f(x_i) + f(x_{i-1})) where \\Delta x = (b - a)/N \\Delta x = (b - a)/N is the length of the subintervals and x_i = a + i \\Delta x x_i = a + i \\Delta x . Notice that the trapezoid is the average of the left and right Riemann sums T_N(f) = \\frac{\\Delta x}{2} \\sum_{i=1}^N (f(x_i) + f(x_{i-1})) = \\frac{1}{2} \\left( \\sum_{i=1}^N f(x_i) \\Delta x + \\sum_{i=1}^N f(x_{i-1}) \\Delta x \\right) T_N(f) = \\frac{\\Delta x}{2} \\sum_{i=1}^N (f(x_i) + f(x_{i-1})) = \\frac{1}{2} \\left( \\sum_{i=1}^N f(x_i) \\Delta x + \\sum_{i=1}^N f(x_{i-1}) \\Delta x \\right) Error Formula When computing integrals numerically, it is essential to know how good our approximations are. Notice in the theorem below that the error formula is inversely proportional to N^2 N^2 . This means that the error decreases much faster with larger N N compared to Riemann sums. Theorem. Let T_N(f) T_N(f) denote the trapezoid rule T_N(f) = \\frac{\\Delta x}{2} \\sum_{i=1}^N (f(x_i) + f(x_{i-1})) T_N(f) = \\frac{\\Delta x}{2} \\sum_{i=1}^N (f(x_i) + f(x_{i-1})) where \\Delta x = (b-a)/N \\Delta x = (b-a)/N and x_i = a + i \\Delta x x_i = a + i \\Delta x . The error bound is E_N^T(f) = \\left| \\ \\int_a^b f(x) \\ dx - T_N(f) \\ \\right| \\leq \\frac{(b-a)^3}{12 N^2} K_2 E_N^T(f) = \\left| \\ \\int_a^b f(x) \\ dx - T_N(f) \\ \\right| \\leq \\frac{(b-a)^3}{12 N^2} K_2 where \\left| \\ f''(x) \\, \\right| \\leq K_2 \\left| \\ f''(x) \\, \\right| \\leq K_2 for all x \\in [a,b] x \\in [a,b] . Implementation Let's write a function called trapz which takes input parameters f f , a a , b b and N N and returns the approximation T_N(f) T_N(f) . Furthermore, let's assign default value N=50 N=50 . def trapz(f,a,b,N=50): '''Approximate the integral of f(x) from a to b by the trapezoid rule. The trapezoid rule approximates the integral \\int_a^b f(x) dx by the sum: (dx/2) \\sum_{k=1}^N (f(x_k) + f(x_{k-1})) where x_k = a + k*dx and dx = (b - a)/N. Parameters ---------- f : function Vectorized function of a single variable a , b : numbers Interval of integration [a,b] N : integer Number of subintervals of [a,b] Returns ------- float Approximation of the integral of f(x) from a to b using the trapezoid rule with N subintervals of equal length. Examples -------- >>> trapz(np.sin,0,np.pi/2,1000) 0.9999997943832332 ''' x = np.linspace(a,b,N+1) # N+1 points make N subintervals y = f(x) y_right = y[1:] # right endpoints y_left = y[:-1] # left endpoints dx = (b - a)/N T = (dx/2) * np.sum(y_right + y_left) return T Let's test our function on an integral where we know the answer \\int_0^{\\pi/2} \\sin x \\ dx = 1 \\int_0^{\\pi/2} \\sin x \\ dx = 1 trapz(np.sin,0,np.pi/2,1000) 0.9999997943832332 Let's test our function again: \\int_0^1 3 x^2 \\ dx = 1 \\int_0^1 3 x^2 \\ dx = 1 trapz(lambda x : 3*x**2,0,1,10000) 1.0000000050000002 And once more: \\int_0^1 x \\ dx = \\frac{1}{2} \\int_0^1 x \\ dx = \\frac{1}{2} trapz(lambda x : x,0,1,1) 0.5 scipy.integrate.trapz The SciPy subpackage scipy.integrate contains several functions for approximating definite integrals and numerically solving differential equations. Let's import the subpackage under the name spi . import scipy.integrate as spi The function scipy.integrate.trapz computes the approximation of a definite by the trapezoid rule. Consulting the documentation, we see that all we need to do it supply arrays of x x and y y values for the integrand and scipy.integrate.trapz returns the approximation of the integral using the trapezoid rule. The number of points we give to scipy.integrate.trapz is up to us but we have to remember that more points gives a better approximation but it takes more time to compute! Examples Arctangent Let's plot the trapezoids for \\displaystyle f(x)=\\frac{1}{1 + x^2} \\displaystyle f(x)=\\frac{1}{1 + x^2} on [0,5] [0,5] with N=10 N=10 . f = lambda x : 1/(1 + x**2) a = 0; b = 5; N = 10 # x and y values for the trapezoid rule x = np.linspace(a,b,N+1) y = f(x) # X and Y values for plotting y=f(x) X = np.linspace(a,b,100) Y = f(X) plt.plot(X,Y) for i in range(N): xs = [x[i],x[i],x[i+1],x[i+1]] ys = [0,f(x[i]),f(x[i+1]),0] plt.fill(xs,ys,'b',edgecolor='b',alpha=0.2) plt.title('Trapezoid Rule, N = {}'.format(N)) plt.show() Let's compute the sum of areas of the trapezoids: T = trapz(f,a,b,N) print(T) 1.3731040812301096 We know the exact value \\int_0^5 \\frac{1}{1 + x^2} dx = \\arctan(5) \\int_0^5 \\frac{1}{1 + x^2} dx = \\arctan(5) and we can compare the trapezoid rule to the value I = np.arctan(5) print(I) 1.373400766945016 print(\"Trapezoid Rule Error:\",np.abs(I - T)) Trapezoid Rule Error: 0.00029668571490626405 Approximate ln(2) Find a value N N which guarantees that the trapezoid rule approximation T_N(f) T_N(f) of the integral \\int_1^2 \\frac{1}{x} \\, dx = \\ln(2) \\int_1^2 \\frac{1}{x} \\, dx = \\ln(2) satisfies E_N^T(f) \\leq 10^{-8} E_N^T(f) \\leq 10^{-8} . For f(x) = \\frac{1}{x} f(x) = \\frac{1}{x} , we compute f''(x) = \\frac{2}{x^3} \\leq 2 f''(x) = \\frac{2}{x^3} \\leq 2 for all x \\in [1,2] x \\in [1,2] therefore the error formula implies \\left| \\, \\int_1^2 \\frac{1}{x} \\, dx - T_N(f) \\, \\right| \\leq \\frac{2}{12N^2} \\left| \\, \\int_1^2 \\frac{1}{x} \\, dx - T_N(f) \\, \\right| \\leq \\frac{2}{12N^2} Then E_N^T \\leq 10^{-8} E_N^T \\leq 10^{-8} is guaranteed if \\frac{1}{6N^2} \\leq 10^{-8} \\frac{1}{6N^2} \\leq 10^{-8} which implies \\frac{10^4}{\\sqrt{6}} \\leq N \\frac{10^4}{\\sqrt{6}} \\leq N 10**4/np.sqrt(6) 4082.4829046386303 We need 4083 subintervals to guarantee E_N^T(f) \\leq 10^{-8} E_N^T(f) \\leq 10^{-8} . Compute the approximation using our own implementation of the trapezoid rule: approximation = trapz(lambda x : 1/x,1,2,4083) print(approximation) 0.6931471843089954 We could also use scipy.integrate.trapz to get the exact same result: N = 4083 x = np.linspace(1,2,N+1) y = 1/x approximation = spi.trapz(y,x) print(approximation) 0.6931471843089955 Let's verify that this is within 10^{-6} 10^{-6} : np.abs(approximation - np.log(2)) < 10**(-8) True Success! However, a natural question arises: what is the actual smallest N N such that the trapezoid rule gives the estimate of \\ln (2) \\ln (2) to within 10^{-8} 10^{-8} ? for n in range(1,4083): approx = trapz(lambda x : 1/x,1,2,n) if np.abs(approx - np.log(2)) < 10e-8: print(\"Accuracy achieved at N =\",n) break Accuracy achieved at N = 791 Fresnel Integral Fresnel integrals are examples of nonelementary integrals : antiderivatives which cannot be written in terms of elementary functions . There are two types of Fresnel integrals: S(t) = \\int_0^t \\sin(x^2) dx \\ \\ \\text{and} \\ \\ C(t) = \\int_0^t \\cos(x^2) dx S(t) = \\int_0^t \\sin(x^2) dx \\ \\ \\text{and} \\ \\ C(t) = \\int_0^t \\cos(x^2) dx Use the trapezoid rule to approximate the Fresnel integral S(1) = \\int_0^1 \\sin(x^2) dx S(1) = \\int_0^1 \\sin(x^2) dx such that the error is less than 10^{-5} 10^{-5} . Compute the derivatives of the integrand f(x) = \\sin(x^2) \\ \\ , \\ \\ f'(x) = 2x\\cos(x^2) f(x) = \\sin(x^2) \\ \\ , \\ \\ f'(x) = 2x\\cos(x^2) f''(x) = 2\\cos(x^2) - 4x^2\\sin(x^2) \\ \\ , \\ \\ f'''(x) = -12x\\sin(x^2) - 8x^3\\cos(x^2) f''(x) = 2\\cos(x^2) - 4x^2\\sin(x^2) \\ \\ , \\ \\ f'''(x) = -12x\\sin(x^2) - 8x^3\\cos(x^2) Since f'''(x) \\leq 0 f'''(x) \\leq 0 for x \\in [0,1] x \\in [0,1] , we see that f''(x) f''(x) is decreasing on [0,1] [0,1] . Values of f''(x) f''(x) at the endpoints of the interval are x = 0 2*np.cos(x**2) - 4*x**2*np.sin(x**2) 2.0 x = 1 2*np.cos(x**2) - 4*x**2*np.sin(x**2) -2.2852793274953065 Therefore \\left| \\, f''(x) \\, \\right| \\leq 2.2852793274953065 \\left| \\, f''(x) \\, \\right| \\leq 2.2852793274953065 for x \\in [0,1] x \\in [0,1] . Use the error bound formula to find a good choice for N N \\frac{(b-a)^3}{12 N^2} K_2 \\leq 10^{-5} \\Rightarrow \\sqrt{\\frac{10^5(2.2852793274953065)}{12}} \\leq N \\frac{(b-a)^3}{12 N^2} K_2 \\leq 10^{-5} \\Rightarrow \\sqrt{\\frac{10^5(2.2852793274953065)}{12}} \\leq N np.sqrt(10**5 * 2.2852793274953065 / 12) 137.9999796949051 Let's compute the integral using the trapezoid rule with N=138 N=138 subintervals x = np.linspace(0,1,139) y = np.sin(x**2) I = spi.trapz(y,x) print(I) 0.31027303032220394 Therefore the Fresnel integral S(1) S(1) is approximately S(1) = \\int_0^1 \\sin(x^2) \\, dx \\approx 0.310273030322 S(1) = \\int_0^1 \\sin(x^2) \\, dx \\approx 0.310273030322 with error less than 10^{-5} 10^{-5} . Logarithmic Integral The Eulerian logarithmic integral is another nonelementary integral \\mathrm{Li}(t) = \\int_2^t \\frac{1}{\\ln x} dx \\mathrm{Li}(t) = \\int_2^t \\frac{1}{\\ln x} dx Let's compute Li(10) Li(10) such that the error is less than 10^{-4} 10^{-4} . Compute derivatives of the integrand f(x) = \\frac{1}{\\ln x} \\ \\ , \\ \\ f'(x) = -\\frac{1}{x(\\ln x)^2} \\ \\ , \\ \\ f''(x) = \\frac{\\ln x + 2 }{x^2(\\ln x)^3} f(x) = \\frac{1}{\\ln x} \\ \\ , \\ \\ f'(x) = -\\frac{1}{x(\\ln x)^2} \\ \\ , \\ \\ f''(x) = \\frac{\\ln x + 2 }{x^2(\\ln x)^3} Plot f''(x) f''(x) on the interval [2,10] [2,10] . a = 2 b = 10 x = np.linspace(a,b,100) y = (np.log(x) + 2) / (x**2 * np.log(x)**3) plt.plot(x,y) plt.show() Clearly f''(x) f''(x) is decreasing on [2,10] [2,10] (and bounded below by 0) therefore the absolute maximum occurs at the left endpoint: \\left| \\, f''(x) \\, \\right| \\leq \\frac{\\ln (2) + 2}{4 \\ln (2)^3} \\left| \\, f''(x) \\, \\right| \\leq \\frac{\\ln (2) + 2}{4 \\ln (2)^3} for x \\in [2,10] x \\in [2,10] and we compute K2 = (np.log(2) + 2)/(4*np.log(2)**3) print(K2) 2.021732598829855 Use the error formula: \\frac{(b-a)^3}{12 N^2} K_2 \\leq 10^{-4} \\Rightarrow \\frac{8^3}{12 N^2} 2.021732598829855 \\leq 10^{-4} \\Rightarrow \\sqrt{ \\frac{8^3 10^4}{12} 2.021732598829855} \\leq N \\frac{(b-a)^3}{12 N^2} K_2 \\leq 10^{-4} \\Rightarrow \\frac{8^3}{12 N^2} 2.021732598829855 \\leq 10^{-4} \\Rightarrow \\sqrt{ \\frac{8^3 10^4}{12} 2.021732598829855} \\leq N np.sqrt(8**3 * 10**4 * 2.021732598829855 / 12) 928.7657986995814 Compute the trapzoid rule with N=929 N=929 N = 929 x = np.linspace(a,b,N+1) y = 1/np.log(x) I = spi.trapz(y,x) print(I) 5.120442039184057 Therefore the Eulerian logarithmic integral is \\mathrm{Li}(10) = \\int_2^{10} \\frac{1}{\\ln x} dx \\approx 5.121065367200469 \\mathrm{Li}(10) = \\int_2^{10} \\frac{1}{\\ln x} dx \\approx 5.121065367200469 such that the error is less than 10^{-4} 10^{-4} . Exercises Let f(x) = x^x f(x) = x^x and note that f'(x) = x^{x} \\left(\\log{\\left(x \\right)} + 1\\right) \\ , \\ f''(x) = x^{x} \\left(\\log{\\left(x \\right)} + 1\\right)^{2} + x^{x-1} f'(x) = x^{x} \\left(\\log{\\left(x \\right)} + 1\\right) \\ , \\ f''(x) = x^{x} \\left(\\log{\\left(x \\right)} + 1\\right)^{2} + x^{x-1} Plot the function f''(x) f''(x) and use that information to compute T_N(f) T_N(f) for the integral \\int_1^2 x^x \\, dx \\int_1^2 x^x \\, dx such that E_N^T(f) \\leq 10^{-3} E_N^T(f) \\leq 10^{-3} . Consider the integral \\int_0^1 \\ln(1+x^2) \\, dx \\int_0^1 \\ln(1+x^2) \\, dx and note that f(x) = \\ln(1 + x^2) \\hspace{1in} f'(x) = \\frac{2x}{1 + x^2} $$ $$ f''(x) = 2 \\left( \\frac{1 - x^2}{1 + x^2} \\right) \\hspace{1in} f'''(x) = 4x \\frac{x^2 - 3}{(x^2 + 1)^3} f(x) = \\ln(1 + x^2) \\hspace{1in} f'(x) = \\frac{2x}{1 + x^2} $$ $$ f''(x) = 2 \\left( \\frac{1 - x^2}{1 + x^2} \\right) \\hspace{1in} f'''(x) = 4x \\frac{x^2 - 3}{(x^2 + 1)^3} Without plotting the functions f(x) f(x) , f'(x) f'(x) , f''(x) f''(x) or f'''(x) f'''(x) , find a value N N such that E_N^T(f) \\leq 10^{-6} E_N^T(f) \\leq 10^{-6} .","title":"Trapezoid Rule"},{"location":"integration/trapezoid-rule/#trapezoid-rule","text":"import numpy as np import matplotlib.pyplot as plt %matplotlib inline","title":"Trapezoid Rule"},{"location":"integration/trapezoid-rule/#trapezoids","text":"The definite integral of f(x) f(x) is equal to the (net) area under the curve y=f(x) y=f(x) over the interval [a,b] [a,b] . Riemann sums approximate definite integrals by using sums of rectangles to approximate the area. The trapezoid rule gives a better approximation of a definite integral by summing the areas of the trapezoids connecting the points (x_{i-1},0), (x_i,0), (x_{i-1},f(x_{i-1})), (x_i,f(x_i)) (x_{i-1},0), (x_i,0), (x_{i-1},f(x_{i-1})), (x_i,f(x_i)) for each subinterval [x_{i-1},x_i] [x_{i-1},x_i] of a partition. Note that the area of each trapezoid is the sum of a rectangle and a triangle (x_i - x_{i-1}) f(x_{i-1}) + \\frac{1}{2}(x_i - x_{i-1}) (f(x_i) - f(x_{i-1})) = \\frac{1}{2}(f(x_i) + f(x_{i-1}))(x_i - x_{i-1}) (x_i - x_{i-1}) f(x_{i-1}) + \\frac{1}{2}(x_i - x_{i-1}) (f(x_i) - f(x_{i-1})) = \\frac{1}{2}(f(x_i) + f(x_{i-1}))(x_i - x_{i-1}) For example, we can use a single trapezoid to approximate: \\int_0^1 e^{-x^2} \\, dx \\int_0^1 e^{-x^2} \\, dx First, let's plot the curve y = e^{-x^2} y = e^{-x^2} and the trapezoid on the interval [0,1] [0,1] : x = np.linspace(-0.5,1.5,100) y = np.exp(-x**2) plt.plot(x,y) x0 = 0; x1 = 1; y0 = np.exp(-x0**2); y1 = np.exp(-x1**2); plt.fill_between([x0,x1],[y0,y1]) plt.xlim([-0.5,1.5]); plt.ylim([0,1.5]); plt.show() Approximate the integral by the area of the trapezoid: A = 0.5*(y1 + y0)*(x1 - x0) print(\"Trapezoid area:\", A) Trapezoid area: 0.6839397205857212","title":"Trapezoids"},{"location":"integration/trapezoid-rule/#definition","text":"The trapezoid rule for N N subintervals of [a,b] [a,b] of equal length is T_N(f) = \\frac{\\Delta x}{2} \\sum_{i=1}^N (f(x_i) + f(x_{i-1})) T_N(f) = \\frac{\\Delta x}{2} \\sum_{i=1}^N (f(x_i) + f(x_{i-1})) where \\Delta x = (b - a)/N \\Delta x = (b - a)/N is the length of the subintervals and x_i = a + i \\Delta x x_i = a + i \\Delta x . Notice that the trapezoid is the average of the left and right Riemann sums T_N(f) = \\frac{\\Delta x}{2} \\sum_{i=1}^N (f(x_i) + f(x_{i-1})) = \\frac{1}{2} \\left( \\sum_{i=1}^N f(x_i) \\Delta x + \\sum_{i=1}^N f(x_{i-1}) \\Delta x \\right) T_N(f) = \\frac{\\Delta x}{2} \\sum_{i=1}^N (f(x_i) + f(x_{i-1})) = \\frac{1}{2} \\left( \\sum_{i=1}^N f(x_i) \\Delta x + \\sum_{i=1}^N f(x_{i-1}) \\Delta x \\right)","title":"Definition"},{"location":"integration/trapezoid-rule/#error-formula","text":"When computing integrals numerically, it is essential to know how good our approximations are. Notice in the theorem below that the error formula is inversely proportional to N^2 N^2 . This means that the error decreases much faster with larger N N compared to Riemann sums. Theorem. Let T_N(f) T_N(f) denote the trapezoid rule T_N(f) = \\frac{\\Delta x}{2} \\sum_{i=1}^N (f(x_i) + f(x_{i-1})) T_N(f) = \\frac{\\Delta x}{2} \\sum_{i=1}^N (f(x_i) + f(x_{i-1})) where \\Delta x = (b-a)/N \\Delta x = (b-a)/N and x_i = a + i \\Delta x x_i = a + i \\Delta x . The error bound is E_N^T(f) = \\left| \\ \\int_a^b f(x) \\ dx - T_N(f) \\ \\right| \\leq \\frac{(b-a)^3}{12 N^2} K_2 E_N^T(f) = \\left| \\ \\int_a^b f(x) \\ dx - T_N(f) \\ \\right| \\leq \\frac{(b-a)^3}{12 N^2} K_2 where \\left| \\ f''(x) \\, \\right| \\leq K_2 \\left| \\ f''(x) \\, \\right| \\leq K_2 for all x \\in [a,b] x \\in [a,b] .","title":"Error Formula"},{"location":"integration/trapezoid-rule/#implementation","text":"Let's write a function called trapz which takes input parameters f f , a a , b b and N N and returns the approximation T_N(f) T_N(f) . Furthermore, let's assign default value N=50 N=50 . def trapz(f,a,b,N=50): '''Approximate the integral of f(x) from a to b by the trapezoid rule. The trapezoid rule approximates the integral \\int_a^b f(x) dx by the sum: (dx/2) \\sum_{k=1}^N (f(x_k) + f(x_{k-1})) where x_k = a + k*dx and dx = (b - a)/N. Parameters ---------- f : function Vectorized function of a single variable a , b : numbers Interval of integration [a,b] N : integer Number of subintervals of [a,b] Returns ------- float Approximation of the integral of f(x) from a to b using the trapezoid rule with N subintervals of equal length. Examples -------- >>> trapz(np.sin,0,np.pi/2,1000) 0.9999997943832332 ''' x = np.linspace(a,b,N+1) # N+1 points make N subintervals y = f(x) y_right = y[1:] # right endpoints y_left = y[:-1] # left endpoints dx = (b - a)/N T = (dx/2) * np.sum(y_right + y_left) return T Let's test our function on an integral where we know the answer \\int_0^{\\pi/2} \\sin x \\ dx = 1 \\int_0^{\\pi/2} \\sin x \\ dx = 1 trapz(np.sin,0,np.pi/2,1000) 0.9999997943832332 Let's test our function again: \\int_0^1 3 x^2 \\ dx = 1 \\int_0^1 3 x^2 \\ dx = 1 trapz(lambda x : 3*x**2,0,1,10000) 1.0000000050000002 And once more: \\int_0^1 x \\ dx = \\frac{1}{2} \\int_0^1 x \\ dx = \\frac{1}{2} trapz(lambda x : x,0,1,1) 0.5","title":"Implementation"},{"location":"integration/trapezoid-rule/#scipyintegratetrapz","text":"The SciPy subpackage scipy.integrate contains several functions for approximating definite integrals and numerically solving differential equations. Let's import the subpackage under the name spi . import scipy.integrate as spi The function scipy.integrate.trapz computes the approximation of a definite by the trapezoid rule. Consulting the documentation, we see that all we need to do it supply arrays of x x and y y values for the integrand and scipy.integrate.trapz returns the approximation of the integral using the trapezoid rule. The number of points we give to scipy.integrate.trapz is up to us but we have to remember that more points gives a better approximation but it takes more time to compute!","title":"scipy.integrate.trapz"},{"location":"integration/trapezoid-rule/#examples","text":"","title":"Examples"},{"location":"integration/trapezoid-rule/#arctangent","text":"Let's plot the trapezoids for \\displaystyle f(x)=\\frac{1}{1 + x^2} \\displaystyle f(x)=\\frac{1}{1 + x^2} on [0,5] [0,5] with N=10 N=10 . f = lambda x : 1/(1 + x**2) a = 0; b = 5; N = 10 # x and y values for the trapezoid rule x = np.linspace(a,b,N+1) y = f(x) # X and Y values for plotting y=f(x) X = np.linspace(a,b,100) Y = f(X) plt.plot(X,Y) for i in range(N): xs = [x[i],x[i],x[i+1],x[i+1]] ys = [0,f(x[i]),f(x[i+1]),0] plt.fill(xs,ys,'b',edgecolor='b',alpha=0.2) plt.title('Trapezoid Rule, N = {}'.format(N)) plt.show() Let's compute the sum of areas of the trapezoids: T = trapz(f,a,b,N) print(T) 1.3731040812301096 We know the exact value \\int_0^5 \\frac{1}{1 + x^2} dx = \\arctan(5) \\int_0^5 \\frac{1}{1 + x^2} dx = \\arctan(5) and we can compare the trapezoid rule to the value I = np.arctan(5) print(I) 1.373400766945016 print(\"Trapezoid Rule Error:\",np.abs(I - T)) Trapezoid Rule Error: 0.00029668571490626405","title":"Arctangent"},{"location":"integration/trapezoid-rule/#approximate-ln2","text":"Find a value N N which guarantees that the trapezoid rule approximation T_N(f) T_N(f) of the integral \\int_1^2 \\frac{1}{x} \\, dx = \\ln(2) \\int_1^2 \\frac{1}{x} \\, dx = \\ln(2) satisfies E_N^T(f) \\leq 10^{-8} E_N^T(f) \\leq 10^{-8} . For f(x) = \\frac{1}{x} f(x) = \\frac{1}{x} , we compute f''(x) = \\frac{2}{x^3} \\leq 2 f''(x) = \\frac{2}{x^3} \\leq 2 for all x \\in [1,2] x \\in [1,2] therefore the error formula implies \\left| \\, \\int_1^2 \\frac{1}{x} \\, dx - T_N(f) \\, \\right| \\leq \\frac{2}{12N^2} \\left| \\, \\int_1^2 \\frac{1}{x} \\, dx - T_N(f) \\, \\right| \\leq \\frac{2}{12N^2} Then E_N^T \\leq 10^{-8} E_N^T \\leq 10^{-8} is guaranteed if \\frac{1}{6N^2} \\leq 10^{-8} \\frac{1}{6N^2} \\leq 10^{-8} which implies \\frac{10^4}{\\sqrt{6}} \\leq N \\frac{10^4}{\\sqrt{6}} \\leq N 10**4/np.sqrt(6) 4082.4829046386303 We need 4083 subintervals to guarantee E_N^T(f) \\leq 10^{-8} E_N^T(f) \\leq 10^{-8} . Compute the approximation using our own implementation of the trapezoid rule: approximation = trapz(lambda x : 1/x,1,2,4083) print(approximation) 0.6931471843089954 We could also use scipy.integrate.trapz to get the exact same result: N = 4083 x = np.linspace(1,2,N+1) y = 1/x approximation = spi.trapz(y,x) print(approximation) 0.6931471843089955 Let's verify that this is within 10^{-6} 10^{-6} : np.abs(approximation - np.log(2)) < 10**(-8) True Success! However, a natural question arises: what is the actual smallest N N such that the trapezoid rule gives the estimate of \\ln (2) \\ln (2) to within 10^{-8} 10^{-8} ? for n in range(1,4083): approx = trapz(lambda x : 1/x,1,2,n) if np.abs(approx - np.log(2)) < 10e-8: print(\"Accuracy achieved at N =\",n) break Accuracy achieved at N = 791","title":"Approximate ln(2)"},{"location":"integration/trapezoid-rule/#fresnel-integral","text":"Fresnel integrals are examples of nonelementary integrals : antiderivatives which cannot be written in terms of elementary functions . There are two types of Fresnel integrals: S(t) = \\int_0^t \\sin(x^2) dx \\ \\ \\text{and} \\ \\ C(t) = \\int_0^t \\cos(x^2) dx S(t) = \\int_0^t \\sin(x^2) dx \\ \\ \\text{and} \\ \\ C(t) = \\int_0^t \\cos(x^2) dx Use the trapezoid rule to approximate the Fresnel integral S(1) = \\int_0^1 \\sin(x^2) dx S(1) = \\int_0^1 \\sin(x^2) dx such that the error is less than 10^{-5} 10^{-5} . Compute the derivatives of the integrand f(x) = \\sin(x^2) \\ \\ , \\ \\ f'(x) = 2x\\cos(x^2) f(x) = \\sin(x^2) \\ \\ , \\ \\ f'(x) = 2x\\cos(x^2) f''(x) = 2\\cos(x^2) - 4x^2\\sin(x^2) \\ \\ , \\ \\ f'''(x) = -12x\\sin(x^2) - 8x^3\\cos(x^2) f''(x) = 2\\cos(x^2) - 4x^2\\sin(x^2) \\ \\ , \\ \\ f'''(x) = -12x\\sin(x^2) - 8x^3\\cos(x^2) Since f'''(x) \\leq 0 f'''(x) \\leq 0 for x \\in [0,1] x \\in [0,1] , we see that f''(x) f''(x) is decreasing on [0,1] [0,1] . Values of f''(x) f''(x) at the endpoints of the interval are x = 0 2*np.cos(x**2) - 4*x**2*np.sin(x**2) 2.0 x = 1 2*np.cos(x**2) - 4*x**2*np.sin(x**2) -2.2852793274953065 Therefore \\left| \\, f''(x) \\, \\right| \\leq 2.2852793274953065 \\left| \\, f''(x) \\, \\right| \\leq 2.2852793274953065 for x \\in [0,1] x \\in [0,1] . Use the error bound formula to find a good choice for N N \\frac{(b-a)^3}{12 N^2} K_2 \\leq 10^{-5} \\Rightarrow \\sqrt{\\frac{10^5(2.2852793274953065)}{12}} \\leq N \\frac{(b-a)^3}{12 N^2} K_2 \\leq 10^{-5} \\Rightarrow \\sqrt{\\frac{10^5(2.2852793274953065)}{12}} \\leq N np.sqrt(10**5 * 2.2852793274953065 / 12) 137.9999796949051 Let's compute the integral using the trapezoid rule with N=138 N=138 subintervals x = np.linspace(0,1,139) y = np.sin(x**2) I = spi.trapz(y,x) print(I) 0.31027303032220394 Therefore the Fresnel integral S(1) S(1) is approximately S(1) = \\int_0^1 \\sin(x^2) \\, dx \\approx 0.310273030322 S(1) = \\int_0^1 \\sin(x^2) \\, dx \\approx 0.310273030322 with error less than 10^{-5} 10^{-5} .","title":"Fresnel Integral"},{"location":"integration/trapezoid-rule/#logarithmic-integral","text":"The Eulerian logarithmic integral is another nonelementary integral \\mathrm{Li}(t) = \\int_2^t \\frac{1}{\\ln x} dx \\mathrm{Li}(t) = \\int_2^t \\frac{1}{\\ln x} dx Let's compute Li(10) Li(10) such that the error is less than 10^{-4} 10^{-4} . Compute derivatives of the integrand f(x) = \\frac{1}{\\ln x} \\ \\ , \\ \\ f'(x) = -\\frac{1}{x(\\ln x)^2} \\ \\ , \\ \\ f''(x) = \\frac{\\ln x + 2 }{x^2(\\ln x)^3} f(x) = \\frac{1}{\\ln x} \\ \\ , \\ \\ f'(x) = -\\frac{1}{x(\\ln x)^2} \\ \\ , \\ \\ f''(x) = \\frac{\\ln x + 2 }{x^2(\\ln x)^3} Plot f''(x) f''(x) on the interval [2,10] [2,10] . a = 2 b = 10 x = np.linspace(a,b,100) y = (np.log(x) + 2) / (x**2 * np.log(x)**3) plt.plot(x,y) plt.show() Clearly f''(x) f''(x) is decreasing on [2,10] [2,10] (and bounded below by 0) therefore the absolute maximum occurs at the left endpoint: \\left| \\, f''(x) \\, \\right| \\leq \\frac{\\ln (2) + 2}{4 \\ln (2)^3} \\left| \\, f''(x) \\, \\right| \\leq \\frac{\\ln (2) + 2}{4 \\ln (2)^3} for x \\in [2,10] x \\in [2,10] and we compute K2 = (np.log(2) + 2)/(4*np.log(2)**3) print(K2) 2.021732598829855 Use the error formula: \\frac{(b-a)^3}{12 N^2} K_2 \\leq 10^{-4} \\Rightarrow \\frac{8^3}{12 N^2} 2.021732598829855 \\leq 10^{-4} \\Rightarrow \\sqrt{ \\frac{8^3 10^4}{12} 2.021732598829855} \\leq N \\frac{(b-a)^3}{12 N^2} K_2 \\leq 10^{-4} \\Rightarrow \\frac{8^3}{12 N^2} 2.021732598829855 \\leq 10^{-4} \\Rightarrow \\sqrt{ \\frac{8^3 10^4}{12} 2.021732598829855} \\leq N np.sqrt(8**3 * 10**4 * 2.021732598829855 / 12) 928.7657986995814 Compute the trapzoid rule with N=929 N=929 N = 929 x = np.linspace(a,b,N+1) y = 1/np.log(x) I = spi.trapz(y,x) print(I) 5.120442039184057 Therefore the Eulerian logarithmic integral is \\mathrm{Li}(10) = \\int_2^{10} \\frac{1}{\\ln x} dx \\approx 5.121065367200469 \\mathrm{Li}(10) = \\int_2^{10} \\frac{1}{\\ln x} dx \\approx 5.121065367200469 such that the error is less than 10^{-4} 10^{-4} .","title":"Logarithmic Integral"},{"location":"integration/trapezoid-rule/#exercises","text":"Let f(x) = x^x f(x) = x^x and note that f'(x) = x^{x} \\left(\\log{\\left(x \\right)} + 1\\right) \\ , \\ f''(x) = x^{x} \\left(\\log{\\left(x \\right)} + 1\\right)^{2} + x^{x-1} f'(x) = x^{x} \\left(\\log{\\left(x \\right)} + 1\\right) \\ , \\ f''(x) = x^{x} \\left(\\log{\\left(x \\right)} + 1\\right)^{2} + x^{x-1} Plot the function f''(x) f''(x) and use that information to compute T_N(f) T_N(f) for the integral \\int_1^2 x^x \\, dx \\int_1^2 x^x \\, dx such that E_N^T(f) \\leq 10^{-3} E_N^T(f) \\leq 10^{-3} . Consider the integral \\int_0^1 \\ln(1+x^2) \\, dx \\int_0^1 \\ln(1+x^2) \\, dx and note that f(x) = \\ln(1 + x^2) \\hspace{1in} f'(x) = \\frac{2x}{1 + x^2} $$ $$ f''(x) = 2 \\left( \\frac{1 - x^2}{1 + x^2} \\right) \\hspace{1in} f'''(x) = 4x \\frac{x^2 - 3}{(x^2 + 1)^3} f(x) = \\ln(1 + x^2) \\hspace{1in} f'(x) = \\frac{2x}{1 + x^2} $$ $$ f''(x) = 2 \\left( \\frac{1 - x^2}{1 + x^2} \\right) \\hspace{1in} f'''(x) = 4x \\frac{x^2 - 3}{(x^2 + 1)^3} Without plotting the functions f(x) f(x) , f'(x) f'(x) , f''(x) f''(x) or f'''(x) f'''(x) , find a value N N such that E_N^T(f) \\leq 10^{-6} E_N^T(f) \\leq 10^{-6} .","title":"Exercises"},{"location":"jupyter/latex/","text":"LaTeX LaTeX is a typesetting language for producing scientific documents. We introduce a very small part of the language for writing mathematical notation. Jupyter notebook recognizes LaTeX code written in markdown cells and renders the symbols in the browser using the MathJax JavaScript library. Mathematics Inline and Display Enclose LaTeX code in dollar signs $ ... $ to display math inline. For example, the code $\\int_a^b f(x) = F(b) - F(a)$ renders inline as $ \\int_a^b f(x) dx = F(b) - F(a) $. Enclose LaTeX code in double dollar signs $$ ... $$ to display expressions in a centered paragraph. For example: $$f'(a) = \\lim_{x \\to a} \\frac{f(x) - f(a)}{x-a}$$ renders as f'(a) = \\lim_{x \\to a} \\frac{f(x) - f(a)}{x-a} f'(a) = \\lim_{x \\to a} \\frac{f(x) - f(a)}{x-a} See the LaTeX WikiBook for more information (especially the section on mathematics ). Common Symbols Below we give a partial list of commonly used mathematical symbols. Most other symbols can be inferred from these examples. See the LaTeX WikiBook (Mathematics) and the Detexify App to find any symbol you can think of! Syntax Output $x_n$ x_n x_n $x^2$ x^2 x^2 $\\infty$ \\infty \\infty $\\frac{a}{b}$ \\frac{a}{b} \\frac{a}{b} $\\partial$ \\partial \\partial $\\alpha$ \\alpha \\alpha $\\beta$ \\beta \\beta $\\gamma$ \\gamma \\gamma $\\Gamma$ \\Gamma \\Gamma $\\Delta$ \\Delta \\Delta $\\sin$ \\sin \\sin $\\cos$ \\cos \\cos $\\tan$ \\tan \\tan $\\sum_{n=0}^{\\infty}$ \\sum_{n=0}^{\\infty} \\sum_{n=0}^{\\infty} $\\prod_{n=0}^{\\infty}$ \\prod_{n=0}^{\\infty} \\prod_{n=0}^{\\infty} $\\int_a^b$ \\int_a^b \\int_a^b $\\lim_{x \\to a}$ \\lim_{x \\to a} \\lim_{x \\to a} $\\mathrm{Hom}$ \\mathrm{Hom} \\mathrm{Hom} $\\mathbf{v}$ \\mathbf{v} \\mathbf{v} $\\mathbb{Z}$ \\mathbb{Z} \\mathbb{Z} $\\mathscr{L}$ \\mathscr{L} \\mathscr{L} $\\mathfrak{g}$ \\mathfrak{g} \\mathfrak{g} $\\dots$ \\dots \\dots $\\vdots$ \\vdots \\vdots $\\ddots$ \\ddots \\ddots Matrices and Brackets Create a matrix without brackets: $$\\begin{matrix} a & b \\\\ c & d \\end{matrix}$$ \\begin{matrix} a & b \\\\\\ c & d \\end{matrix} \\begin{matrix} a & b \\\\\\ c & d \\end{matrix} Create a matrix with round brackets: $$\\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix}$$ \\begin{pmatrix} a & b \\\\\\ c & d \\end{pmatrix} \\begin{pmatrix} a & b \\\\\\ c & d \\end{pmatrix} Create a matrix with square brackets: $$\\begin{bmatrix} 1 & 2 & 1 \\\\ 3 & 0 & 1 \\\\ 0 & 2 & 4 \\end{bmatrix}$$ \\begin{bmatrix} 1 & 2 & 1 \\\\\\ 3 & 0 & 1 \\\\\\ 0 & 2 & 4 \\end{bmatrix} \\begin{bmatrix} 1 & 2 & 1 \\\\\\ 3 & 0 & 1 \\\\\\ 0 & 2 & 4 \\end{bmatrix} Use \\left and \\right to enclose an arbitrary expression in brackets: $$\\left( \\frac{p}{q} \\right)$$ \\left( \\frac{p}{q} \\right) \\left( \\frac{p}{q} \\right) Examples Derivative The derivative f'(a) f'(a) of the function f(x) f(x) at the point x=a x=a is the limit $$f'(a) = \\lim_{x \\to a} \\frac{f(x) - f(a)}{x - a}$$ f'(a) = \\lim_{x \\to a} \\frac{f(x) - f(a)}{x - a} f'(a) = \\lim_{x \\to a} \\frac{f(x) - f(a)}{x - a} Continuity A function f(x) f(x) is continuous at a point x=a x=a if $$\\lim_{x \\to a^-} f(x) = f(a) = \\lim_{x \\to a^+} f(x)$$ \\lim_{x \\to a^-} f(x) = f(a) = \\lim_{x \\to a^+} f(x) \\lim_{x \\to a^-} f(x) = f(a) = \\lim_{x \\to a^+} f(x) MacLaurin Series The MacLaurin series for e^x e^x is $$e^x = \\sum_{k=0}^{\\infty} \\frac{x^k}{k!}$$ e^x = \\sum_{k=0}^{\\infty} \\frac{x^k}{k!} e^x = \\sum_{k=0}^{\\infty} \\frac{x^k}{k!} Jacobian Matrix The Jacobian matrix of the function \\mathbf{f}(x_1, \\dots, x_n) \\mathbf{f}(x_1, \\dots, x_n) is $$ \\mathbf{J} = \\frac{d \\mathbf{f}}{d \\mathbf{x}} = \\left[ \\frac{\\partial \\mathbf{f}}{\\partial x_1} \\cdots \\frac{\\partial \\mathbf{f}}{\\partial x_n} \\right] = \\begin{bmatrix} \\frac{\\partial f_1}{\\partial x_1} & \\cdots & \\frac{\\partial f_1}{\\partial x_n} \\\\ \\vdots & \\ddots & \\vdots \\\\ \\frac{\\partial f_m}{\\partial x_1} & \\cdots & \\frac{\\partial f_m}{\\partial x_n} \\end{bmatrix} $$ \\mathbf{J} = \\frac{d \\mathbf{f}}{d \\mathbf{x}} = \\left[ \\frac{\\partial \\mathbf{f}}{\\partial x_1} \\cdots \\frac{\\partial \\mathbf{f}}{\\partial x_n} \\right] = \\begin{bmatrix} \\frac{\\partial f_1}{\\partial x_1} & \\cdots & \\frac{\\partial f_1}{\\partial x_n} \\\\\\ \\vdots & \\ddots & \\vdots \\\\\\ \\frac{\\partial f_m}{\\partial x_1} & \\cdots & \\frac{\\partial f_m}{\\partial x_n} \\end{bmatrix} \\mathbf{J} = \\frac{d \\mathbf{f}}{d \\mathbf{x}} = \\left[ \\frac{\\partial \\mathbf{f}}{\\partial x_1} \\cdots \\frac{\\partial \\mathbf{f}}{\\partial x_n} \\right] = \\begin{bmatrix} \\frac{\\partial f_1}{\\partial x_1} & \\cdots & \\frac{\\partial f_1}{\\partial x_n} \\\\\\ \\vdots & \\ddots & \\vdots \\\\\\ \\frac{\\partial f_m}{\\partial x_1} & \\cdots & \\frac{\\partial f_m}{\\partial x_n} \\end{bmatrix} Exercises Write LaTeX code to display the angle sum identity \\cos(\\alpha \\pm \\beta) = \\cos \\alpha \\cos \\beta \\mp \\sin \\alpha \\sin \\beta \\cos(\\alpha \\pm \\beta) = \\cos \\alpha \\cos \\beta \\mp \\sin \\alpha \\sin \\beta Write LaTeX code to display the indefinite integral \\int \\frac{1}{1 + x^2} \\, dx = \\arctan x + C \\int \\frac{1}{1 + x^2} \\, dx = \\arctan x + C Write LaTeX code to display the Navier-Stokes Equation for Incompressible Flow \\frac{\\partial \\mathbf{u}}{\\partial t} + (\\mathbf{u} \\cdot \\nabla) \\mathbf{u} - \\nu \\nabla^2 \\mathbf{u} = - \\nabla w + \\mathbf{g} \\frac{\\partial \\mathbf{u}}{\\partial t} + (\\mathbf{u} \\cdot \\nabla) \\mathbf{u} - \\nu \\nabla^2 \\mathbf{u} = - \\nabla w + \\mathbf{g} Write LaTeX code to display Green's Theorem \\oint_C (L dx + M dy) = \\iint_D \\left( \\frac{\\partial M}{\\partial x} - \\frac{\\partial L}{\\partial y} \\right) dx \\, dy \\oint_C (L dx + M dy) = \\iint_D \\left( \\frac{\\partial M}{\\partial x} - \\frac{\\partial L}{\\partial y} \\right) dx \\, dy Write LaTeX code to display the Prime Number Theorem \\lim_{x \\to \\infty} \\frac{\\pi(x)}{ \\frac{x}{\\log(x)}} = 1 \\lim_{x \\to \\infty} \\frac{\\pi(x)}{ \\frac{x}{\\log(x)}} = 1 Write LaTeX code to display the general formula for Taylor series \\sum_{n=0}^{\\infty} \\frac{f^{(n)}(a)}{n!} (x-a)^n \\sum_{n=0}^{\\infty} \\frac{f^{(n)}(a)}{n!} (x-a)^n Write LaTeX code to display Stokes' Theorem \\int_{\\partial \\Omega} \\omega = \\int_{\\Omega} d \\omega \\int_{\\partial \\Omega} \\omega = \\int_{\\Omega} d \\omega Write LaTeX code to display the adjoint property of the tensor product \\mathrm{Hom}(U \\otimes V,W) \\cong \\mathrm{Hom}(U, \\mathrm{Hom}(V,W)) \\mathrm{Hom}(U \\otimes V,W) \\cong \\mathrm{Hom}(U, \\mathrm{Hom}(V,W)) Write LaTeX code to display the definition of the Laplace transform \\mathscr{L} \\{ f(t) \\} = F(s) = \\int_0^{\\infty} f(t) e^{-st} dt \\mathscr{L} \\{ f(t) \\} = F(s) = \\int_0^{\\infty} f(t) e^{-st} dt Write LaTeX code to display the inverse matrix formula \\begin{bmatrix} a & b \\\\\\ c & d \\end{bmatrix}^{-1} = \\frac{1}{ad - bc} \\begin{bmatrix} d & -b \\\\\\ -c & a \\end{bmatrix} \\begin{bmatrix} a & b \\\\\\ c & d \\end{bmatrix}^{-1} = \\frac{1}{ad - bc} \\begin{bmatrix} d & -b \\\\\\ -c & a \\end{bmatrix} Write LaTeX code to display the infinite product formula \\sin x = x \\prod_{n=1}^{\\infty} \\left( 1 - \\frac{x^2}{\\pi^2 n^2} \\right) \\sin x = x \\prod_{n=1}^{\\infty} \\left( 1 - \\frac{x^2}{\\pi^2 n^2} \\right) Pick your favourite math course and write the notes from your last class in LaTeX.","title":"LaTeX"},{"location":"jupyter/latex/#latex","text":"LaTeX is a typesetting language for producing scientific documents. We introduce a very small part of the language for writing mathematical notation. Jupyter notebook recognizes LaTeX code written in markdown cells and renders the symbols in the browser using the MathJax JavaScript library.","title":"LaTeX"},{"location":"jupyter/latex/#mathematics-inline-and-display","text":"Enclose LaTeX code in dollar signs $ ... $ to display math inline. For example, the code $\\int_a^b f(x) = F(b) - F(a)$ renders inline as $ \\int_a^b f(x) dx = F(b) - F(a) $. Enclose LaTeX code in double dollar signs $$ ... $$ to display expressions in a centered paragraph. For example: $$f'(a) = \\lim_{x \\to a} \\frac{f(x) - f(a)}{x-a}$$ renders as f'(a) = \\lim_{x \\to a} \\frac{f(x) - f(a)}{x-a} f'(a) = \\lim_{x \\to a} \\frac{f(x) - f(a)}{x-a} See the LaTeX WikiBook for more information (especially the section on mathematics ).","title":"Mathematics Inline and Display"},{"location":"jupyter/latex/#common-symbols","text":"Below we give a partial list of commonly used mathematical symbols. Most other symbols can be inferred from these examples. See the LaTeX WikiBook (Mathematics) and the Detexify App to find any symbol you can think of! Syntax Output $x_n$ x_n x_n $x^2$ x^2 x^2 $\\infty$ \\infty \\infty $\\frac{a}{b}$ \\frac{a}{b} \\frac{a}{b} $\\partial$ \\partial \\partial $\\alpha$ \\alpha \\alpha $\\beta$ \\beta \\beta $\\gamma$ \\gamma \\gamma $\\Gamma$ \\Gamma \\Gamma $\\Delta$ \\Delta \\Delta $\\sin$ \\sin \\sin $\\cos$ \\cos \\cos $\\tan$ \\tan \\tan $\\sum_{n=0}^{\\infty}$ \\sum_{n=0}^{\\infty} \\sum_{n=0}^{\\infty} $\\prod_{n=0}^{\\infty}$ \\prod_{n=0}^{\\infty} \\prod_{n=0}^{\\infty} $\\int_a^b$ \\int_a^b \\int_a^b $\\lim_{x \\to a}$ \\lim_{x \\to a} \\lim_{x \\to a} $\\mathrm{Hom}$ \\mathrm{Hom} \\mathrm{Hom} $\\mathbf{v}$ \\mathbf{v} \\mathbf{v} $\\mathbb{Z}$ \\mathbb{Z} \\mathbb{Z} $\\mathscr{L}$ \\mathscr{L} \\mathscr{L} $\\mathfrak{g}$ \\mathfrak{g} \\mathfrak{g} $\\dots$ \\dots \\dots $\\vdots$ \\vdots \\vdots $\\ddots$ \\ddots \\ddots","title":"Common Symbols"},{"location":"jupyter/latex/#matrices-and-brackets","text":"Create a matrix without brackets: $$\\begin{matrix} a & b \\\\ c & d \\end{matrix}$$ \\begin{matrix} a & b \\\\\\ c & d \\end{matrix} \\begin{matrix} a & b \\\\\\ c & d \\end{matrix} Create a matrix with round brackets: $$\\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix}$$ \\begin{pmatrix} a & b \\\\\\ c & d \\end{pmatrix} \\begin{pmatrix} a & b \\\\\\ c & d \\end{pmatrix} Create a matrix with square brackets: $$\\begin{bmatrix} 1 & 2 & 1 \\\\ 3 & 0 & 1 \\\\ 0 & 2 & 4 \\end{bmatrix}$$ \\begin{bmatrix} 1 & 2 & 1 \\\\\\ 3 & 0 & 1 \\\\\\ 0 & 2 & 4 \\end{bmatrix} \\begin{bmatrix} 1 & 2 & 1 \\\\\\ 3 & 0 & 1 \\\\\\ 0 & 2 & 4 \\end{bmatrix} Use \\left and \\right to enclose an arbitrary expression in brackets: $$\\left( \\frac{p}{q} \\right)$$ \\left( \\frac{p}{q} \\right) \\left( \\frac{p}{q} \\right)","title":"Matrices and Brackets"},{"location":"jupyter/latex/#examples","text":"","title":"Examples"},{"location":"jupyter/latex/#derivative","text":"The derivative f'(a) f'(a) of the function f(x) f(x) at the point x=a x=a is the limit $$f'(a) = \\lim_{x \\to a} \\frac{f(x) - f(a)}{x - a}$$ f'(a) = \\lim_{x \\to a} \\frac{f(x) - f(a)}{x - a} f'(a) = \\lim_{x \\to a} \\frac{f(x) - f(a)}{x - a}","title":"Derivative"},{"location":"jupyter/latex/#continuity","text":"A function f(x) f(x) is continuous at a point x=a x=a if $$\\lim_{x \\to a^-} f(x) = f(a) = \\lim_{x \\to a^+} f(x)$$ \\lim_{x \\to a^-} f(x) = f(a) = \\lim_{x \\to a^+} f(x) \\lim_{x \\to a^-} f(x) = f(a) = \\lim_{x \\to a^+} f(x)","title":"Continuity"},{"location":"jupyter/latex/#maclaurin-series","text":"The MacLaurin series for e^x e^x is $$e^x = \\sum_{k=0}^{\\infty} \\frac{x^k}{k!}$$ e^x = \\sum_{k=0}^{\\infty} \\frac{x^k}{k!} e^x = \\sum_{k=0}^{\\infty} \\frac{x^k}{k!}","title":"MacLaurin Series"},{"location":"jupyter/latex/#jacobian-matrix","text":"The Jacobian matrix of the function \\mathbf{f}(x_1, \\dots, x_n) \\mathbf{f}(x_1, \\dots, x_n) is $$ \\mathbf{J} = \\frac{d \\mathbf{f}}{d \\mathbf{x}} = \\left[ \\frac{\\partial \\mathbf{f}}{\\partial x_1} \\cdots \\frac{\\partial \\mathbf{f}}{\\partial x_n} \\right] = \\begin{bmatrix} \\frac{\\partial f_1}{\\partial x_1} & \\cdots & \\frac{\\partial f_1}{\\partial x_n} \\\\ \\vdots & \\ddots & \\vdots \\\\ \\frac{\\partial f_m}{\\partial x_1} & \\cdots & \\frac{\\partial f_m}{\\partial x_n} \\end{bmatrix} $$ \\mathbf{J} = \\frac{d \\mathbf{f}}{d \\mathbf{x}} = \\left[ \\frac{\\partial \\mathbf{f}}{\\partial x_1} \\cdots \\frac{\\partial \\mathbf{f}}{\\partial x_n} \\right] = \\begin{bmatrix} \\frac{\\partial f_1}{\\partial x_1} & \\cdots & \\frac{\\partial f_1}{\\partial x_n} \\\\\\ \\vdots & \\ddots & \\vdots \\\\\\ \\frac{\\partial f_m}{\\partial x_1} & \\cdots & \\frac{\\partial f_m}{\\partial x_n} \\end{bmatrix} \\mathbf{J} = \\frac{d \\mathbf{f}}{d \\mathbf{x}} = \\left[ \\frac{\\partial \\mathbf{f}}{\\partial x_1} \\cdots \\frac{\\partial \\mathbf{f}}{\\partial x_n} \\right] = \\begin{bmatrix} \\frac{\\partial f_1}{\\partial x_1} & \\cdots & \\frac{\\partial f_1}{\\partial x_n} \\\\\\ \\vdots & \\ddots & \\vdots \\\\\\ \\frac{\\partial f_m}{\\partial x_1} & \\cdots & \\frac{\\partial f_m}{\\partial x_n} \\end{bmatrix}","title":"Jacobian Matrix"},{"location":"jupyter/latex/#exercises","text":"Write LaTeX code to display the angle sum identity \\cos(\\alpha \\pm \\beta) = \\cos \\alpha \\cos \\beta \\mp \\sin \\alpha \\sin \\beta \\cos(\\alpha \\pm \\beta) = \\cos \\alpha \\cos \\beta \\mp \\sin \\alpha \\sin \\beta Write LaTeX code to display the indefinite integral \\int \\frac{1}{1 + x^2} \\, dx = \\arctan x + C \\int \\frac{1}{1 + x^2} \\, dx = \\arctan x + C Write LaTeX code to display the Navier-Stokes Equation for Incompressible Flow \\frac{\\partial \\mathbf{u}}{\\partial t} + (\\mathbf{u} \\cdot \\nabla) \\mathbf{u} - \\nu \\nabla^2 \\mathbf{u} = - \\nabla w + \\mathbf{g} \\frac{\\partial \\mathbf{u}}{\\partial t} + (\\mathbf{u} \\cdot \\nabla) \\mathbf{u} - \\nu \\nabla^2 \\mathbf{u} = - \\nabla w + \\mathbf{g} Write LaTeX code to display Green's Theorem \\oint_C (L dx + M dy) = \\iint_D \\left( \\frac{\\partial M}{\\partial x} - \\frac{\\partial L}{\\partial y} \\right) dx \\, dy \\oint_C (L dx + M dy) = \\iint_D \\left( \\frac{\\partial M}{\\partial x} - \\frac{\\partial L}{\\partial y} \\right) dx \\, dy Write LaTeX code to display the Prime Number Theorem \\lim_{x \\to \\infty} \\frac{\\pi(x)}{ \\frac{x}{\\log(x)}} = 1 \\lim_{x \\to \\infty} \\frac{\\pi(x)}{ \\frac{x}{\\log(x)}} = 1 Write LaTeX code to display the general formula for Taylor series \\sum_{n=0}^{\\infty} \\frac{f^{(n)}(a)}{n!} (x-a)^n \\sum_{n=0}^{\\infty} \\frac{f^{(n)}(a)}{n!} (x-a)^n Write LaTeX code to display Stokes' Theorem \\int_{\\partial \\Omega} \\omega = \\int_{\\Omega} d \\omega \\int_{\\partial \\Omega} \\omega = \\int_{\\Omega} d \\omega Write LaTeX code to display the adjoint property of the tensor product \\mathrm{Hom}(U \\otimes V,W) \\cong \\mathrm{Hom}(U, \\mathrm{Hom}(V,W)) \\mathrm{Hom}(U \\otimes V,W) \\cong \\mathrm{Hom}(U, \\mathrm{Hom}(V,W)) Write LaTeX code to display the definition of the Laplace transform \\mathscr{L} \\{ f(t) \\} = F(s) = \\int_0^{\\infty} f(t) e^{-st} dt \\mathscr{L} \\{ f(t) \\} = F(s) = \\int_0^{\\infty} f(t) e^{-st} dt Write LaTeX code to display the inverse matrix formula \\begin{bmatrix} a & b \\\\\\ c & d \\end{bmatrix}^{-1} = \\frac{1}{ad - bc} \\begin{bmatrix} d & -b \\\\\\ -c & a \\end{bmatrix} \\begin{bmatrix} a & b \\\\\\ c & d \\end{bmatrix}^{-1} = \\frac{1}{ad - bc} \\begin{bmatrix} d & -b \\\\\\ -c & a \\end{bmatrix} Write LaTeX code to display the infinite product formula \\sin x = x \\prod_{n=1}^{\\infty} \\left( 1 - \\frac{x^2}{\\pi^2 n^2} \\right) \\sin x = x \\prod_{n=1}^{\\infty} \\left( 1 - \\frac{x^2}{\\pi^2 n^2} \\right) Pick your favourite math course and write the notes from your last class in LaTeX.","title":"Exercises"},{"location":"jupyter/markdown/","text":"Markdown Markdown is a simple text-to-HTML markup language written in plain text. Jupyter notebook recognizes markdown and renders markdown code as HTML. In this section, we present the basic features of markdown. See Markdown (by John Gruber) and GitHub Markdown Help for more information. Text Output Syntax emphasis *emphasis* strong **strong** code `code` Headings Output Syntax Heading 1 # Heading 1 Heading 2 ## Heading 2 Heading 3 ### Heading 3 Heading 4 #### Heading 4 Heading 5 ##### Heading 5 Heading 6 ###### Heading 6 Lists Create an ordered list using numbers: 1. Number theory 2. Algebra 3. Partial differential equations 4. Probability Number theory Algebra Partial differential equations Probability Create an unordered list using an asterisk * for each item: * Number theory * Algebra * Partial differential equations * Probability Number theory Algebra Partial differential equations Probability Use indentation to create nested lists: 1. Mathematics * Calculus * Linear Algebra * Probability 2. Physics * Classical Mechanics * Relativity * Thermodynamics 3. Biology * Diffusion and Osmosis * Homeostasis * Immunology Mathematics Calculus Linear Algebra Probability Physics Classical Mechanics Relativity Thermodynamics Biology Diffusion and Osmosis Homeostasis Immunology Links Create a link with the syntax [description](url) . For example: [UBC Math](http://www.math.ubc.ca) creates the link UBC Math . Images Include an image using the syntax ![description](url) . For example: ![Jupyter logo](http://jupyter.org/assets/nav_logo.svg) displays the image Tables Create a table by separating entries by pipe characters |: | Python Operator | Description | | :---: | :---: | | `+` | addition | | `-` | subtraction | | `*` | multiplication | | `/` | division | | `**` | power | Python Operator Description + addition - subtraction * multiplication / division ** power The syntax :---: specifies the alignment (centered in this case) of the columns. See more about GitHub flavoured markdown . Exercises Create a numbered list of the top 5 websites you visit most often and include a link for each site. Write a short biography of your favourite mathematician, provide a link to their Wikipedia page and include an image (with a link and description of the source). Create a table of all the courses that you have taken in university. Include the columns: course number, course title, year (that you took the class), and instructor name.","title":"Markdown"},{"location":"jupyter/markdown/#markdown","text":"Markdown is a simple text-to-HTML markup language written in plain text. Jupyter notebook recognizes markdown and renders markdown code as HTML. In this section, we present the basic features of markdown. See Markdown (by John Gruber) and GitHub Markdown Help for more information.","title":"Markdown"},{"location":"jupyter/markdown/#text","text":"Output Syntax emphasis *emphasis* strong **strong** code `code`","title":"Text"},{"location":"jupyter/markdown/#headings","text":"Output Syntax","title":"Headings"},{"location":"jupyter/markdown/#lists","text":"Create an ordered list using numbers: 1. Number theory 2. Algebra 3. Partial differential equations 4. Probability Number theory Algebra Partial differential equations Probability Create an unordered list using an asterisk * for each item: * Number theory * Algebra * Partial differential equations * Probability Number theory Algebra Partial differential equations Probability Use indentation to create nested lists: 1. Mathematics * Calculus * Linear Algebra * Probability 2. Physics * Classical Mechanics * Relativity * Thermodynamics 3. Biology * Diffusion and Osmosis * Homeostasis * Immunology Mathematics Calculus Linear Algebra Probability Physics Classical Mechanics Relativity Thermodynamics Biology Diffusion and Osmosis Homeostasis Immunology","title":"Lists"},{"location":"jupyter/markdown/#links","text":"Create a link with the syntax [description](url) . For example: [UBC Math](http://www.math.ubc.ca) creates the link UBC Math .","title":"Links"},{"location":"jupyter/markdown/#images","text":"Include an image using the syntax ![description](url) . For example: ![Jupyter logo](http://jupyter.org/assets/nav_logo.svg) displays the image","title":"Images"},{"location":"jupyter/markdown/#tables","text":"Create a table by separating entries by pipe characters |: | Python Operator | Description | | :---: | :---: | | `+` | addition | | `-` | subtraction | | `*` | multiplication | | `/` | division | | `**` | power | Python Operator Description + addition - subtraction * multiplication / division ** power The syntax :---: specifies the alignment (centered in this case) of the columns. See more about GitHub flavoured markdown .","title":"Tables"},{"location":"jupyter/markdown/#exercises","text":"Create a numbered list of the top 5 websites you visit most often and include a link for each site. Write a short biography of your favourite mathematician, provide a link to their Wikipedia page and include an image (with a link and description of the source). Create a table of all the courses that you have taken in university. Include the columns: course number, course title, year (that you took the class), and instructor name.","title":"Exercises"},{"location":"jupyter/notebook/","text":"Jupyter Notebook From the official webpage jupyter.org : The Jupyter Notebook is a web application that allows you to create and share documents that contain live code, equations, visualizations and explanatory text. In this section, we present the basic features of Jupyter notebooks. See the User Interface Tour in the Help menu in the Jupyter notebook. Cells There are two main types of cells: code cells and markdown cells. Hit SHIFT+ENTER to execute the contents of a cell. Markdown cells contain: markdown HTML LaTeX plain text images videos Anything that a browser can understand For more information about markdown see Markdown Basics on GitHub and Markdown Syntax . Python code is written in code cells. Hit SHIFT+ENTER to execute the code. Output is displayed below the code cell: # Python code to display the first 10 square numbers for n in range(1,11): print(n**2) 1 4 9 16 25 36 49 64 81 100 Modes There are two modes: edit mode and command mode. Press ESC to enter command mode and ENTER for edit mode. Edit mode is for writing text and code in the cell. Edit mode is indicated by a green border around the cell. Command mode is for notebook editing commands such as cut cell, paste cell, and insert cell above. Command mode is indicated by a blue border around the cell. Keyboard Shortcuts The toolbar has buttons for common actions however you can increase the speed of your workflow by memorizing the following keyboard shortcuts in command mode: Command Mode Action Shortcut insert empty cell above a insert empty cell below b copy cell c cut cell x paste cell below v to code cell y to markdown cell m save and checkpoint s execute cell SHIFT+ENTER to edit mode ENTER to command mode ESC See Help in the toolbar of the Jupyter notebook to see the list of keyboard shortcuts.","title":"Jupyter Notebook"},{"location":"jupyter/notebook/#jupyter-notebook","text":"From the official webpage jupyter.org : The Jupyter Notebook is a web application that allows you to create and share documents that contain live code, equations, visualizations and explanatory text. In this section, we present the basic features of Jupyter notebooks. See the User Interface Tour in the Help menu in the Jupyter notebook.","title":"Jupyter Notebook"},{"location":"jupyter/notebook/#cells","text":"There are two main types of cells: code cells and markdown cells. Hit SHIFT+ENTER to execute the contents of a cell. Markdown cells contain: markdown HTML LaTeX plain text images videos Anything that a browser can understand For more information about markdown see Markdown Basics on GitHub and Markdown Syntax . Python code is written in code cells. Hit SHIFT+ENTER to execute the code. Output is displayed below the code cell: # Python code to display the first 10 square numbers for n in range(1,11): print(n**2) 1 4 9 16 25 36 49 64 81 100","title":"Cells"},{"location":"jupyter/notebook/#modes","text":"There are two modes: edit mode and command mode. Press ESC to enter command mode and ENTER for edit mode. Edit mode is for writing text and code in the cell. Edit mode is indicated by a green border around the cell. Command mode is for notebook editing commands such as cut cell, paste cell, and insert cell above. Command mode is indicated by a blue border around the cell.","title":"Modes"},{"location":"jupyter/notebook/#keyboard-shortcuts","text":"The toolbar has buttons for common actions however you can increase the speed of your workflow by memorizing the following keyboard shortcuts in command mode: Command Mode Action Shortcut insert empty cell above a insert empty cell below b copy cell c cut cell x paste cell below v to code cell y to markdown cell m save and checkpoint s execute cell SHIFT+ENTER to edit mode ENTER to command mode ESC See Help in the toolbar of the Jupyter notebook to see the list of keyboard shortcuts.","title":"Keyboard Shortcuts"},{"location":"linear-algebra/applications/","text":"Applications import numpy as np import matplotlib.pyplot as plt import scipy.linalg as la Polynomial Interpolation Polynomial interpolation finds the unique polynomial of degree n n which passes through n+1 n+1 points in the xy xy -plane. For example, two points in the xy xy -plane determine a line and three points determine a parabola. Formulation Suppose we have n + 1 n + 1 points in the xy xy -plane (x_0,y_0),(x_1,y_1),\\dots,(x_n,y_n) (x_0,y_0),(x_1,y_1),\\dots,(x_n,y_n) such that all the x x values are distinct ( x_i \\not= x_j x_i \\not= x_j for i \\not= j i \\not= j ). The general form of a degree n n polynomial is p(x) = a_0 + a_1 x + a_2x^2 + \\cdots + a_n x^n p(x) = a_0 + a_1 x + a_2x^2 + \\cdots + a_n x^n If p(x) p(x) is the unique degree n n polynomial which interpolates all the points, then the coefficients a_0 a_0 , a_1 a_1 , \\dots \\dots , a_n a_n satisfy the following equations: \\begin{align} a_0 + a_1x_0 + a_2x_0^2 + \\cdots + a_n x_0^n &= y_0 \\\\\\ a_0 + a_1x_1 + a_2x_1^2 + \\cdots + a_n x_1^n &= y_1 \\\\\\ & \\ \\ \\vdots \\\\\\ a_0 + a_1x_n + a_2x_n^2 + \\cdots + a_n x_n^n &= y_n \\end{align} \\begin{align} a_0 + a_1x_0 + a_2x_0^2 + \\cdots + a_n x_0^n &= y_0 \\\\\\ a_0 + a_1x_1 + a_2x_1^2 + \\cdots + a_n x_1^n &= y_1 \\\\\\ & \\ \\ \\vdots \\\\\\ a_0 + a_1x_n + a_2x_n^2 + \\cdots + a_n x_n^n &= y_n \\end{align} Therefore the vector of coefficients \\mathbf{a} = \\begin{bmatrix} a_0 \\\\\\ a_1 \\\\\\ \\vdots \\\\\\ a_n \\end{bmatrix} \\mathbf{a} = \\begin{bmatrix} a_0 \\\\\\ a_1 \\\\\\ \\vdots \\\\\\ a_n \\end{bmatrix} is the unique the solution of the linear system of equations X \\mathbf{a}=\\mathbf{y} X \\mathbf{a}=\\mathbf{y} where X X is the Vandermonde matrix and \\mathbf{y} \\mathbf{y} is the vector of y y values X = \\begin{bmatrix} 1 & x_0 & x_0^2 & \\dots & x_0^n \\\\\\ 1 & x_1 & x_1^2 & \\dots & x_1^n \\\\\\ & \\vdots & & & \\vdots \\\\\\ 1 & x_n & x_n^2 & \\dots & x_n^n \\\\\\ \\end{bmatrix} \\ \\ \\mathrm{and} \\ \\ \\mathbf{y} = \\begin{bmatrix} y_0 \\\\\\ y_1 \\\\\\ y_2 \\\\\\ \\vdots \\\\\\ y_n \\end{bmatrix} X = \\begin{bmatrix} 1 & x_0 & x_0^2 & \\dots & x_0^n \\\\\\ 1 & x_1 & x_1^2 & \\dots & x_1^n \\\\\\ & \\vdots & & & \\vdots \\\\\\ 1 & x_n & x_n^2 & \\dots & x_n^n \\\\\\ \\end{bmatrix} \\ \\ \\mathrm{and} \\ \\ \\mathbf{y} = \\begin{bmatrix} y_0 \\\\\\ y_1 \\\\\\ y_2 \\\\\\ \\vdots \\\\\\ y_n \\end{bmatrix} Examples Simple Parabola Let's do a simple example. We know that y=x^2 y=x^2 is the unique degree 2 polynomial that interpolates the points (-1,1) (-1,1) , (0,0) (0,0) and (1,1) (1,1) . Let's compute the polynomial interpolation of these points and verify the expected result a_0=0 a_0=0 , a_1=0 a_1=0 and a_2=1 a_2=1 . Create the Vandermonde matrix X X with the array of x x values: x = np.array([-1,0,1]) X = np.column_stack([[1,1,1],x,x**2]) print(X) [[ 1 -1 1] [ 1 0 0] [ 1 1 1]] Create the vector \\mathbf{y} \\mathbf{y} of y y values: y = np.array([1,0,1]).reshape(3,1) print(y) [[1] [0] [1]] We expect the solution \\mathbf{a} = [0,0,1]^T \\mathbf{a} = [0,0,1]^T : a = la.solve(X,y) print(a) [[0.] [0.] [1.]] Success! Another Parabola The polynomial interpolation of 3 points (x_0,y_0) (x_0,y_0) , (x_1,y_1) (x_1,y_1) and (x_2,y_2) (x_2,y_2) is the parabola p(x) = a_0 + a_1x + a_2x^2 p(x) = a_0 + a_1x + a_2x^2 such that the coefficients satisfy \\begin{align} a_0 + a_1x_0 + a_2x_0^2 = y_0 \\\\\\ a_0 + a_1x_1 + a_2x_1^2 = y_1 \\\\\\ a_0 + a_1x_2 + a_2x_2^2 = y_2 \\end{align} \\begin{align} a_0 + a_1x_0 + a_2x_0^2 = y_0 \\\\\\ a_0 + a_1x_1 + a_2x_1^2 = y_1 \\\\\\ a_0 + a_1x_2 + a_2x_2^2 = y_2 \\end{align} Let's find the polynomial interpolation of the points (0,6) (0,6) , (3,1) (3,1) and (8,2) (8,2) . Create the Vandermonde matrix X X : x = np.array([0,3,8]) X = np.column_stack([[1,1,1],x,x**2]) print(X) [[ 1 0 0] [ 1 3 9] [ 1 8 64]] And the vector of y y values: y = np.array([6,1,2]).reshape(3,1) print(y) [[6] [1] [2]] Compute the vector \\mathbf{a} \\mathbf{a} of coefficients: a = la.solve(X,y) print(a) [[ 6. ] [-2.36666667] [ 0.23333333]] And plot the result: xs = np.linspace(0,8,20) ys = a[0] + a[1]*xs + a[2]*xs**2 plt.plot(xs,ys,x,y,'b.',ms=20) plt.show() Over Fitting 10 Random Points Now let's interpolate points with x_i=i x_i=i , i=0,\\dots,9 i=0,\\dots,9 , and 10 random integers sampled from [0,10) [0,10) as y y values: N = 10 x = np.arange(0,N) y = np.random.randint(0,10,N) plt.plot(x,y,'r.') plt.show() Create the Vandermonde matrix and verify the first 5 rows and columns: X = np.column_stack([x**k for k in range(0,N)]) print(X[:5,:5]) [[ 1 0 0 0 0] [ 1 1 1 1 1] [ 1 2 4 8 16] [ 1 3 9 27 81] [ 1 4 16 64 256]] We could also use the NumPy function numpy.vander . We specify the option increasing=True so that powers of x_i x_i increase left-to-right: X = np.vander(x,increasing=True) print(X[:5,:5]) [[ 1 0 0 0 0] [ 1 1 1 1 1] [ 1 2 4 8 16] [ 1 3 9 27 81] [ 1 4 16 64 256]] Solve the linear system: a = la.solve(X,y) Plot the interpolation: xs = np.linspace(0,N-1,200) ys = sum([a[k]*xs**k for k in range(0,N)]) plt.plot(x,y,'r.',xs,ys) plt.show() Success! But notice how unstable the curve is. That's why it better to use a cubic spline to interpolate a large number of points. However real-life data is usually very noisy and interpolation is not the best tool to fit a line to data. Instead we would want to take a polynomial with smaller degree (like a line) and fit it as best we can without interpolating the points. Least Squares Linear Regression Suppose we have n+1 n+1 points (x_0,y_0) , (x_1,y_1) , \\dots , (x_n,y_n) (x_0,y_0) , (x_1,y_1) , \\dots , (x_n,y_n) in the xy xy -plane and we want to fit a line y=a_0 + a_1x y=a_0 + a_1x that \"best fits\" the data. There are different ways to quantify what \"best fit\" means but the most common method is called least squares linear regression . In least squares linear regression, we want to minimize the sum of squared errors SSE = \\sum_i (y_i - (a_0 + a_1 x_i))^2 SSE = \\sum_i (y_i - (a_0 + a_1 x_i))^2 Formulation If we form matrices X = \\begin{bmatrix} 1 & x_0 \\\\\\ 1 & x_1 \\\\\\ \\vdots & \\vdots \\\\\\ 1 & x_n \\end{bmatrix} \\ , \\ \\ \\mathbf{y} = \\begin{bmatrix} y_0 \\\\\\ y_1 \\\\\\ \\vdots \\\\\\ y_n \\end{bmatrix} \\ , \\ \\ \\mathbf{a} = \\begin{bmatrix} a_0 \\\\\\ a_1 \\end{bmatrix} X = \\begin{bmatrix} 1 & x_0 \\\\\\ 1 & x_1 \\\\\\ \\vdots & \\vdots \\\\\\ 1 & x_n \\end{bmatrix} \\ , \\ \\ \\mathbf{y} = \\begin{bmatrix} y_0 \\\\\\ y_1 \\\\\\ \\vdots \\\\\\ y_n \\end{bmatrix} \\ , \\ \\ \\mathbf{a} = \\begin{bmatrix} a_0 \\\\\\ a_1 \\end{bmatrix} then the sum of squared errors can be expressed as SSE = \\Vert \\mathbf{y} - X \\mathbf{a} \\Vert^2 SSE = \\Vert \\mathbf{y} - X \\mathbf{a} \\Vert^2 Theorem. (Least Squares Linear Regression) Consider n+1 n+1 points (x_0,y_0) , (x_1,y_1) , \\dots , (x_n,y_n) (x_0,y_0) , (x_1,y_1) , \\dots , (x_n,y_n) in the xy xy -plane. The coefficients \\mathbf{a} = [a_0,a_1]^T \\mathbf{a} = [a_0,a_1]^T which minimize the sum of squared errors SSE = \\sum_i (y_i - (a_0 + a_1 x_i))^2 SSE = \\sum_i (y_i - (a_0 + a_1 x_i))^2 is the unique solution of the system \\left( X^T X \\right) \\mathbf{a} = X^T \\mathbf{y} \\left( X^T X \\right) \\mathbf{a} = X^T \\mathbf{y} Sketch of Proof. The product X\\mathbf{a} X\\mathbf{a} is in the column space of X X . The line connecting \\mathbf{y} \\mathbf{y} to the nearest point in the column space of X X is perpendicluar to the column space of X X . Therefore X^T \\left( \\mathbf{y} - X \\mathbf{a} \\right) = \\mathbf{0} X^T \\left( \\mathbf{y} - X \\mathbf{a} \\right) = \\mathbf{0} and so \\left( X^T X \\right) \\mathbf{a} = X^T \\mathbf{y} \\left( X^T X \\right) \\mathbf{a} = X^T \\mathbf{y} Examples Fake Noisy Linear Data Let's do an example with some fake data. Let's build a set of random points based on the model y = a_0 + a_1x + \\epsilon y = a_0 + a_1x + \\epsilon for some arbitrary choice of a_0 a_0 and a_1 a_1 . The factor \\epsilon \\epsilon represents some random noise which we model using the normal distribution . We can generate random numbers sampled from the standard normal distribution using the NumPy function numpy.random.rand . The goal is to demonstrate that we can use linear regression to retrieve the coefficeints a_0 a_0 and a_1 a_1 from the linear regression calculation. a0 = 2 a1 = 3 N = 100 x = np.random.rand(100) noise = 0.1*np.random.randn(100) y = a0 + a1*x + noise plt.scatter(x,y); plt.show() Let's use linear regression to retrieve the coefficients a_0 a_0 and a_1 a_1 . Construct the matrix X X : X = np.column_stack([np.ones(N),x]) print(X.shape) (100, 2) Let's look at the first 5 rows of X X to see that it is in the correct form: X[:5,:] array([[1. , 0.92365627], [1. , 0.78757973], [1. , 0.51506055], [1. , 0.51540875], [1. , 0.86563343]]) Use scipy.linalg.solve to solve \\left(X^T X\\right)\\mathbf{a} = \\left(X^T\\right)\\mathbf{y} \\left(X^T X\\right)\\mathbf{a} = \\left(X^T\\right)\\mathbf{y} for \\mathbf{a} \\mathbf{a} : a = la.solve(X.T @ X, X.T @ y) print(a) [2.02783873 2.95308228] We have retrieved the coefficients of the model almost exactly! Let's plot the random data points with the linear regression we just computed. xs = np.linspace(0,1,10) ys = a[0] + a[1]*xs plt.plot(xs,ys,'r',linewidth=4) plt.scatter(x,y); plt.show() Real Kobe Bryant Data Let's work with some real data. Kobe Bryant retired in 2016 with 33643 total points which is the third highest total points in NBA history . How many more years would Kobe Bryant have to had played to pass Kareem Abdul-Jabbar's record 38387 points? Kobe Bryant's peak was the 2005-2006 NBA season. Let's look at Kobe Bryant's total games played and points per game from 2006 to 2016. years = np.array([2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016]) games = [80,77,82,82,73,82,58,78,6,35,66] points = np.array([35.4,31.6,28.3,26.8,27,25.3,27.9,27.3,13.8,22.3,17.6]) fig = plt.figure(figsize=(12,10)) axs = fig.subplots(2,1,sharex=True) axs[0].plot(years,points,'b.',ms=15) axs[0].set_title('Kobe Bryant, Points per Game') axs[0].set_ylim([0,40]) axs[0].grid(True) axs[1].bar(years,games) axs[1].set_title('Kobe Bryant, Games Played') axs[1].set_ylim([0,100]) axs[1].grid(True) plt.show() Kobe was injured for most of the 2013-2014 NBA season and played only 6 games. This is an outlier and so we can drop this data point: years = np.array([2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2015, 2016]) games = np.array([80,77,82,82,73,82,58,78,35,66]) points = np.array([35.4,31.6,28.3,26.8,27,25.3,27.9,27.3,22.3,17.6]) Let's compute the average games played per season over this period: avg_games_per_year = np.mean(games) print(avg_games_per_year) 71.3 Compute the linear model for points per game: X = np.column_stack([np.ones(len(years)),years]) a = la.solve(X.T @ X, X.T @ points) model = a[0] + a[1]*years plt.plot(years,model,years,points,'b.',ms=15) plt.title('Kobe Bryant, Points per Game') plt.ylim([0,40]) plt.grid(True) plt.show() Now we can extrapolate to future years and multiply points per games by games per season and compute the cumulative sum to see Kobe's total points: future_years = np.array([2017,2018,2019,2020,2021]) future_points = (a[0] + a[1]*future_years)*avg_games_per_year total_points = 33643 + np.cumsum(future_points) kareem = 38387*np.ones(len(future_years)) plt.plot(future_years,total_points,future_years,kareem) plt.grid(True) plt.xticks(future_years) plt.title('Kobe Bryant Total Points Prediction') plt.show() Only 4 more years! Polynomial Regression Formulation The same idea works for fitting a degree d d polynomial model y = a_0 + a_1x + a_2x^2 + \\cdots + a_dx^d y = a_0 + a_1x + a_2x^2 + \\cdots + a_dx^d to a set of n+1 n+1 data points (x_0,y_0), (x_1,y_1), \\dots , (x_n,y_n) (x_0,y_0), (x_1,y_1), \\dots , (x_n,y_n) We form the matrices as before but now the Vandermonde matrix X X has d+1 d+1 columns X = \\begin{bmatrix} 1 & x_0 & x_0^2 & \\cdots & x_0^d \\\\\\ 1 & x_1 & x_1^2 & \\cdots & x_1^d \\\\\\ & \\vdots & & & \\vdots \\\\\\ 1 & x_n & x_n^2 & \\cdots & x_n^d \\end{bmatrix} \\ , \\ \\ \\mathbf{y} = \\begin{bmatrix} y_0 \\\\\\ y_1 \\\\\\ \\vdots \\\\\\ y_n \\end{bmatrix} \\ , \\ \\ \\mathbf{a} = \\begin{bmatrix} a_0 \\\\\\ a_1 \\\\\\ a_2 \\\\\\ \\vdots \\\\\\ a_d \\end{bmatrix} X = \\begin{bmatrix} 1 & x_0 & x_0^2 & \\cdots & x_0^d \\\\\\ 1 & x_1 & x_1^2 & \\cdots & x_1^d \\\\\\ & \\vdots & & & \\vdots \\\\\\ 1 & x_n & x_n^2 & \\cdots & x_n^d \\end{bmatrix} \\ , \\ \\ \\mathbf{y} = \\begin{bmatrix} y_0 \\\\\\ y_1 \\\\\\ \\vdots \\\\\\ y_n \\end{bmatrix} \\ , \\ \\ \\mathbf{a} = \\begin{bmatrix} a_0 \\\\\\ a_1 \\\\\\ a_2 \\\\\\ \\vdots \\\\\\ a_d \\end{bmatrix} The coefficients \\mathbf{a} = [a_0,a_1,a_2,\\dots,a_d]^T \\mathbf{a} = [a_0,a_1,a_2,\\dots,a_d]^T which minimize the sum of squared errors SSE SSE is the unique solution of the linear system \\left( X^T X \\right) \\mathbf{a} = \\left( X^T \\right) \\mathbf{y} \\left( X^T X \\right) \\mathbf{a} = \\left( X^T \\right) \\mathbf{y} Example Fake Noisy Quadratic Data Let's build some fake data using a quadratic model y = a_0 + a_1x + a_2x^2 + \\epsilon y = a_0 + a_1x + a_2x^2 + \\epsilon and use linear regression to retrieve the coefficients a_0 a_0 , a_1 a_1 and a_2 a_2 . a0 = 3 a1 = 5 a2 = 8 N = 1000 x = 2*np.random.rand(N) - 1 # Random numbers in the interval (-1,1) noise = np.random.randn(N) y = a0 + a1*x + a2*x**2 + noise plt.scatter(x,y,alpha=0.5,lw=0); plt.show() Construct the matrix X X : X = np.column_stack([np.ones(N),x,x**2]) Use scipy.linalg.solve to solve \\left( X^T X \\right) \\mathbf{a} = \\left( X^T \\right) \\mathbf{y} \\left( X^T X \\right) \\mathbf{a} = \\left( X^T \\right) \\mathbf{y} : a = la.solve((X.T @ X),X.T @ y) Plot the result: xs = np.linspace(-1,1,20) ys = a[0] + a[1]*xs + a[2]*xs**2 plt.plot(xs,ys,'r',linewidth=4) plt.scatter(x,y,alpha=0.5,lw=0) plt.show() Graph Theory A graph is a set of vertices and a set of edges connecting some of the vertices. We will consider simple, undirected, connected graphs: a graph is simple if there are no loops or multiple edges between vertices a graph is undirected if the edges do not have an orientation a graph is connected if each vertex is connected to every other vertex in the graph by a path We can visualize a graph as a set of vertices and edges and answer questions about the graph just by looking at it. However this becomes much more difficult with a large graphs such as a social network graph . Instead, we construct matrices from the graph such as the adjacency matrix and the Laplacian matrix and study their properties. Spectral graph theory is the study of the eigenvalues of the adjacency matrix (and other associated matrices) and the relationships to the structure of G G . NetworkX Let's use the Python package NetworkX to construct and visualize some simple graphs. import networkx as nx Adjacency Matrix The adjacency matrix A_G A_G of a graph G G with n n vertices is the square matrix of size n n such that A_{i,j} = 1 A_{i,j} = 1 if vertices i i and j j are connected by an edge, and A_{i,j} = 0 A_{i,j} = 0 otherwise. We can use networkx to create the adjacency matrix of a graph G G . The function nx.adjacency_matrix returns a sparse matrix and we convert it to a regular NumPy array using the todense method. For example, plot the complete graph with 5 vertices and compute the adjacency matrix: G = nx.complete_graph(5) nx.draw(G,with_labels=True) A = nx.adjacency_matrix(G).todense() print(A) [[0 1 1 1 1] [1 0 1 1 1] [1 1 0 1 1] [1 1 1 0 1] [1 1 1 1 0]] Length of the Shortest Path The length of the shortest path between vertices in a simple, undirected graph G G can be easily computed from the adjacency matrix A_G A_G . In particular, the length of shortest path from vertex i i to vertex j j ( i\\not=j i\\not=j ) is the smallest positive integer k k such that A^k_{i,j} \\not= 0 A^k_{i,j} \\not= 0 . Plot the dodecahedral graph : G = nx.dodecahedral_graph() nx.draw(G,with_labels=True) A = nx.adjacency_matrix(G).todense() print(A) [[0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1] [1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0] [0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0] [0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1] [0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0] [0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0] [0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0] [0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0] [0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0] [0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0] [1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0] [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0] [0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0] [0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0] [0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0] [0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0] [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0] [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0] [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1] [1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]] With this labelling, let's find the length of the shortest path from vertex 0 0 to 15 15 : i = 0 j = 15 k = 1 Ak = A while Ak[i,j] == 0: Ak = Ak @ A k = k + 1 print('Length of the shortest path is',k) Length of the shortest path is 5 Triangles in a Graph A simple result in spectral graph theory is the number of triangles in a graph T(G) T(G) is given by: T(G) = \\frac{1}{6} ( \\lambda_1^3 + \\lambda_2^3 + \\cdots + \\lambda_n^3) T(G) = \\frac{1}{6} ( \\lambda_1^3 + \\lambda_2^3 + \\cdots + \\lambda_n^3) where \\lambda_1 \\leq \\lambda_2 \\leq \\cdots \\leq \\lambda_n \\lambda_1 \\leq \\lambda_2 \\leq \\cdots \\leq \\lambda_n are the eigenvalues of the adjacency matrix. Let's verify this for the simplest case, the complete graph on 3 vertices: C3 = nx.complete_graph(3) nx.draw(C3,with_labels=True) A3 = nx.adjacency_matrix(C3).todense() eigvals, eigvecs = la.eig(A3) int(np.round(np.sum(eigvals.real**3)/6,0)) 1 Let's compute the number of triangles in the complete graph 7 vertices: C7 = nx.complete_graph(7) nx.draw(C7,with_labels=True) A7 = nx.adjacency_matrix(C7).todense() eigvals, eigvecs = la.eig(A7) int(np.round(np.sum(eigvals.real**3)/6,0)) 35 There are 35 triangles in the complete graph with 7 vertices! Let's write a function called triangles which takes a square matrix M and return the sum \\frac{1}{6} ( \\lambda_1^3 + \\lambda_2^3 + \\cdots + \\lambda_n^3) \\frac{1}{6} ( \\lambda_1^3 + \\lambda_2^3 + \\cdots + \\lambda_n^3) where \\lambda_i \\lambda_i are the eigenvalues of the symmetric matrix A = (M + M^T)/2 A = (M + M^T)/2 . Note that M = A M = A if M M is symmetric. The return value is the number of triangles in the graph G G if the input M M is the adjacency matrix. def triangles(M): A = (M + M.T)/2 eigvals, eigvecs = la.eig(A) eigvals = eigvals.real return int(np.round(np.sum(eigvals**3)/6,0)) Next, let's try a Turan graph . G = nx.turan_graph(10,5) nx.draw(G,with_labels=True) A = nx.adjacency_matrix(G).todense() print(A) [[0 0 1 1 1 1 1 1 1 1] [0 0 1 1 1 1 1 1 1 1] [1 1 0 0 1 1 1 1 1 1] [1 1 0 0 1 1 1 1 1 1] [1 1 1 1 0 0 1 1 1 1] [1 1 1 1 0 0 1 1 1 1] [1 1 1 1 1 1 0 0 1 1] [1 1 1 1 1 1 0 0 1 1] [1 1 1 1 1 1 1 1 0 0] [1 1 1 1 1 1 1 1 0 0]] Find the number of triangles: triangles(A) 80 Finally, let's compute the number of triangles in the dodecahedral graph: G = nx.dodecahedral_graph() nx.draw(G,with_labels=True) A = nx.adjacency_matrix(G).todense() print(A) [[0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1] [1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0] [0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0] [0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1] [0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0] [0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0] [0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0] [0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0] [0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0] [0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0] [1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0] [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0] [0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0] [0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0] [0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0] [0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0] [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0] [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0] [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1] [1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]] np.round(triangles(A),2) 0 Exercises Under Construction","title":"Applications"},{"location":"linear-algebra/applications/#applications","text":"import numpy as np import matplotlib.pyplot as plt import scipy.linalg as la","title":"Applications"},{"location":"linear-algebra/applications/#polynomial-interpolation","text":"Polynomial interpolation finds the unique polynomial of degree n n which passes through n+1 n+1 points in the xy xy -plane. For example, two points in the xy xy -plane determine a line and three points determine a parabola.","title":"Polynomial Interpolation"},{"location":"linear-algebra/applications/#formulation","text":"Suppose we have n + 1 n + 1 points in the xy xy -plane (x_0,y_0),(x_1,y_1),\\dots,(x_n,y_n) (x_0,y_0),(x_1,y_1),\\dots,(x_n,y_n) such that all the x x values are distinct ( x_i \\not= x_j x_i \\not= x_j for i \\not= j i \\not= j ). The general form of a degree n n polynomial is p(x) = a_0 + a_1 x + a_2x^2 + \\cdots + a_n x^n p(x) = a_0 + a_1 x + a_2x^2 + \\cdots + a_n x^n If p(x) p(x) is the unique degree n n polynomial which interpolates all the points, then the coefficients a_0 a_0 , a_1 a_1 , \\dots \\dots , a_n a_n satisfy the following equations: \\begin{align} a_0 + a_1x_0 + a_2x_0^2 + \\cdots + a_n x_0^n &= y_0 \\\\\\ a_0 + a_1x_1 + a_2x_1^2 + \\cdots + a_n x_1^n &= y_1 \\\\\\ & \\ \\ \\vdots \\\\\\ a_0 + a_1x_n + a_2x_n^2 + \\cdots + a_n x_n^n &= y_n \\end{align} \\begin{align} a_0 + a_1x_0 + a_2x_0^2 + \\cdots + a_n x_0^n &= y_0 \\\\\\ a_0 + a_1x_1 + a_2x_1^2 + \\cdots + a_n x_1^n &= y_1 \\\\\\ & \\ \\ \\vdots \\\\\\ a_0 + a_1x_n + a_2x_n^2 + \\cdots + a_n x_n^n &= y_n \\end{align} Therefore the vector of coefficients \\mathbf{a} = \\begin{bmatrix} a_0 \\\\\\ a_1 \\\\\\ \\vdots \\\\\\ a_n \\end{bmatrix} \\mathbf{a} = \\begin{bmatrix} a_0 \\\\\\ a_1 \\\\\\ \\vdots \\\\\\ a_n \\end{bmatrix} is the unique the solution of the linear system of equations X \\mathbf{a}=\\mathbf{y} X \\mathbf{a}=\\mathbf{y} where X X is the Vandermonde matrix and \\mathbf{y} \\mathbf{y} is the vector of y y values X = \\begin{bmatrix} 1 & x_0 & x_0^2 & \\dots & x_0^n \\\\\\ 1 & x_1 & x_1^2 & \\dots & x_1^n \\\\\\ & \\vdots & & & \\vdots \\\\\\ 1 & x_n & x_n^2 & \\dots & x_n^n \\\\\\ \\end{bmatrix} \\ \\ \\mathrm{and} \\ \\ \\mathbf{y} = \\begin{bmatrix} y_0 \\\\\\ y_1 \\\\\\ y_2 \\\\\\ \\vdots \\\\\\ y_n \\end{bmatrix} X = \\begin{bmatrix} 1 & x_0 & x_0^2 & \\dots & x_0^n \\\\\\ 1 & x_1 & x_1^2 & \\dots & x_1^n \\\\\\ & \\vdots & & & \\vdots \\\\\\ 1 & x_n & x_n^2 & \\dots & x_n^n \\\\\\ \\end{bmatrix} \\ \\ \\mathrm{and} \\ \\ \\mathbf{y} = \\begin{bmatrix} y_0 \\\\\\ y_1 \\\\\\ y_2 \\\\\\ \\vdots \\\\\\ y_n \\end{bmatrix}","title":"Formulation"},{"location":"linear-algebra/applications/#examples","text":"Simple Parabola Let's do a simple example. We know that y=x^2 y=x^2 is the unique degree 2 polynomial that interpolates the points (-1,1) (-1,1) , (0,0) (0,0) and (1,1) (1,1) . Let's compute the polynomial interpolation of these points and verify the expected result a_0=0 a_0=0 , a_1=0 a_1=0 and a_2=1 a_2=1 . Create the Vandermonde matrix X X with the array of x x values: x = np.array([-1,0,1]) X = np.column_stack([[1,1,1],x,x**2]) print(X) [[ 1 -1 1] [ 1 0 0] [ 1 1 1]] Create the vector \\mathbf{y} \\mathbf{y} of y y values: y = np.array([1,0,1]).reshape(3,1) print(y) [[1] [0] [1]] We expect the solution \\mathbf{a} = [0,0,1]^T \\mathbf{a} = [0,0,1]^T : a = la.solve(X,y) print(a) [[0.] [0.] [1.]] Success! Another Parabola The polynomial interpolation of 3 points (x_0,y_0) (x_0,y_0) , (x_1,y_1) (x_1,y_1) and (x_2,y_2) (x_2,y_2) is the parabola p(x) = a_0 + a_1x + a_2x^2 p(x) = a_0 + a_1x + a_2x^2 such that the coefficients satisfy \\begin{align} a_0 + a_1x_0 + a_2x_0^2 = y_0 \\\\\\ a_0 + a_1x_1 + a_2x_1^2 = y_1 \\\\\\ a_0 + a_1x_2 + a_2x_2^2 = y_2 \\end{align} \\begin{align} a_0 + a_1x_0 + a_2x_0^2 = y_0 \\\\\\ a_0 + a_1x_1 + a_2x_1^2 = y_1 \\\\\\ a_0 + a_1x_2 + a_2x_2^2 = y_2 \\end{align} Let's find the polynomial interpolation of the points (0,6) (0,6) , (3,1) (3,1) and (8,2) (8,2) . Create the Vandermonde matrix X X : x = np.array([0,3,8]) X = np.column_stack([[1,1,1],x,x**2]) print(X) [[ 1 0 0] [ 1 3 9] [ 1 8 64]] And the vector of y y values: y = np.array([6,1,2]).reshape(3,1) print(y) [[6] [1] [2]] Compute the vector \\mathbf{a} \\mathbf{a} of coefficients: a = la.solve(X,y) print(a) [[ 6. ] [-2.36666667] [ 0.23333333]] And plot the result: xs = np.linspace(0,8,20) ys = a[0] + a[1]*xs + a[2]*xs**2 plt.plot(xs,ys,x,y,'b.',ms=20) plt.show() Over Fitting 10 Random Points Now let's interpolate points with x_i=i x_i=i , i=0,\\dots,9 i=0,\\dots,9 , and 10 random integers sampled from [0,10) [0,10) as y y values: N = 10 x = np.arange(0,N) y = np.random.randint(0,10,N) plt.plot(x,y,'r.') plt.show() Create the Vandermonde matrix and verify the first 5 rows and columns: X = np.column_stack([x**k for k in range(0,N)]) print(X[:5,:5]) [[ 1 0 0 0 0] [ 1 1 1 1 1] [ 1 2 4 8 16] [ 1 3 9 27 81] [ 1 4 16 64 256]] We could also use the NumPy function numpy.vander . We specify the option increasing=True so that powers of x_i x_i increase left-to-right: X = np.vander(x,increasing=True) print(X[:5,:5]) [[ 1 0 0 0 0] [ 1 1 1 1 1] [ 1 2 4 8 16] [ 1 3 9 27 81] [ 1 4 16 64 256]] Solve the linear system: a = la.solve(X,y) Plot the interpolation: xs = np.linspace(0,N-1,200) ys = sum([a[k]*xs**k for k in range(0,N)]) plt.plot(x,y,'r.',xs,ys) plt.show() Success! But notice how unstable the curve is. That's why it better to use a cubic spline to interpolate a large number of points. However real-life data is usually very noisy and interpolation is not the best tool to fit a line to data. Instead we would want to take a polynomial with smaller degree (like a line) and fit it as best we can without interpolating the points.","title":"Examples"},{"location":"linear-algebra/applications/#least-squares-linear-regression","text":"Suppose we have n+1 n+1 points (x_0,y_0) , (x_1,y_1) , \\dots , (x_n,y_n) (x_0,y_0) , (x_1,y_1) , \\dots , (x_n,y_n) in the xy xy -plane and we want to fit a line y=a_0 + a_1x y=a_0 + a_1x that \"best fits\" the data. There are different ways to quantify what \"best fit\" means but the most common method is called least squares linear regression . In least squares linear regression, we want to minimize the sum of squared errors SSE = \\sum_i (y_i - (a_0 + a_1 x_i))^2 SSE = \\sum_i (y_i - (a_0 + a_1 x_i))^2","title":"Least Squares Linear Regression"},{"location":"linear-algebra/applications/#formulation_1","text":"If we form matrices X = \\begin{bmatrix} 1 & x_0 \\\\\\ 1 & x_1 \\\\\\ \\vdots & \\vdots \\\\\\ 1 & x_n \\end{bmatrix} \\ , \\ \\ \\mathbf{y} = \\begin{bmatrix} y_0 \\\\\\ y_1 \\\\\\ \\vdots \\\\\\ y_n \\end{bmatrix} \\ , \\ \\ \\mathbf{a} = \\begin{bmatrix} a_0 \\\\\\ a_1 \\end{bmatrix} X = \\begin{bmatrix} 1 & x_0 \\\\\\ 1 & x_1 \\\\\\ \\vdots & \\vdots \\\\\\ 1 & x_n \\end{bmatrix} \\ , \\ \\ \\mathbf{y} = \\begin{bmatrix} y_0 \\\\\\ y_1 \\\\\\ \\vdots \\\\\\ y_n \\end{bmatrix} \\ , \\ \\ \\mathbf{a} = \\begin{bmatrix} a_0 \\\\\\ a_1 \\end{bmatrix} then the sum of squared errors can be expressed as SSE = \\Vert \\mathbf{y} - X \\mathbf{a} \\Vert^2 SSE = \\Vert \\mathbf{y} - X \\mathbf{a} \\Vert^2 Theorem. (Least Squares Linear Regression) Consider n+1 n+1 points (x_0,y_0) , (x_1,y_1) , \\dots , (x_n,y_n) (x_0,y_0) , (x_1,y_1) , \\dots , (x_n,y_n) in the xy xy -plane. The coefficients \\mathbf{a} = [a_0,a_1]^T \\mathbf{a} = [a_0,a_1]^T which minimize the sum of squared errors SSE = \\sum_i (y_i - (a_0 + a_1 x_i))^2 SSE = \\sum_i (y_i - (a_0 + a_1 x_i))^2 is the unique solution of the system \\left( X^T X \\right) \\mathbf{a} = X^T \\mathbf{y} \\left( X^T X \\right) \\mathbf{a} = X^T \\mathbf{y} Sketch of Proof. The product X\\mathbf{a} X\\mathbf{a} is in the column space of X X . The line connecting \\mathbf{y} \\mathbf{y} to the nearest point in the column space of X X is perpendicluar to the column space of X X . Therefore X^T \\left( \\mathbf{y} - X \\mathbf{a} \\right) = \\mathbf{0} X^T \\left( \\mathbf{y} - X \\mathbf{a} \\right) = \\mathbf{0} and so \\left( X^T X \\right) \\mathbf{a} = X^T \\mathbf{y} \\left( X^T X \\right) \\mathbf{a} = X^T \\mathbf{y}","title":"Formulation"},{"location":"linear-algebra/applications/#examples_1","text":"Fake Noisy Linear Data Let's do an example with some fake data. Let's build a set of random points based on the model y = a_0 + a_1x + \\epsilon y = a_0 + a_1x + \\epsilon for some arbitrary choice of a_0 a_0 and a_1 a_1 . The factor \\epsilon \\epsilon represents some random noise which we model using the normal distribution . We can generate random numbers sampled from the standard normal distribution using the NumPy function numpy.random.rand . The goal is to demonstrate that we can use linear regression to retrieve the coefficeints a_0 a_0 and a_1 a_1 from the linear regression calculation. a0 = 2 a1 = 3 N = 100 x = np.random.rand(100) noise = 0.1*np.random.randn(100) y = a0 + a1*x + noise plt.scatter(x,y); plt.show() Let's use linear regression to retrieve the coefficients a_0 a_0 and a_1 a_1 . Construct the matrix X X : X = np.column_stack([np.ones(N),x]) print(X.shape) (100, 2) Let's look at the first 5 rows of X X to see that it is in the correct form: X[:5,:] array([[1. , 0.92365627], [1. , 0.78757973], [1. , 0.51506055], [1. , 0.51540875], [1. , 0.86563343]]) Use scipy.linalg.solve to solve \\left(X^T X\\right)\\mathbf{a} = \\left(X^T\\right)\\mathbf{y} \\left(X^T X\\right)\\mathbf{a} = \\left(X^T\\right)\\mathbf{y} for \\mathbf{a} \\mathbf{a} : a = la.solve(X.T @ X, X.T @ y) print(a) [2.02783873 2.95308228] We have retrieved the coefficients of the model almost exactly! Let's plot the random data points with the linear regression we just computed. xs = np.linspace(0,1,10) ys = a[0] + a[1]*xs plt.plot(xs,ys,'r',linewidth=4) plt.scatter(x,y); plt.show() Real Kobe Bryant Data Let's work with some real data. Kobe Bryant retired in 2016 with 33643 total points which is the third highest total points in NBA history . How many more years would Kobe Bryant have to had played to pass Kareem Abdul-Jabbar's record 38387 points? Kobe Bryant's peak was the 2005-2006 NBA season. Let's look at Kobe Bryant's total games played and points per game from 2006 to 2016. years = np.array([2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016]) games = [80,77,82,82,73,82,58,78,6,35,66] points = np.array([35.4,31.6,28.3,26.8,27,25.3,27.9,27.3,13.8,22.3,17.6]) fig = plt.figure(figsize=(12,10)) axs = fig.subplots(2,1,sharex=True) axs[0].plot(years,points,'b.',ms=15) axs[0].set_title('Kobe Bryant, Points per Game') axs[0].set_ylim([0,40]) axs[0].grid(True) axs[1].bar(years,games) axs[1].set_title('Kobe Bryant, Games Played') axs[1].set_ylim([0,100]) axs[1].grid(True) plt.show() Kobe was injured for most of the 2013-2014 NBA season and played only 6 games. This is an outlier and so we can drop this data point: years = np.array([2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2015, 2016]) games = np.array([80,77,82,82,73,82,58,78,35,66]) points = np.array([35.4,31.6,28.3,26.8,27,25.3,27.9,27.3,22.3,17.6]) Let's compute the average games played per season over this period: avg_games_per_year = np.mean(games) print(avg_games_per_year) 71.3 Compute the linear model for points per game: X = np.column_stack([np.ones(len(years)),years]) a = la.solve(X.T @ X, X.T @ points) model = a[0] + a[1]*years plt.plot(years,model,years,points,'b.',ms=15) plt.title('Kobe Bryant, Points per Game') plt.ylim([0,40]) plt.grid(True) plt.show() Now we can extrapolate to future years and multiply points per games by games per season and compute the cumulative sum to see Kobe's total points: future_years = np.array([2017,2018,2019,2020,2021]) future_points = (a[0] + a[1]*future_years)*avg_games_per_year total_points = 33643 + np.cumsum(future_points) kareem = 38387*np.ones(len(future_years)) plt.plot(future_years,total_points,future_years,kareem) plt.grid(True) plt.xticks(future_years) plt.title('Kobe Bryant Total Points Prediction') plt.show() Only 4 more years!","title":"Examples"},{"location":"linear-algebra/applications/#polynomial-regression","text":"","title":"Polynomial Regression"},{"location":"linear-algebra/applications/#formulation_2","text":"The same idea works for fitting a degree d d polynomial model y = a_0 + a_1x + a_2x^2 + \\cdots + a_dx^d y = a_0 + a_1x + a_2x^2 + \\cdots + a_dx^d to a set of n+1 n+1 data points (x_0,y_0), (x_1,y_1), \\dots , (x_n,y_n) (x_0,y_0), (x_1,y_1), \\dots , (x_n,y_n) We form the matrices as before but now the Vandermonde matrix X X has d+1 d+1 columns X = \\begin{bmatrix} 1 & x_0 & x_0^2 & \\cdots & x_0^d \\\\\\ 1 & x_1 & x_1^2 & \\cdots & x_1^d \\\\\\ & \\vdots & & & \\vdots \\\\\\ 1 & x_n & x_n^2 & \\cdots & x_n^d \\end{bmatrix} \\ , \\ \\ \\mathbf{y} = \\begin{bmatrix} y_0 \\\\\\ y_1 \\\\\\ \\vdots \\\\\\ y_n \\end{bmatrix} \\ , \\ \\ \\mathbf{a} = \\begin{bmatrix} a_0 \\\\\\ a_1 \\\\\\ a_2 \\\\\\ \\vdots \\\\\\ a_d \\end{bmatrix} X = \\begin{bmatrix} 1 & x_0 & x_0^2 & \\cdots & x_0^d \\\\\\ 1 & x_1 & x_1^2 & \\cdots & x_1^d \\\\\\ & \\vdots & & & \\vdots \\\\\\ 1 & x_n & x_n^2 & \\cdots & x_n^d \\end{bmatrix} \\ , \\ \\ \\mathbf{y} = \\begin{bmatrix} y_0 \\\\\\ y_1 \\\\\\ \\vdots \\\\\\ y_n \\end{bmatrix} \\ , \\ \\ \\mathbf{a} = \\begin{bmatrix} a_0 \\\\\\ a_1 \\\\\\ a_2 \\\\\\ \\vdots \\\\\\ a_d \\end{bmatrix} The coefficients \\mathbf{a} = [a_0,a_1,a_2,\\dots,a_d]^T \\mathbf{a} = [a_0,a_1,a_2,\\dots,a_d]^T which minimize the sum of squared errors SSE SSE is the unique solution of the linear system \\left( X^T X \\right) \\mathbf{a} = \\left( X^T \\right) \\mathbf{y} \\left( X^T X \\right) \\mathbf{a} = \\left( X^T \\right) \\mathbf{y}","title":"Formulation"},{"location":"linear-algebra/applications/#example","text":"Fake Noisy Quadratic Data Let's build some fake data using a quadratic model y = a_0 + a_1x + a_2x^2 + \\epsilon y = a_0 + a_1x + a_2x^2 + \\epsilon and use linear regression to retrieve the coefficients a_0 a_0 , a_1 a_1 and a_2 a_2 . a0 = 3 a1 = 5 a2 = 8 N = 1000 x = 2*np.random.rand(N) - 1 # Random numbers in the interval (-1,1) noise = np.random.randn(N) y = a0 + a1*x + a2*x**2 + noise plt.scatter(x,y,alpha=0.5,lw=0); plt.show() Construct the matrix X X : X = np.column_stack([np.ones(N),x,x**2]) Use scipy.linalg.solve to solve \\left( X^T X \\right) \\mathbf{a} = \\left( X^T \\right) \\mathbf{y} \\left( X^T X \\right) \\mathbf{a} = \\left( X^T \\right) \\mathbf{y} : a = la.solve((X.T @ X),X.T @ y) Plot the result: xs = np.linspace(-1,1,20) ys = a[0] + a[1]*xs + a[2]*xs**2 plt.plot(xs,ys,'r',linewidth=4) plt.scatter(x,y,alpha=0.5,lw=0) plt.show()","title":"Example"},{"location":"linear-algebra/applications/#graph-theory","text":"A graph is a set of vertices and a set of edges connecting some of the vertices. We will consider simple, undirected, connected graphs: a graph is simple if there are no loops or multiple edges between vertices a graph is undirected if the edges do not have an orientation a graph is connected if each vertex is connected to every other vertex in the graph by a path We can visualize a graph as a set of vertices and edges and answer questions about the graph just by looking at it. However this becomes much more difficult with a large graphs such as a social network graph . Instead, we construct matrices from the graph such as the adjacency matrix and the Laplacian matrix and study their properties. Spectral graph theory is the study of the eigenvalues of the adjacency matrix (and other associated matrices) and the relationships to the structure of G G .","title":"Graph Theory"},{"location":"linear-algebra/applications/#networkx","text":"Let's use the Python package NetworkX to construct and visualize some simple graphs. import networkx as nx","title":"NetworkX"},{"location":"linear-algebra/applications/#adjacency-matrix","text":"The adjacency matrix A_G A_G of a graph G G with n n vertices is the square matrix of size n n such that A_{i,j} = 1 A_{i,j} = 1 if vertices i i and j j are connected by an edge, and A_{i,j} = 0 A_{i,j} = 0 otherwise. We can use networkx to create the adjacency matrix of a graph G G . The function nx.adjacency_matrix returns a sparse matrix and we convert it to a regular NumPy array using the todense method. For example, plot the complete graph with 5 vertices and compute the adjacency matrix: G = nx.complete_graph(5) nx.draw(G,with_labels=True) A = nx.adjacency_matrix(G).todense() print(A) [[0 1 1 1 1] [1 0 1 1 1] [1 1 0 1 1] [1 1 1 0 1] [1 1 1 1 0]]","title":"Adjacency Matrix"},{"location":"linear-algebra/applications/#length-of-the-shortest-path","text":"The length of the shortest path between vertices in a simple, undirected graph G G can be easily computed from the adjacency matrix A_G A_G . In particular, the length of shortest path from vertex i i to vertex j j ( i\\not=j i\\not=j ) is the smallest positive integer k k such that A^k_{i,j} \\not= 0 A^k_{i,j} \\not= 0 . Plot the dodecahedral graph : G = nx.dodecahedral_graph() nx.draw(G,with_labels=True) A = nx.adjacency_matrix(G).todense() print(A) [[0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1] [1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0] [0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0] [0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1] [0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0] [0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0] [0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0] [0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0] [0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0] [0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0] [1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0] [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0] [0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0] [0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0] [0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0] [0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0] [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0] [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0] [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1] [1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]] With this labelling, let's find the length of the shortest path from vertex 0 0 to 15 15 : i = 0 j = 15 k = 1 Ak = A while Ak[i,j] == 0: Ak = Ak @ A k = k + 1 print('Length of the shortest path is',k) Length of the shortest path is 5","title":"Length of the Shortest Path"},{"location":"linear-algebra/applications/#triangles-in-a-graph","text":"A simple result in spectral graph theory is the number of triangles in a graph T(G) T(G) is given by: T(G) = \\frac{1}{6} ( \\lambda_1^3 + \\lambda_2^3 + \\cdots + \\lambda_n^3) T(G) = \\frac{1}{6} ( \\lambda_1^3 + \\lambda_2^3 + \\cdots + \\lambda_n^3) where \\lambda_1 \\leq \\lambda_2 \\leq \\cdots \\leq \\lambda_n \\lambda_1 \\leq \\lambda_2 \\leq \\cdots \\leq \\lambda_n are the eigenvalues of the adjacency matrix. Let's verify this for the simplest case, the complete graph on 3 vertices: C3 = nx.complete_graph(3) nx.draw(C3,with_labels=True) A3 = nx.adjacency_matrix(C3).todense() eigvals, eigvecs = la.eig(A3) int(np.round(np.sum(eigvals.real**3)/6,0)) 1 Let's compute the number of triangles in the complete graph 7 vertices: C7 = nx.complete_graph(7) nx.draw(C7,with_labels=True) A7 = nx.adjacency_matrix(C7).todense() eigvals, eigvecs = la.eig(A7) int(np.round(np.sum(eigvals.real**3)/6,0)) 35 There are 35 triangles in the complete graph with 7 vertices! Let's write a function called triangles which takes a square matrix M and return the sum \\frac{1}{6} ( \\lambda_1^3 + \\lambda_2^3 + \\cdots + \\lambda_n^3) \\frac{1}{6} ( \\lambda_1^3 + \\lambda_2^3 + \\cdots + \\lambda_n^3) where \\lambda_i \\lambda_i are the eigenvalues of the symmetric matrix A = (M + M^T)/2 A = (M + M^T)/2 . Note that M = A M = A if M M is symmetric. The return value is the number of triangles in the graph G G if the input M M is the adjacency matrix. def triangles(M): A = (M + M.T)/2 eigvals, eigvecs = la.eig(A) eigvals = eigvals.real return int(np.round(np.sum(eigvals**3)/6,0)) Next, let's try a Turan graph . G = nx.turan_graph(10,5) nx.draw(G,with_labels=True) A = nx.adjacency_matrix(G).todense() print(A) [[0 0 1 1 1 1 1 1 1 1] [0 0 1 1 1 1 1 1 1 1] [1 1 0 0 1 1 1 1 1 1] [1 1 0 0 1 1 1 1 1 1] [1 1 1 1 0 0 1 1 1 1] [1 1 1 1 0 0 1 1 1 1] [1 1 1 1 1 1 0 0 1 1] [1 1 1 1 1 1 0 0 1 1] [1 1 1 1 1 1 1 1 0 0] [1 1 1 1 1 1 1 1 0 0]] Find the number of triangles: triangles(A) 80 Finally, let's compute the number of triangles in the dodecahedral graph: G = nx.dodecahedral_graph() nx.draw(G,with_labels=True) A = nx.adjacency_matrix(G).todense() print(A) [[0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1] [1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0] [0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0] [0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1] [0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0] [0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0] [0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0] [0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0] [0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0] [0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0] [1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0] [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0] [0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0] [0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0] [0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0] [0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0] [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0] [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0] [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1] [1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]] np.round(triangles(A),2) 0","title":"Triangles in a Graph"},{"location":"linear-algebra/applications/#exercises","text":"Under Construction","title":"Exercises"},{"location":"linear-algebra/eigenvalues-eigenvectors/","text":"Eigenvalues and Eigenvectors import numpy as np import matplotlib.pyplot as plt import scipy.linalg as la Definition Let A A be a square matrix. A non-zero vector \\mathbf{v} \\mathbf{v} is an eigenvector for A A with eigenvalue \\lambda \\lambda if A\\mathbf{v} = \\lambda \\mathbf{v} A\\mathbf{v} = \\lambda \\mathbf{v} Rearranging the equation, we see that \\mathbf{v} \\mathbf{v} is a solution of the homogeneous system of equations \\left( A - \\lambda I \\right) \\mathbf{v} = \\mathbf{0} \\left( A - \\lambda I \\right) \\mathbf{v} = \\mathbf{0} where I I is the identity matrix of size n n . Non-trivial solutions exist only if the matrix A - \\lambda I A - \\lambda I is singular which means \\mathrm{det}(A - \\lambda I) = 0 \\mathrm{det}(A - \\lambda I) = 0 . Therefore eigenvalues of A A are roots of the characteristic polynomial p(\\lambda) = \\mathrm{det}(A - \\lambda I) p(\\lambda) = \\mathrm{det}(A - \\lambda I) scipy.linalg.eig The function scipy.linalg.eig computes eigenvalues and eigenvectors of a square matrix A A . Let's consider a simple example with a diagonal matrix: A = np.array([[1,0],[0,-2]]) print(A) [[ 1 0] [ 0 -2]] The function la.eig returns a tuple (eigvals,eigvecs) where eigvals is a 1D NumPy array of complex numbers giving the eigenvalues of A A , and eigvecs is a 2D NumPy array with the corresponding eigenvectors in the columns: results = la.eig(A) The eigenvalues of A A are: print(results[0]) [ 1.+0.j -2.+0.j] The corresponding eigenvectors are: print(results[1]) [[1. 0.] [0. 1.]] We can unpack the tuple : eigvals, eigvecs = la.eig(A) print(eigvals) [ 1.+0.j -2.+0.j] print(eigvecs) [[1. 0.] [0. 1.]] If we know that the eigenvalues are real numbers (ie. if A A is symmetric), then we can use the NumPy array method .real to convert the array of eigenvalues to real numbers: eigvals = eigvals.real print(eigvals) [ 1. -2.] Notice that the position of an eigenvalue in the array eigvals correspond to the column in eigvecs with its eigenvector: lambda1 = eigvals[1] print(lambda1) -2.0 v1 = eigvecs[:,1].reshape(2,1) print(v1) [[0.] [1.]] A @ v1 array([[ 0.], [-2.]]) lambda1 * v1 array([[-0.], [-2.]]) Examples Symmetric Matrices The eigenvalues of a symmetric matrix are always real and the eigenvectors are always orthogonal! Let's verify these facts with some random matrices: n = 4 P = np.random.randint(0,10,(n,n)) print(P) [[7 0 6 2] [9 5 1 3] [0 2 2 5] [6 8 8 6]] Create the symmetric matrix S = P P^T S = P P^T : S = P @ P.T print(S) [[ 89 75 22 102] [ 75 116 27 120] [ 22 27 33 62] [102 120 62 200]] Let's unpack the eigenvalues and eigenvectors of S S : evals, evecs = la.eig(S) print(evals) [361.75382302+0.j 42.74593101+0.j 26.33718907+0.j 7.16305691+0.j] The eigenvalues all have zero imaginary part and so they are indeed real numbers: evals = evals.real print(evals) [361.75382302 42.74593101 26.33718907 7.16305691] The corresponding eigenvectors of A A are: print(evecs) [[-0.42552429 -0.42476765 0.76464379 -0.23199439] [-0.50507589 -0.54267519 -0.64193252 -0.19576676] [-0.20612674 0.54869183 -0.05515612 -0.80833585] [-0.72203822 0.4733005 0.01415338 0.50442752]] Let's check that the eigenvectors are orthogonal to each other: v1 = evecs[:,0] # First column is the first eigenvector print(v1) [-0.42552429 -0.50507589 -0.20612674 -0.72203822] v2 = evecs[:,1] # Second column is the second eigenvector print(v2) [-0.42476765 -0.54267519 0.54869183 0.4733005 ] v1 @ v2 -1.1102230246251565e-16 The dot product of eigenvectors \\mathbf{v}_1 \\mathbf{v}_1 and \\mathbf{v}_2 \\mathbf{v}_2 is zero (the number above is very close to zero and is due to rounding errors in the computations) and so they are orthogonal! Diagonalization A square matrix M M is diagonalizable if it is similar to a diagonal matrix. In other words, M M is diagonalizable if there exists an invertible matrix P P such that D = P^{-1}MP D = P^{-1}MP is a diagonal matrix. A beautiful result in linear algebra is that a square matrix M M of size n n is diagonalizable if and only if M M has n n independent eigevectors. Furthermore, M = PDP^{-1} M = PDP^{-1} where the columns of P P are the eigenvectors of M M and D D has corresponding eigenvalues along the diagonal. Let's use this to construct a matrix with given eigenvalues \\lambda_1 = 3, \\lambda_2 = 1 \\lambda_1 = 3, \\lambda_2 = 1 , and eigenvectors v_1 = [1,1]^T, v_2 = [1,-1]^T v_1 = [1,1]^T, v_2 = [1,-1]^T . P = np.array([[1,1],[1,-1]]) print(P) [[ 1 1] [ 1 -1]] D = np.diag((3,1)) print(D) [[3 0] [0 1]] M = P @ D @ la.inv(P) print(M) [[2. 1.] [1. 2.]] Let's verify that the eigenvalues of M M are 3 and 1: evals, evecs = la.eig(M) print(evals) [3.+0.j 1.+0.j] Verify the eigenvectors: print(evecs) [[ 0.70710678 -0.70710678] [ 0.70710678 0.70710678]] Matrix Powers Let M M be a square matrix. Computing powers of M M by matrix multiplication M^k = \\underbrace{M M \\cdots M}_k M^k = \\underbrace{M M \\cdots M}_k is computationally expensive. Instead, let's use diagonalization to compute M^k M^k more efficiently M^k = \\left( P D P^{-1} \\right)^k = \\underbrace{P D P^{-1} P D P^{-1} \\cdots P D P^{-1}}_k = P D^k P^{-1} M^k = \\left( P D P^{-1} \\right)^k = \\underbrace{P D P^{-1} P D P^{-1} \\cdots P D P^{-1}}_k = P D^k P^{-1} Let's compute M^{20} M^{20} both ways and compare execution time. Pinv = la.inv(P) k = 20 %%timeit result = M.copy() for _ in range(1,k): result = result @ M 42.1 \u00b5s \u00b1 11.4 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each) Let's use diagonalization to do the same computation. %%timeit P @ D**k @ Pinv 6.42 \u00b5s \u00b1 1.36 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each) Diagonalization computes M^{k} M^{k} much faster! Exercises Under construction","title":"Eigenvalues and Eigenvectors"},{"location":"linear-algebra/eigenvalues-eigenvectors/#eigenvalues-and-eigenvectors","text":"import numpy as np import matplotlib.pyplot as plt import scipy.linalg as la","title":"Eigenvalues and Eigenvectors"},{"location":"linear-algebra/eigenvalues-eigenvectors/#definition","text":"Let A A be a square matrix. A non-zero vector \\mathbf{v} \\mathbf{v} is an eigenvector for A A with eigenvalue \\lambda \\lambda if A\\mathbf{v} = \\lambda \\mathbf{v} A\\mathbf{v} = \\lambda \\mathbf{v} Rearranging the equation, we see that \\mathbf{v} \\mathbf{v} is a solution of the homogeneous system of equations \\left( A - \\lambda I \\right) \\mathbf{v} = \\mathbf{0} \\left( A - \\lambda I \\right) \\mathbf{v} = \\mathbf{0} where I I is the identity matrix of size n n . Non-trivial solutions exist only if the matrix A - \\lambda I A - \\lambda I is singular which means \\mathrm{det}(A - \\lambda I) = 0 \\mathrm{det}(A - \\lambda I) = 0 . Therefore eigenvalues of A A are roots of the characteristic polynomial p(\\lambda) = \\mathrm{det}(A - \\lambda I) p(\\lambda) = \\mathrm{det}(A - \\lambda I)","title":"Definition"},{"location":"linear-algebra/eigenvalues-eigenvectors/#scipylinalgeig","text":"The function scipy.linalg.eig computes eigenvalues and eigenvectors of a square matrix A A . Let's consider a simple example with a diagonal matrix: A = np.array([[1,0],[0,-2]]) print(A) [[ 1 0] [ 0 -2]] The function la.eig returns a tuple (eigvals,eigvecs) where eigvals is a 1D NumPy array of complex numbers giving the eigenvalues of A A , and eigvecs is a 2D NumPy array with the corresponding eigenvectors in the columns: results = la.eig(A) The eigenvalues of A A are: print(results[0]) [ 1.+0.j -2.+0.j] The corresponding eigenvectors are: print(results[1]) [[1. 0.] [0. 1.]] We can unpack the tuple : eigvals, eigvecs = la.eig(A) print(eigvals) [ 1.+0.j -2.+0.j] print(eigvecs) [[1. 0.] [0. 1.]] If we know that the eigenvalues are real numbers (ie. if A A is symmetric), then we can use the NumPy array method .real to convert the array of eigenvalues to real numbers: eigvals = eigvals.real print(eigvals) [ 1. -2.] Notice that the position of an eigenvalue in the array eigvals correspond to the column in eigvecs with its eigenvector: lambda1 = eigvals[1] print(lambda1) -2.0 v1 = eigvecs[:,1].reshape(2,1) print(v1) [[0.] [1.]] A @ v1 array([[ 0.], [-2.]]) lambda1 * v1 array([[-0.], [-2.]])","title":"scipy.linalg.eig"},{"location":"linear-algebra/eigenvalues-eigenvectors/#examples","text":"","title":"Examples"},{"location":"linear-algebra/eigenvalues-eigenvectors/#symmetric-matrices","text":"The eigenvalues of a symmetric matrix are always real and the eigenvectors are always orthogonal! Let's verify these facts with some random matrices: n = 4 P = np.random.randint(0,10,(n,n)) print(P) [[7 0 6 2] [9 5 1 3] [0 2 2 5] [6 8 8 6]] Create the symmetric matrix S = P P^T S = P P^T : S = P @ P.T print(S) [[ 89 75 22 102] [ 75 116 27 120] [ 22 27 33 62] [102 120 62 200]] Let's unpack the eigenvalues and eigenvectors of S S : evals, evecs = la.eig(S) print(evals) [361.75382302+0.j 42.74593101+0.j 26.33718907+0.j 7.16305691+0.j] The eigenvalues all have zero imaginary part and so they are indeed real numbers: evals = evals.real print(evals) [361.75382302 42.74593101 26.33718907 7.16305691] The corresponding eigenvectors of A A are: print(evecs) [[-0.42552429 -0.42476765 0.76464379 -0.23199439] [-0.50507589 -0.54267519 -0.64193252 -0.19576676] [-0.20612674 0.54869183 -0.05515612 -0.80833585] [-0.72203822 0.4733005 0.01415338 0.50442752]] Let's check that the eigenvectors are orthogonal to each other: v1 = evecs[:,0] # First column is the first eigenvector print(v1) [-0.42552429 -0.50507589 -0.20612674 -0.72203822] v2 = evecs[:,1] # Second column is the second eigenvector print(v2) [-0.42476765 -0.54267519 0.54869183 0.4733005 ] v1 @ v2 -1.1102230246251565e-16 The dot product of eigenvectors \\mathbf{v}_1 \\mathbf{v}_1 and \\mathbf{v}_2 \\mathbf{v}_2 is zero (the number above is very close to zero and is due to rounding errors in the computations) and so they are orthogonal!","title":"Symmetric Matrices"},{"location":"linear-algebra/eigenvalues-eigenvectors/#diagonalization","text":"A square matrix M M is diagonalizable if it is similar to a diagonal matrix. In other words, M M is diagonalizable if there exists an invertible matrix P P such that D = P^{-1}MP D = P^{-1}MP is a diagonal matrix. A beautiful result in linear algebra is that a square matrix M M of size n n is diagonalizable if and only if M M has n n independent eigevectors. Furthermore, M = PDP^{-1} M = PDP^{-1} where the columns of P P are the eigenvectors of M M and D D has corresponding eigenvalues along the diagonal. Let's use this to construct a matrix with given eigenvalues \\lambda_1 = 3, \\lambda_2 = 1 \\lambda_1 = 3, \\lambda_2 = 1 , and eigenvectors v_1 = [1,1]^T, v_2 = [1,-1]^T v_1 = [1,1]^T, v_2 = [1,-1]^T . P = np.array([[1,1],[1,-1]]) print(P) [[ 1 1] [ 1 -1]] D = np.diag((3,1)) print(D) [[3 0] [0 1]] M = P @ D @ la.inv(P) print(M) [[2. 1.] [1. 2.]] Let's verify that the eigenvalues of M M are 3 and 1: evals, evecs = la.eig(M) print(evals) [3.+0.j 1.+0.j] Verify the eigenvectors: print(evecs) [[ 0.70710678 -0.70710678] [ 0.70710678 0.70710678]]","title":"Diagonalization"},{"location":"linear-algebra/eigenvalues-eigenvectors/#matrix-powers","text":"Let M M be a square matrix. Computing powers of M M by matrix multiplication M^k = \\underbrace{M M \\cdots M}_k M^k = \\underbrace{M M \\cdots M}_k is computationally expensive. Instead, let's use diagonalization to compute M^k M^k more efficiently M^k = \\left( P D P^{-1} \\right)^k = \\underbrace{P D P^{-1} P D P^{-1} \\cdots P D P^{-1}}_k = P D^k P^{-1} M^k = \\left( P D P^{-1} \\right)^k = \\underbrace{P D P^{-1} P D P^{-1} \\cdots P D P^{-1}}_k = P D^k P^{-1} Let's compute M^{20} M^{20} both ways and compare execution time. Pinv = la.inv(P) k = 20 %%timeit result = M.copy() for _ in range(1,k): result = result @ M 42.1 \u00b5s \u00b1 11.4 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each) Let's use diagonalization to do the same computation. %%timeit P @ D**k @ Pinv 6.42 \u00b5s \u00b1 1.36 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each) Diagonalization computes M^{k} M^{k} much faster!","title":"Matrix Powers"},{"location":"linear-algebra/eigenvalues-eigenvectors/#exercises","text":"Under construction","title":"Exercises"},{"location":"linear-algebra/linear-algebra-scipy/","text":"Linear Algebra with SciPy The main Python package for linear algebra is the SciPy subpackage scipy.linalg which builds on NumPy. Let's import both packages: import numpy as np import scipy.linalg as la NumPy Arrays Let's begin with a quick review of NumPy arrays . We can think of a 1D NumPy array as a list of numbers. We can think of a 2D NumPy array as a matrix. And we can think of a 3D array as a cube of numbers. When we select a row or column from a 2D NumPy array, the result is a 1D NumPy array (called a slice ). This is different from MATLAB where when you select a column from a matrix it's returned as a column vector which is a 2D MATLAB matrix. It can get a bit confusing and so we need to keep track of the shape, size and dimension of our NumPy arrays. Array Attributes Create a 1D (one-dimensional) NumPy array and verify its dimensions, shape and size. a = np.array([1,3,-2,1]) print(a) [ 1 3 -2 1] Verify the number of dimensions: a.ndim 1 Verify the shape of the array: a.shape (4,) The shape of an array is returned as a Python tuple . The output in the cell above is a tuple of length 1. And we verify the size of the array (ie. the total number of entries in the array): a.size 4 Create a 2D (two-dimensional) NumPy array (ie. matrix): M = np.array([[1,2],[3,7],[-1,5]]) print(M) [[ 1 2] [ 3 7] [-1 5]] Verify the number of dimensions: M.ndim 2 Verify the shape of the array: M.shape (3, 2) Finally, verify the total number of entries in the array: M.size 6 Select a row or column from a 2D NumPy array and we get a 1D array: col = M[:,1] print(col) [2 7 5] Verify the number of dimensions of the slice: col.ndim 1 Verify the shape and size of the slice: col.shape (3,) col.size 3 When we select a row of column from a 2D NumPy array, the result is a 1D NumPy array. However, we may want to select a column as a 2D column vector. This requires us to use the reshape method. For example, create a 2D column vector from the 1D slice selected from the matrix M above: print(col) [2 7 5] column = np.array([2,7,5]).reshape(3,1) print(column) [[2] [7] [5]] Verify the dimensions, shape and size of the array: print('Dimensions:', column.ndim) print('Shape:', column.shape) print('Size:', column.size) Dimensions: 2 Shape: (3, 1) Size: 3 The variables col and column are different types of objects even though they have the \"same\" data. print(col) [2 7 5] print('Dimensions:',col.ndim) print('Shape:',col.shape) print('Size:',col.size) Dimensions: 1 Shape: (3,) Size: 3 Matrix Operations and Functions Arithmetic Operations Recall that arithmetic array operations + , - , / , * and ** are performed elementwise on NumPy arrays. Let's create a NumPy array and do some computations: M = np.array([[3,4],[-1,5]]) print(M) [[ 3 4] [-1 5]] M * M array([[ 9, 16], [ 1, 25]]) Matrix Multiplication We use the @ operator to do matrix multiplication with NumPy arrays: M @ M array([[ 5, 32], [-8, 21]]) Let's compute 2I + 3A - AB 2I + 3A - AB for A = \\begin{bmatrix} 1 & 3 \\\\\\ -1 & 7 \\end{bmatrix} \\ \\ \\ \\ B = \\begin{bmatrix} 5 & 2 \\\\\\ 1 & 2 \\end{bmatrix} A = \\begin{bmatrix} 1 & 3 \\\\\\ -1 & 7 \\end{bmatrix} \\ \\ \\ \\ B = \\begin{bmatrix} 5 & 2 \\\\\\ 1 & 2 \\end{bmatrix} and I I is the identity matrix of size 2: A = np.array([[1,3],[-1,7]]) print(A) [[ 1 3] [-1 7]] B = np.array([[5,2],[1,2]]) print(B) [[5 2] [1 2]] I = np.eye(2) print(I) [[1. 0.] [0. 1.]] 2*I + 3*A - A@B array([[-3., 1.], [-5., 11.]]) Matrix Powers There's no symbol for matrix powers and so we must import the function matrix_power from the subpackage numpy.linalg . from numpy.linalg import matrix_power as mpow M = np.array([[3,4],[-1,5]]) print(M) [[ 3 4] [-1 5]] mpow(M,2) array([[ 5, 32], [-8, 21]]) mpow(M,5) array([[-1525, 3236], [ -809, 93]]) Compare with the matrix multiplcation operator: M @ M @ M @ M @ M array([[-1525, 3236], [ -809, 93]]) mpow(M,3) array([[-17, 180], [-45, 73]]) M @ M @ M array([[-17, 180], [-45, 73]]) Tranpose We can take the transpose with .T attribute: print(M) [[ 3 4] [-1 5]] print(M.T) [[ 3 -1] [ 4 5]] Notice that M M^T M M^T is a symmetric matrix: M @ M.T array([[25, 17], [17, 26]]) Inverse We can find the inverse using the function scipy.linalg.inv : A = np.array([[1,2],[3,4]]) print(A) [[1 2] [3 4]] la.inv(A) array([[-2. , 1. ], [ 1.5, -0.5]]) Trace We can find the trace of a matrix using the function numpy.trace : np.trace(A) 5 Norm Under construction Determinant We find the determinant using the function scipy.linalg.det : A = np.array([[1,2],[3,4]]) print(A) [[1 2] [3 4]] la.det(A) -2.0 Dot Product Under construction Examples Characteristic Polynomials and Cayley-Hamilton Theorem The characteristic polynomial of a 2 by 2 square matrix A A is p_A(\\lambda) = \\det(A - \\lambda I) = \\lambda^2 - \\mathrm{tr}(A) \\lambda + \\mathrm{det}(A) p_A(\\lambda) = \\det(A - \\lambda I) = \\lambda^2 - \\mathrm{tr}(A) \\lambda + \\mathrm{det}(A) The Cayley-Hamilton Theorem states that any square matrix satisfies its characteristic polynomial. For a matrix A A of size 2, this means that p_A(A) = A^2 - \\mathrm{tr}(A) A + \\mathrm{det}(A) I = 0 p_A(A) = A^2 - \\mathrm{tr}(A) A + \\mathrm{det}(A) I = 0 Let's verify the Cayley-Hamilton Theorem for a few different matrices. print(A) [[1 2] [3 4]] trace_A = np.trace(A) det_A = la.det(A) I = np.eye(2) A @ A - trace_A * A + det_A * I array([[0., 0.], [0., 0.]]) Let's do this again for some random matrices: N = np.random.randint(0,10,[2,2]) print(N) [[1 9] [4 3]] trace_N = np.trace(N) det_N = la.det(N) I = np.eye(2) N @ N - trace_N * N + det_N * I array([[0., 0.], [0., 0.]]) Projections The formula to project a vector v v onto a vector w w is \\mathrm{proj}_w(v) = \\frac{v \\cdot w}{w \\cdot w} w \\mathrm{proj}_w(v) = \\frac{v \\cdot w}{w \\cdot w} w Let's write a function called proj which computes the projection v v onto w w . def proj(v,w): '''Project vector v onto w.''' v = np.array(v) w = np.array(w) return np.sum(v * w)/np.sum(w * w) * w # or (v @ w)/(w @ w) * w proj([1,2,3],[1,1,1]) array([2., 2., 2.]) Exercises Write a function which takes an input parameter A A , i i and j j and returns the dot product of the i i th and j j th row (indexing starts at 0). Compute the matrix equation AB + 2B^2 - I AB + 2B^2 - I for matrices A = \\begin{bmatrix} 3 & 4 \\\\\\ -1 & 2 \\end{bmatrix} A = \\begin{bmatrix} 3 & 4 \\\\\\ -1 & 2 \\end{bmatrix} and B = \\begin{bmatrix} 5 & 2 \\\\\\ 8 & -3 \\end{bmatrix} B = \\begin{bmatrix} 5 & 2 \\\\\\ 8 & -3 \\end{bmatrix} .","title":"Linear Algebra with SciPy"},{"location":"linear-algebra/linear-algebra-scipy/#linear-algebra-with-scipy","text":"The main Python package for linear algebra is the SciPy subpackage scipy.linalg which builds on NumPy. Let's import both packages: import numpy as np import scipy.linalg as la","title":"Linear Algebra with SciPy"},{"location":"linear-algebra/linear-algebra-scipy/#numpy-arrays","text":"Let's begin with a quick review of NumPy arrays . We can think of a 1D NumPy array as a list of numbers. We can think of a 2D NumPy array as a matrix. And we can think of a 3D array as a cube of numbers. When we select a row or column from a 2D NumPy array, the result is a 1D NumPy array (called a slice ). This is different from MATLAB where when you select a column from a matrix it's returned as a column vector which is a 2D MATLAB matrix. It can get a bit confusing and so we need to keep track of the shape, size and dimension of our NumPy arrays.","title":"NumPy Arrays"},{"location":"linear-algebra/linear-algebra-scipy/#array-attributes","text":"Create a 1D (one-dimensional) NumPy array and verify its dimensions, shape and size. a = np.array([1,3,-2,1]) print(a) [ 1 3 -2 1] Verify the number of dimensions: a.ndim 1 Verify the shape of the array: a.shape (4,) The shape of an array is returned as a Python tuple . The output in the cell above is a tuple of length 1. And we verify the size of the array (ie. the total number of entries in the array): a.size 4 Create a 2D (two-dimensional) NumPy array (ie. matrix): M = np.array([[1,2],[3,7],[-1,5]]) print(M) [[ 1 2] [ 3 7] [-1 5]] Verify the number of dimensions: M.ndim 2 Verify the shape of the array: M.shape (3, 2) Finally, verify the total number of entries in the array: M.size 6 Select a row or column from a 2D NumPy array and we get a 1D array: col = M[:,1] print(col) [2 7 5] Verify the number of dimensions of the slice: col.ndim 1 Verify the shape and size of the slice: col.shape (3,) col.size 3 When we select a row of column from a 2D NumPy array, the result is a 1D NumPy array. However, we may want to select a column as a 2D column vector. This requires us to use the reshape method. For example, create a 2D column vector from the 1D slice selected from the matrix M above: print(col) [2 7 5] column = np.array([2,7,5]).reshape(3,1) print(column) [[2] [7] [5]] Verify the dimensions, shape and size of the array: print('Dimensions:', column.ndim) print('Shape:', column.shape) print('Size:', column.size) Dimensions: 2 Shape: (3, 1) Size: 3 The variables col and column are different types of objects even though they have the \"same\" data. print(col) [2 7 5] print('Dimensions:',col.ndim) print('Shape:',col.shape) print('Size:',col.size) Dimensions: 1 Shape: (3,) Size: 3","title":"Array Attributes"},{"location":"linear-algebra/linear-algebra-scipy/#matrix-operations-and-functions","text":"","title":"Matrix Operations and Functions"},{"location":"linear-algebra/linear-algebra-scipy/#arithmetic-operations","text":"Recall that arithmetic array operations + , - , / , * and ** are performed elementwise on NumPy arrays. Let's create a NumPy array and do some computations: M = np.array([[3,4],[-1,5]]) print(M) [[ 3 4] [-1 5]] M * M array([[ 9, 16], [ 1, 25]])","title":"Arithmetic Operations"},{"location":"linear-algebra/linear-algebra-scipy/#matrix-multiplication","text":"We use the @ operator to do matrix multiplication with NumPy arrays: M @ M array([[ 5, 32], [-8, 21]]) Let's compute 2I + 3A - AB 2I + 3A - AB for A = \\begin{bmatrix} 1 & 3 \\\\\\ -1 & 7 \\end{bmatrix} \\ \\ \\ \\ B = \\begin{bmatrix} 5 & 2 \\\\\\ 1 & 2 \\end{bmatrix} A = \\begin{bmatrix} 1 & 3 \\\\\\ -1 & 7 \\end{bmatrix} \\ \\ \\ \\ B = \\begin{bmatrix} 5 & 2 \\\\\\ 1 & 2 \\end{bmatrix} and I I is the identity matrix of size 2: A = np.array([[1,3],[-1,7]]) print(A) [[ 1 3] [-1 7]] B = np.array([[5,2],[1,2]]) print(B) [[5 2] [1 2]] I = np.eye(2) print(I) [[1. 0.] [0. 1.]] 2*I + 3*A - A@B array([[-3., 1.], [-5., 11.]])","title":"Matrix Multiplication"},{"location":"linear-algebra/linear-algebra-scipy/#matrix-powers","text":"There's no symbol for matrix powers and so we must import the function matrix_power from the subpackage numpy.linalg . from numpy.linalg import matrix_power as mpow M = np.array([[3,4],[-1,5]]) print(M) [[ 3 4] [-1 5]] mpow(M,2) array([[ 5, 32], [-8, 21]]) mpow(M,5) array([[-1525, 3236], [ -809, 93]]) Compare with the matrix multiplcation operator: M @ M @ M @ M @ M array([[-1525, 3236], [ -809, 93]]) mpow(M,3) array([[-17, 180], [-45, 73]]) M @ M @ M array([[-17, 180], [-45, 73]])","title":"Matrix Powers"},{"location":"linear-algebra/linear-algebra-scipy/#tranpose","text":"We can take the transpose with .T attribute: print(M) [[ 3 4] [-1 5]] print(M.T) [[ 3 -1] [ 4 5]] Notice that M M^T M M^T is a symmetric matrix: M @ M.T array([[25, 17], [17, 26]])","title":"Tranpose"},{"location":"linear-algebra/linear-algebra-scipy/#inverse","text":"We can find the inverse using the function scipy.linalg.inv : A = np.array([[1,2],[3,4]]) print(A) [[1 2] [3 4]] la.inv(A) array([[-2. , 1. ], [ 1.5, -0.5]])","title":"Inverse"},{"location":"linear-algebra/linear-algebra-scipy/#trace","text":"We can find the trace of a matrix using the function numpy.trace : np.trace(A) 5","title":"Trace"},{"location":"linear-algebra/linear-algebra-scipy/#norm","text":"Under construction","title":"Norm"},{"location":"linear-algebra/linear-algebra-scipy/#determinant","text":"We find the determinant using the function scipy.linalg.det : A = np.array([[1,2],[3,4]]) print(A) [[1 2] [3 4]] la.det(A) -2.0","title":"Determinant"},{"location":"linear-algebra/linear-algebra-scipy/#dot-product","text":"Under construction","title":"Dot Product"},{"location":"linear-algebra/linear-algebra-scipy/#examples","text":"","title":"Examples"},{"location":"linear-algebra/linear-algebra-scipy/#characteristic-polynomials-and-cayley-hamilton-theorem","text":"The characteristic polynomial of a 2 by 2 square matrix A A is p_A(\\lambda) = \\det(A - \\lambda I) = \\lambda^2 - \\mathrm{tr}(A) \\lambda + \\mathrm{det}(A) p_A(\\lambda) = \\det(A - \\lambda I) = \\lambda^2 - \\mathrm{tr}(A) \\lambda + \\mathrm{det}(A) The Cayley-Hamilton Theorem states that any square matrix satisfies its characteristic polynomial. For a matrix A A of size 2, this means that p_A(A) = A^2 - \\mathrm{tr}(A) A + \\mathrm{det}(A) I = 0 p_A(A) = A^2 - \\mathrm{tr}(A) A + \\mathrm{det}(A) I = 0 Let's verify the Cayley-Hamilton Theorem for a few different matrices. print(A) [[1 2] [3 4]] trace_A = np.trace(A) det_A = la.det(A) I = np.eye(2) A @ A - trace_A * A + det_A * I array([[0., 0.], [0., 0.]]) Let's do this again for some random matrices: N = np.random.randint(0,10,[2,2]) print(N) [[1 9] [4 3]] trace_N = np.trace(N) det_N = la.det(N) I = np.eye(2) N @ N - trace_N * N + det_N * I array([[0., 0.], [0., 0.]])","title":"Characteristic Polynomials and Cayley-Hamilton Theorem"},{"location":"linear-algebra/linear-algebra-scipy/#projections","text":"The formula to project a vector v v onto a vector w w is \\mathrm{proj}_w(v) = \\frac{v \\cdot w}{w \\cdot w} w \\mathrm{proj}_w(v) = \\frac{v \\cdot w}{w \\cdot w} w Let's write a function called proj which computes the projection v v onto w w . def proj(v,w): '''Project vector v onto w.''' v = np.array(v) w = np.array(w) return np.sum(v * w)/np.sum(w * w) * w # or (v @ w)/(w @ w) * w proj([1,2,3],[1,1,1]) array([2., 2., 2.])","title":"Projections"},{"location":"linear-algebra/linear-algebra-scipy/#exercises","text":"Write a function which takes an input parameter A A , i i and j j and returns the dot product of the i i th and j j th row (indexing starts at 0). Compute the matrix equation AB + 2B^2 - I AB + 2B^2 - I for matrices A = \\begin{bmatrix} 3 & 4 \\\\\\ -1 & 2 \\end{bmatrix} A = \\begin{bmatrix} 3 & 4 \\\\\\ -1 & 2 \\end{bmatrix} and B = \\begin{bmatrix} 5 & 2 \\\\\\ 8 & -3 \\end{bmatrix} B = \\begin{bmatrix} 5 & 2 \\\\\\ 8 & -3 \\end{bmatrix} .","title":"Exercises"},{"location":"linear-algebra/solving-linear-systems/","text":"Solving Linear Systems import numpy as np import matplotlib.pyplot as plt import scipy.linalg as la %matplotlib inline Linear Systems A linear system of equations is a collection of linear equations \\begin{align} a_{0,0}x_0 + a_{0,1}x_2 + \\cdots + a_{0,n}x_n & = b_0 \\\\\\ a_{1,0}x_0 + a_{1,1}x_2 + \\cdots + a_{1,n}x_n & = b_1 \\\\\\ & \\vdots \\\\\\ a_{m,0}x_0 + a_{m,1}x_2 + \\cdots + a_{m,n}x_n & = b_m \\\\\\ \\end{align} \\begin{align} a_{0,0}x_0 + a_{0,1}x_2 + \\cdots + a_{0,n}x_n & = b_0 \\\\\\ a_{1,0}x_0 + a_{1,1}x_2 + \\cdots + a_{1,n}x_n & = b_1 \\\\\\ & \\vdots \\\\\\ a_{m,0}x_0 + a_{m,1}x_2 + \\cdots + a_{m,n}x_n & = b_m \\\\\\ \\end{align} In matrix notation, a linear system is A \\mathbf{x}= \\mathbf{b} A \\mathbf{x}= \\mathbf{b} where A = \\begin{bmatrix} a_{0,0} & a_{0,1} & \\cdots & a_{0,n} \\\\\\ a_{1,0} & a_{1,1} & \\cdots & a_{1,n} \\\\\\ \\vdots & & & \\vdots \\\\\\ a_{m,0} & a_{m,1} & \\cdots & a_{m,n} \\\\\\ \\end{bmatrix} \\ \\ , \\ \\ \\mathbf{x} = \\begin{bmatrix} x_0 \\\\\\ x_1 \\\\\\ \\vdots \\\\\\ x_n \\end{bmatrix} \\ \\ , \\ \\ \\mathbf{b} = \\begin{bmatrix} b_0 \\\\\\ b_1 \\\\\\ \\vdots \\\\\\ b_m \\end{bmatrix} A = \\begin{bmatrix} a_{0,0} & a_{0,1} & \\cdots & a_{0,n} \\\\\\ a_{1,0} & a_{1,1} & \\cdots & a_{1,n} \\\\\\ \\vdots & & & \\vdots \\\\\\ a_{m,0} & a_{m,1} & \\cdots & a_{m,n} \\\\\\ \\end{bmatrix} \\ \\ , \\ \\ \\mathbf{x} = \\begin{bmatrix} x_0 \\\\\\ x_1 \\\\\\ \\vdots \\\\\\ x_n \\end{bmatrix} \\ \\ , \\ \\ \\mathbf{b} = \\begin{bmatrix} b_0 \\\\\\ b_1 \\\\\\ \\vdots \\\\\\ b_m \\end{bmatrix} Gaussian elimination The general procedure to solve a linear system of equation is called Gaussian elimination . The idea is to perform elementary row operations to reduce the system to its row echelon form and then solve. Elementary Row Operations Elementary row operations include: Add k k times row j j to row i i . Multiply row i i by scalar k k . Switch rows i i and j j . Each of the elementary row operations is the result of matrix multiplication by an elementary matrix (on the left). To add k k times row i i to row j j in a matrix A A , we multiply A A by the matrix E E where E E is equal to the identity matrix except the i,j i,j entry is E_{i,j} = k E_{i,j} = k . For example, if A A is 3 by 3 and we want to add 3 times row 2 to row 0 (using 0 indexing) then E_1 = \\begin{bmatrix} 1 & 0 & 3 \\\\\\ 0 & 1 & 0 \\\\\\ 0 & 0 & 1 \\end{bmatrix} E_1 = \\begin{bmatrix} 1 & 0 & 3 \\\\\\ 0 & 1 & 0 \\\\\\ 0 & 0 & 1 \\end{bmatrix} Let's verify the calculation: A = np.array([[1,1,2],[-1,3,1],[0,5,2]]) print(A) [[ 1 1 2] [-1 3 1] [ 0 5 2]] E1 = np.array([[1,0,3],[0,1,0],[0,0,1]]) print(E1) [[1 0 3] [0 1 0] [0 0 1]] E1 @ A array([[ 1, 16, 8], [-1, 3, 1], [ 0, 5, 2]]) To multiply k k times row i i in a matrix A A , we multiply A A by the matrix E E where E E is equal to the identity matrix except the ,i,j ,i,j entry is E_{i,i} = k E_{i,i} = k . For example, if A A is 3 by 3 and we want to multiply row 1 by -2 then E_2 = \\begin{bmatrix} 1 & 0 & 0 \\\\\\ 0 & -2 & 0 \\\\\\ 0 & 0 & 1 \\end{bmatrix} E_2 = \\begin{bmatrix} 1 & 0 & 0 \\\\\\ 0 & -2 & 0 \\\\\\ 0 & 0 & 1 \\end{bmatrix} Let's verify the calculation: E2 = np.array([[1,0,0],[0,-2,0],[0,0,1]]) print(E2) [[ 1 0 0] [ 0 -2 0] [ 0 0 1]] E2 @ A array([[ 1, 1, 2], [ 2, -6, -2], [ 0, 5, 2]]) Finally, to switch row i i and row j j in a matrix A A , we multiply A A by the matrix E E where E E is equal to the identity matrix except E_{i,i} = 0 E_{i,i} = 0 , E_{j,j} = 0 E_{j,j} = 0 , E_{i,j} = 1 E_{i,j} = 1 and E_{j,i} = 1 E_{j,i} = 1 . For example, if A A is 3 by 3 and we want to switch row 1 and row 2 then E^3 = \\begin{bmatrix} 1 & 0 & 0 \\\\\\ 0 & 0 & 1 \\\\\\ 0 & 1 & 0 \\end{bmatrix} E^3 = \\begin{bmatrix} 1 & 0 & 0 \\\\\\ 0 & 0 & 1 \\\\\\ 0 & 1 & 0 \\end{bmatrix} Let's verify the calculation: E3 = np.array([[1,0,0],[0,0,1],[0,1,0]]) print(E3) [[1 0 0] [0 0 1] [0 1 0]] E3 @ A array([[ 1, 1, 2], [ 0, 5, 2], [-1, 3, 1]]) Implementation Let's write function to implement the elementary row operations. First of all, let's write a function called add_rows which takes input parameters A A , k k , i i and j j and returns the NumPy array resulting from adding k k times row j j to row i i in the matrix A A . If i=j i=j , then let's say that the function scales row i i by k+1 k+1 since this would be the result of k k times row i i added to row i i . def add_row(A,k,i,j): \"Add k times row j to row i in matrix A.\" n = A.shape[0] E = np.eye(n) if i == j: E[i,i] = k + 1 else: E[i,j] = k return E @ A Let's test our function: M = np.array([[1,1],[3,2]]) print(M) [[1 1] [3 2]] add_row(M,2,0,1) array([[7., 5.], [3., 2.]]) add_row(M,3,1,1) array([[ 1., 1.], [12., 8.]]) Let's write a function called scale_row which takes 3 input parameters A A , k k , and i i and returns the matrix that results from k k times row i i in the matrix A A . def scale_row(A,k,i): \"Multiply row i by k in matrix A.\" n = A.shape[0] E = np.eye(n) E[i,i] = k return E @ A M = np.array([[3,1],[-2,7]]) print(M) [[ 3 1] [-2 7]] scale_row(M,3,1) array([[ 3., 1.], [-6., 21.]]) A = np.array([[1,1,1],[1,-1,0]]) print(A) [[ 1 1 1] [ 1 -1 0]] scale_row(A,5,1) array([[ 1., 1., 1.], [ 5., -5., 0.]]) Let's write a function called switch_rows which takes 3 input parameters A A , i i and j j and returns the matrix that results from switching rows i i and j j in the matrix A A . def switch_rows(A,i,j): \"Switch rows i and j in matrix A.\" n = A.shape[0] E = np.eye(n) E[i,i] = 0 E[j,j] = 0 E[i,j] = 1 E[j,i] = 1 return E @ A A = np.array([[1,1,1],[1,-1,0]]) print(A) [[ 1 1 1] [ 1 -1 0]] switch_rows(A,0,1) array([[ 1., -1., 0.], [ 1., 1., 1.]]) Examples Find the Inverse Let's apply our functions to the augmented matrix [M \\ | \\ I] [M \\ | \\ I] to find the inverse of the matrix M M : M = np.array([[5,4,2],[-1,2,1],[1,1,1]]) print(M) [[ 5 4 2] [-1 2 1] [ 1 1 1]] A = np.hstack([M,np.eye(3)]) print(A) [[ 5. 4. 2. 1. 0. 0.] [-1. 2. 1. 0. 1. 0.] [ 1. 1. 1. 0. 0. 1.]] A1 = switch_rows(A,0,2) print(A1) [[ 1. 1. 1. 0. 0. 1.] [-1. 2. 1. 0. 1. 0.] [ 5. 4. 2. 1. 0. 0.]] A2 = add_row(A1,1,1,0) print(A2) [[1. 1. 1. 0. 0. 1.] [0. 3. 2. 0. 1. 1.] [5. 4. 2. 1. 0. 0.]] A3 = add_row(A2,-5,2,0) print(A3) [[ 1. 1. 1. 0. 0. 1.] [ 0. 3. 2. 0. 1. 1.] [ 0. -1. -3. 1. 0. -5.]] A4 = switch_rows(A3,1,2) print(A4) [[ 1. 1. 1. 0. 0. 1.] [ 0. -1. -3. 1. 0. -5.] [ 0. 3. 2. 0. 1. 1.]] A5 = scale_row(A4,-1,1) print(A5) [[ 1. 1. 1. 0. 0. 1.] [ 0. 1. 3. -1. 0. 5.] [ 0. 3. 2. 0. 1. 1.]] A6 = add_row(A5,-3,2,1) print(A6) [[ 1. 1. 1. 0. 0. 1.] [ 0. 1. 3. -1. 0. 5.] [ 0. 0. -7. 3. 1. -14.]] A7 = scale_row(A6,-1/7,2) print(A7) [[ 1. 1. 1. 0. 0. 1. ] [ 0. 1. 3. -1. 0. 5. ] [ 0. 0. 1. -0.42857143 -0.14285714 2. ]] A8 = add_row(A7,-3,1,2) print(A8) [[ 1. 1. 1. 0. 0. 1. ] [ 0. 1. 0. 0.28571429 0.42857143 -1. ] [ 0. 0. 1. -0.42857143 -0.14285714 2. ]] A9 = add_row(A8,-1,0,2) print(A9) [[ 1. 1. 0. 0.42857143 0.14285714 -1. ] [ 0. 1. 0. 0.28571429 0.42857143 -1. ] [ 0. 0. 1. -0.42857143 -0.14285714 2. ]] A10 = add_row(A9,-1,0,1) print(A10) [[ 1. 0. 0. 0.14285714 -0.28571429 0. ] [ 0. 1. 0. 0.28571429 0.42857143 -1. ] [ 0. 0. 1. -0.42857143 -0.14285714 2. ]] Let's verify that we found the inverse M^{-1} M^{-1} correctly: Minv = A10[:,3:] print(Minv) [[ 0.14285714 -0.28571429 0. ] [ 0.28571429 0.42857143 -1. ] [-0.42857143 -0.14285714 2. ]] result = Minv @ M print(result) [[ 1.00000000e+00 4.44089210e-16 2.22044605e-16] [-6.66133815e-16 1.00000000e+00 -2.22044605e-16] [ 0.00000000e+00 0.00000000e+00 1.00000000e+00]] Success! We can see the result more clearly if we round to 15 decimal places: np.round(result,15) array([[ 1.e+00, 0.e+00, 0.e+00], [-1.e-15, 1.e+00, -0.e+00], [ 0.e+00, 0.e+00, 1.e+00]]) Solve a System Let's use our functions to perform Gaussian elimination and solve a linear system of equations A \\mathbf{x} = \\mathbf{b} A \\mathbf{x} = \\mathbf{b} . A = np.array([[6,15,1],[8,7,12],[2,7,8]]) print(A) [[ 6 15 1] [ 8 7 12] [ 2 7 8]] b = np.array([[2],[14],[10]]) print(b) [[ 2] [14] [10]] Form the augemented matrix M M : M = np.hstack([A,b]) print(M) [[ 6 15 1 2] [ 8 7 12 14] [ 2 7 8 10]] Perform row operations: M1 = scale_row(M,1/6,0) print(M1) [[ 1. 2.5 0.16666667 0.33333333] [ 8. 7. 12. 14. ] [ 2. 7. 8. 10. ]] M2 = add_row(M1,-8,1,0) print(M2) [[ 1. 2.5 0.16666667 0.33333333] [ 0. -13. 10.66666667 11.33333333] [ 2. 7. 8. 10. ]] M3 = add_row(M2,-2,2,0) print(M3) [[ 1. 2.5 0.16666667 0.33333333] [ 0. -13. 10.66666667 11.33333333] [ 0. 2. 7.66666667 9.33333333]] M4 = scale_row(M3,-1/13,1) print(M4) [[ 1. 2.5 0.16666667 0.33333333] [ 0. 1. -0.82051282 -0.87179487] [ 0. 2. 7.66666667 9.33333333]] M5 = add_row(M4,-2,2,1) print(M5) [[ 1. 2.5 0.16666667 0.33333333] [ 0. 1. -0.82051282 -0.87179487] [ 0. 0. 9.30769231 11.07692308]] M6 = scale_row(M5,1/M5[2,2],2) print(M6) [[ 1. 2.5 0.16666667 0.33333333] [ 0. 1. -0.82051282 -0.87179487] [ 0. 0. 1. 1.19008264]] M7 = add_row(M6,-M6[1,2],1,2) print(M7) [[1. 2.5 0.16666667 0.33333333] [0. 1. 0. 0.1046832 ] [0. 0. 1. 1.19008264]] M8 = add_row(M7,-M7[0,2],0,2) print(M8) [[1. 2.5 0. 0.13498623] [0. 1. 0. 0.1046832 ] [0. 0. 1. 1.19008264]] M9 = add_row(M8,-M8[0,1],0,1) print(M9) [[ 1. 0. 0. -0.12672176] [ 0. 1. 0. 0.1046832 ] [ 0. 0. 1. 1.19008264]] Success! The solution of Ax=b Ax=b is x = M9[:,3].reshape(3,1) print(x) [[-0.12672176] [ 0.1046832 ] [ 1.19008264]] Or, we can do it the easy way... x = la.solve(A,b) print(x) [[-0.12672176] [ 0.1046832 ] [ 1.19008264]] scipy.linalg.solve We are mostly interested in linear systems A \\mathbf{x} = \\mathbf{b} A \\mathbf{x} = \\mathbf{b} where there is a unique solution \\mathbf{x} \\mathbf{x} . This is the case when A A is a square matrix ( m=n m=n ) and \\mathrm{det}(A) \\not= 0 \\mathrm{det}(A) \\not= 0 . To solve such a system, we can use the function scipy.linalg.solve . The function returns a solution of the system of equations A \\mathbf{x} = \\mathbf{b} A \\mathbf{x} = \\mathbf{b} . For example: A = np.array([[1,1],[1,-1]]) print(A) [[ 1 1] [ 1 -1]] b1 = np.array([2,0]) print(b1) [2 0] And solve: x1 = la.solve(A,b1) print(x1) [1. 1.] Note that the output \\mathbf{x} \\mathbf{x} is returned as a 1D NumPy array when the vector \\mathbf{b} \\mathbf{b} (the right hand side) is entered as a 1D NumPy array. If we input \\mathbf{b} \\mathbf{b} as a 2D NumPy array, then the output is a 2D NumPy array. For example: A = np.array([[1,1],[1,-1]]) b2 = np.array([2,0]).reshape(2,1) x2 = la.solve(A,b2) print(x2) [[1.] [1.]] Finally, if the right hand side \\mathbf{b} \\mathbf{b} is a matrix, then the output is a matrix of the same size. It is the solution of A \\mathbf{x} = \\mathbf{b} A \\mathbf{x} = \\mathbf{b} when \\mathbf{b} \\mathbf{b} is a matrix. For example: A = np.array([[1,1],[1,-1]]) b3 = np.array([[2,2],[0,1]]) x3 = la.solve(A,b3) print(x3) [[1. 1.5] [1. 0.5]] Simple Example Let's compute the solution of the system of equations \\begin{align} 2x + y &= 1 \\\\\\ x + y &= 1 \\end{align} \\begin{align} 2x + y &= 1 \\\\\\ x + y &= 1 \\end{align} Create the matrix of coefficients: A = np.array([[2,1],[1,1]]) print(A) [[2 1] [1 1]] And the vector \\mathbf{b} \\mathbf{b} : b = np.array([1,-1]).reshape(2,1) print(b) [[ 1] [-1]] And solve: x = la.solve(A,b) print(x) [[ 2.] [-3.]] We can verify the solution by computing the inverse of A A : Ainv = la.inv(A) print(Ainv) [[ 1. -1.] [-1. 2.]] And multiply A^{-1} \\mathbf{b} A^{-1} \\mathbf{b} to solve for \\mathbf{x} \\mathbf{x} : x = Ainv @ b print(x) [[ 2.] [-3.]] We get the same result. Success! Inverse or Solve It's a bad idea to use the inverse A^{-1} A^{-1} to solve A \\mathbf{x} = \\mathbf{b} A \\mathbf{x} = \\mathbf{b} if A A is large. It's too computationally expensive. Let's create a large random matrix A A and vector \\mathbf{b} \\mathbf{b} and compute the solution \\mathbf{x} \\mathbf{x} in 2 ways: N = 1000 A = np.random.rand(N,N) b = np.random.rand(N,1) Check the first entries A A : A[:3,:3] array([[0.35754719, 0.63135432, 0.6572258 ], [0.18450506, 0.14639832, 0.23528745], [0.27576474, 0.46264005, 0.26589724]]) And for \\mathbf{b} \\mathbf{b} : b[:4,:] array([[0.82726751], [0.96946096], [0.31351176], [0.63757837]]) Now we compare the speed of scipy.linalg.solve with scipy.linalg.inv : %%timeit x = la.solve(A,b) 2.77 s \u00b1 509 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) %%timeit x = la.inv(A) @ b 4.46 s \u00b1 2.04 s per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) Solving with scipy.linalg.solve is about twice as fast! Exercises Under construction","title":"Solving Linear Systems"},{"location":"linear-algebra/solving-linear-systems/#solving-linear-systems","text":"import numpy as np import matplotlib.pyplot as plt import scipy.linalg as la %matplotlib inline","title":"Solving Linear Systems"},{"location":"linear-algebra/solving-linear-systems/#linear-systems","text":"A linear system of equations is a collection of linear equations \\begin{align} a_{0,0}x_0 + a_{0,1}x_2 + \\cdots + a_{0,n}x_n & = b_0 \\\\\\ a_{1,0}x_0 + a_{1,1}x_2 + \\cdots + a_{1,n}x_n & = b_1 \\\\\\ & \\vdots \\\\\\ a_{m,0}x_0 + a_{m,1}x_2 + \\cdots + a_{m,n}x_n & = b_m \\\\\\ \\end{align} \\begin{align} a_{0,0}x_0 + a_{0,1}x_2 + \\cdots + a_{0,n}x_n & = b_0 \\\\\\ a_{1,0}x_0 + a_{1,1}x_2 + \\cdots + a_{1,n}x_n & = b_1 \\\\\\ & \\vdots \\\\\\ a_{m,0}x_0 + a_{m,1}x_2 + \\cdots + a_{m,n}x_n & = b_m \\\\\\ \\end{align} In matrix notation, a linear system is A \\mathbf{x}= \\mathbf{b} A \\mathbf{x}= \\mathbf{b} where A = \\begin{bmatrix} a_{0,0} & a_{0,1} & \\cdots & a_{0,n} \\\\\\ a_{1,0} & a_{1,1} & \\cdots & a_{1,n} \\\\\\ \\vdots & & & \\vdots \\\\\\ a_{m,0} & a_{m,1} & \\cdots & a_{m,n} \\\\\\ \\end{bmatrix} \\ \\ , \\ \\ \\mathbf{x} = \\begin{bmatrix} x_0 \\\\\\ x_1 \\\\\\ \\vdots \\\\\\ x_n \\end{bmatrix} \\ \\ , \\ \\ \\mathbf{b} = \\begin{bmatrix} b_0 \\\\\\ b_1 \\\\\\ \\vdots \\\\\\ b_m \\end{bmatrix} A = \\begin{bmatrix} a_{0,0} & a_{0,1} & \\cdots & a_{0,n} \\\\\\ a_{1,0} & a_{1,1} & \\cdots & a_{1,n} \\\\\\ \\vdots & & & \\vdots \\\\\\ a_{m,0} & a_{m,1} & \\cdots & a_{m,n} \\\\\\ \\end{bmatrix} \\ \\ , \\ \\ \\mathbf{x} = \\begin{bmatrix} x_0 \\\\\\ x_1 \\\\\\ \\vdots \\\\\\ x_n \\end{bmatrix} \\ \\ , \\ \\ \\mathbf{b} = \\begin{bmatrix} b_0 \\\\\\ b_1 \\\\\\ \\vdots \\\\\\ b_m \\end{bmatrix}","title":"Linear Systems"},{"location":"linear-algebra/solving-linear-systems/#gaussian-elimination","text":"The general procedure to solve a linear system of equation is called Gaussian elimination . The idea is to perform elementary row operations to reduce the system to its row echelon form and then solve.","title":"Gaussian elimination"},{"location":"linear-algebra/solving-linear-systems/#elementary-row-operations","text":"Elementary row operations include: Add k k times row j j to row i i . Multiply row i i by scalar k k . Switch rows i i and j j . Each of the elementary row operations is the result of matrix multiplication by an elementary matrix (on the left). To add k k times row i i to row j j in a matrix A A , we multiply A A by the matrix E E where E E is equal to the identity matrix except the i,j i,j entry is E_{i,j} = k E_{i,j} = k . For example, if A A is 3 by 3 and we want to add 3 times row 2 to row 0 (using 0 indexing) then E_1 = \\begin{bmatrix} 1 & 0 & 3 \\\\\\ 0 & 1 & 0 \\\\\\ 0 & 0 & 1 \\end{bmatrix} E_1 = \\begin{bmatrix} 1 & 0 & 3 \\\\\\ 0 & 1 & 0 \\\\\\ 0 & 0 & 1 \\end{bmatrix} Let's verify the calculation: A = np.array([[1,1,2],[-1,3,1],[0,5,2]]) print(A) [[ 1 1 2] [-1 3 1] [ 0 5 2]] E1 = np.array([[1,0,3],[0,1,0],[0,0,1]]) print(E1) [[1 0 3] [0 1 0] [0 0 1]] E1 @ A array([[ 1, 16, 8], [-1, 3, 1], [ 0, 5, 2]]) To multiply k k times row i i in a matrix A A , we multiply A A by the matrix E E where E E is equal to the identity matrix except the ,i,j ,i,j entry is E_{i,i} = k E_{i,i} = k . For example, if A A is 3 by 3 and we want to multiply row 1 by -2 then E_2 = \\begin{bmatrix} 1 & 0 & 0 \\\\\\ 0 & -2 & 0 \\\\\\ 0 & 0 & 1 \\end{bmatrix} E_2 = \\begin{bmatrix} 1 & 0 & 0 \\\\\\ 0 & -2 & 0 \\\\\\ 0 & 0 & 1 \\end{bmatrix} Let's verify the calculation: E2 = np.array([[1,0,0],[0,-2,0],[0,0,1]]) print(E2) [[ 1 0 0] [ 0 -2 0] [ 0 0 1]] E2 @ A array([[ 1, 1, 2], [ 2, -6, -2], [ 0, 5, 2]]) Finally, to switch row i i and row j j in a matrix A A , we multiply A A by the matrix E E where E E is equal to the identity matrix except E_{i,i} = 0 E_{i,i} = 0 , E_{j,j} = 0 E_{j,j} = 0 , E_{i,j} = 1 E_{i,j} = 1 and E_{j,i} = 1 E_{j,i} = 1 . For example, if A A is 3 by 3 and we want to switch row 1 and row 2 then E^3 = \\begin{bmatrix} 1 & 0 & 0 \\\\\\ 0 & 0 & 1 \\\\\\ 0 & 1 & 0 \\end{bmatrix} E^3 = \\begin{bmatrix} 1 & 0 & 0 \\\\\\ 0 & 0 & 1 \\\\\\ 0 & 1 & 0 \\end{bmatrix} Let's verify the calculation: E3 = np.array([[1,0,0],[0,0,1],[0,1,0]]) print(E3) [[1 0 0] [0 0 1] [0 1 0]] E3 @ A array([[ 1, 1, 2], [ 0, 5, 2], [-1, 3, 1]])","title":"Elementary Row Operations"},{"location":"linear-algebra/solving-linear-systems/#implementation","text":"Let's write function to implement the elementary row operations. First of all, let's write a function called add_rows which takes input parameters A A , k k , i i and j j and returns the NumPy array resulting from adding k k times row j j to row i i in the matrix A A . If i=j i=j , then let's say that the function scales row i i by k+1 k+1 since this would be the result of k k times row i i added to row i i . def add_row(A,k,i,j): \"Add k times row j to row i in matrix A.\" n = A.shape[0] E = np.eye(n) if i == j: E[i,i] = k + 1 else: E[i,j] = k return E @ A Let's test our function: M = np.array([[1,1],[3,2]]) print(M) [[1 1] [3 2]] add_row(M,2,0,1) array([[7., 5.], [3., 2.]]) add_row(M,3,1,1) array([[ 1., 1.], [12., 8.]]) Let's write a function called scale_row which takes 3 input parameters A A , k k , and i i and returns the matrix that results from k k times row i i in the matrix A A . def scale_row(A,k,i): \"Multiply row i by k in matrix A.\" n = A.shape[0] E = np.eye(n) E[i,i] = k return E @ A M = np.array([[3,1],[-2,7]]) print(M) [[ 3 1] [-2 7]] scale_row(M,3,1) array([[ 3., 1.], [-6., 21.]]) A = np.array([[1,1,1],[1,-1,0]]) print(A) [[ 1 1 1] [ 1 -1 0]] scale_row(A,5,1) array([[ 1., 1., 1.], [ 5., -5., 0.]]) Let's write a function called switch_rows which takes 3 input parameters A A , i i and j j and returns the matrix that results from switching rows i i and j j in the matrix A A . def switch_rows(A,i,j): \"Switch rows i and j in matrix A.\" n = A.shape[0] E = np.eye(n) E[i,i] = 0 E[j,j] = 0 E[i,j] = 1 E[j,i] = 1 return E @ A A = np.array([[1,1,1],[1,-1,0]]) print(A) [[ 1 1 1] [ 1 -1 0]] switch_rows(A,0,1) array([[ 1., -1., 0.], [ 1., 1., 1.]])","title":"Implementation"},{"location":"linear-algebra/solving-linear-systems/#examples","text":"","title":"Examples"},{"location":"linear-algebra/solving-linear-systems/#find-the-inverse","text":"Let's apply our functions to the augmented matrix [M \\ | \\ I] [M \\ | \\ I] to find the inverse of the matrix M M : M = np.array([[5,4,2],[-1,2,1],[1,1,1]]) print(M) [[ 5 4 2] [-1 2 1] [ 1 1 1]] A = np.hstack([M,np.eye(3)]) print(A) [[ 5. 4. 2. 1. 0. 0.] [-1. 2. 1. 0. 1. 0.] [ 1. 1. 1. 0. 0. 1.]] A1 = switch_rows(A,0,2) print(A1) [[ 1. 1. 1. 0. 0. 1.] [-1. 2. 1. 0. 1. 0.] [ 5. 4. 2. 1. 0. 0.]] A2 = add_row(A1,1,1,0) print(A2) [[1. 1. 1. 0. 0. 1.] [0. 3. 2. 0. 1. 1.] [5. 4. 2. 1. 0. 0.]] A3 = add_row(A2,-5,2,0) print(A3) [[ 1. 1. 1. 0. 0. 1.] [ 0. 3. 2. 0. 1. 1.] [ 0. -1. -3. 1. 0. -5.]] A4 = switch_rows(A3,1,2) print(A4) [[ 1. 1. 1. 0. 0. 1.] [ 0. -1. -3. 1. 0. -5.] [ 0. 3. 2. 0. 1. 1.]] A5 = scale_row(A4,-1,1) print(A5) [[ 1. 1. 1. 0. 0. 1.] [ 0. 1. 3. -1. 0. 5.] [ 0. 3. 2. 0. 1. 1.]] A6 = add_row(A5,-3,2,1) print(A6) [[ 1. 1. 1. 0. 0. 1.] [ 0. 1. 3. -1. 0. 5.] [ 0. 0. -7. 3. 1. -14.]] A7 = scale_row(A6,-1/7,2) print(A7) [[ 1. 1. 1. 0. 0. 1. ] [ 0. 1. 3. -1. 0. 5. ] [ 0. 0. 1. -0.42857143 -0.14285714 2. ]] A8 = add_row(A7,-3,1,2) print(A8) [[ 1. 1. 1. 0. 0. 1. ] [ 0. 1. 0. 0.28571429 0.42857143 -1. ] [ 0. 0. 1. -0.42857143 -0.14285714 2. ]] A9 = add_row(A8,-1,0,2) print(A9) [[ 1. 1. 0. 0.42857143 0.14285714 -1. ] [ 0. 1. 0. 0.28571429 0.42857143 -1. ] [ 0. 0. 1. -0.42857143 -0.14285714 2. ]] A10 = add_row(A9,-1,0,1) print(A10) [[ 1. 0. 0. 0.14285714 -0.28571429 0. ] [ 0. 1. 0. 0.28571429 0.42857143 -1. ] [ 0. 0. 1. -0.42857143 -0.14285714 2. ]] Let's verify that we found the inverse M^{-1} M^{-1} correctly: Minv = A10[:,3:] print(Minv) [[ 0.14285714 -0.28571429 0. ] [ 0.28571429 0.42857143 -1. ] [-0.42857143 -0.14285714 2. ]] result = Minv @ M print(result) [[ 1.00000000e+00 4.44089210e-16 2.22044605e-16] [-6.66133815e-16 1.00000000e+00 -2.22044605e-16] [ 0.00000000e+00 0.00000000e+00 1.00000000e+00]] Success! We can see the result more clearly if we round to 15 decimal places: np.round(result,15) array([[ 1.e+00, 0.e+00, 0.e+00], [-1.e-15, 1.e+00, -0.e+00], [ 0.e+00, 0.e+00, 1.e+00]])","title":"Find the Inverse"},{"location":"linear-algebra/solving-linear-systems/#solve-a-system","text":"Let's use our functions to perform Gaussian elimination and solve a linear system of equations A \\mathbf{x} = \\mathbf{b} A \\mathbf{x} = \\mathbf{b} . A = np.array([[6,15,1],[8,7,12],[2,7,8]]) print(A) [[ 6 15 1] [ 8 7 12] [ 2 7 8]] b = np.array([[2],[14],[10]]) print(b) [[ 2] [14] [10]] Form the augemented matrix M M : M = np.hstack([A,b]) print(M) [[ 6 15 1 2] [ 8 7 12 14] [ 2 7 8 10]] Perform row operations: M1 = scale_row(M,1/6,0) print(M1) [[ 1. 2.5 0.16666667 0.33333333] [ 8. 7. 12. 14. ] [ 2. 7. 8. 10. ]] M2 = add_row(M1,-8,1,0) print(M2) [[ 1. 2.5 0.16666667 0.33333333] [ 0. -13. 10.66666667 11.33333333] [ 2. 7. 8. 10. ]] M3 = add_row(M2,-2,2,0) print(M3) [[ 1. 2.5 0.16666667 0.33333333] [ 0. -13. 10.66666667 11.33333333] [ 0. 2. 7.66666667 9.33333333]] M4 = scale_row(M3,-1/13,1) print(M4) [[ 1. 2.5 0.16666667 0.33333333] [ 0. 1. -0.82051282 -0.87179487] [ 0. 2. 7.66666667 9.33333333]] M5 = add_row(M4,-2,2,1) print(M5) [[ 1. 2.5 0.16666667 0.33333333] [ 0. 1. -0.82051282 -0.87179487] [ 0. 0. 9.30769231 11.07692308]] M6 = scale_row(M5,1/M5[2,2],2) print(M6) [[ 1. 2.5 0.16666667 0.33333333] [ 0. 1. -0.82051282 -0.87179487] [ 0. 0. 1. 1.19008264]] M7 = add_row(M6,-M6[1,2],1,2) print(M7) [[1. 2.5 0.16666667 0.33333333] [0. 1. 0. 0.1046832 ] [0. 0. 1. 1.19008264]] M8 = add_row(M7,-M7[0,2],0,2) print(M8) [[1. 2.5 0. 0.13498623] [0. 1. 0. 0.1046832 ] [0. 0. 1. 1.19008264]] M9 = add_row(M8,-M8[0,1],0,1) print(M9) [[ 1. 0. 0. -0.12672176] [ 0. 1. 0. 0.1046832 ] [ 0. 0. 1. 1.19008264]] Success! The solution of Ax=b Ax=b is x = M9[:,3].reshape(3,1) print(x) [[-0.12672176] [ 0.1046832 ] [ 1.19008264]] Or, we can do it the easy way... x = la.solve(A,b) print(x) [[-0.12672176] [ 0.1046832 ] [ 1.19008264]]","title":"Solve a System"},{"location":"linear-algebra/solving-linear-systems/#scipylinalgsolve","text":"We are mostly interested in linear systems A \\mathbf{x} = \\mathbf{b} A \\mathbf{x} = \\mathbf{b} where there is a unique solution \\mathbf{x} \\mathbf{x} . This is the case when A A is a square matrix ( m=n m=n ) and \\mathrm{det}(A) \\not= 0 \\mathrm{det}(A) \\not= 0 . To solve such a system, we can use the function scipy.linalg.solve . The function returns a solution of the system of equations A \\mathbf{x} = \\mathbf{b} A \\mathbf{x} = \\mathbf{b} . For example: A = np.array([[1,1],[1,-1]]) print(A) [[ 1 1] [ 1 -1]] b1 = np.array([2,0]) print(b1) [2 0] And solve: x1 = la.solve(A,b1) print(x1) [1. 1.] Note that the output \\mathbf{x} \\mathbf{x} is returned as a 1D NumPy array when the vector \\mathbf{b} \\mathbf{b} (the right hand side) is entered as a 1D NumPy array. If we input \\mathbf{b} \\mathbf{b} as a 2D NumPy array, then the output is a 2D NumPy array. For example: A = np.array([[1,1],[1,-1]]) b2 = np.array([2,0]).reshape(2,1) x2 = la.solve(A,b2) print(x2) [[1.] [1.]] Finally, if the right hand side \\mathbf{b} \\mathbf{b} is a matrix, then the output is a matrix of the same size. It is the solution of A \\mathbf{x} = \\mathbf{b} A \\mathbf{x} = \\mathbf{b} when \\mathbf{b} \\mathbf{b} is a matrix. For example: A = np.array([[1,1],[1,-1]]) b3 = np.array([[2,2],[0,1]]) x3 = la.solve(A,b3) print(x3) [[1. 1.5] [1. 0.5]]","title":"scipy.linalg.solve"},{"location":"linear-algebra/solving-linear-systems/#simple-example","text":"Let's compute the solution of the system of equations \\begin{align} 2x + y &= 1 \\\\\\ x + y &= 1 \\end{align} \\begin{align} 2x + y &= 1 \\\\\\ x + y &= 1 \\end{align} Create the matrix of coefficients: A = np.array([[2,1],[1,1]]) print(A) [[2 1] [1 1]] And the vector \\mathbf{b} \\mathbf{b} : b = np.array([1,-1]).reshape(2,1) print(b) [[ 1] [-1]] And solve: x = la.solve(A,b) print(x) [[ 2.] [-3.]] We can verify the solution by computing the inverse of A A : Ainv = la.inv(A) print(Ainv) [[ 1. -1.] [-1. 2.]] And multiply A^{-1} \\mathbf{b} A^{-1} \\mathbf{b} to solve for \\mathbf{x} \\mathbf{x} : x = Ainv @ b print(x) [[ 2.] [-3.]] We get the same result. Success!","title":"Simple Example"},{"location":"linear-algebra/solving-linear-systems/#inverse-or-solve","text":"It's a bad idea to use the inverse A^{-1} A^{-1} to solve A \\mathbf{x} = \\mathbf{b} A \\mathbf{x} = \\mathbf{b} if A A is large. It's too computationally expensive. Let's create a large random matrix A A and vector \\mathbf{b} \\mathbf{b} and compute the solution \\mathbf{x} \\mathbf{x} in 2 ways: N = 1000 A = np.random.rand(N,N) b = np.random.rand(N,1) Check the first entries A A : A[:3,:3] array([[0.35754719, 0.63135432, 0.6572258 ], [0.18450506, 0.14639832, 0.23528745], [0.27576474, 0.46264005, 0.26589724]]) And for \\mathbf{b} \\mathbf{b} : b[:4,:] array([[0.82726751], [0.96946096], [0.31351176], [0.63757837]]) Now we compare the speed of scipy.linalg.solve with scipy.linalg.inv : %%timeit x = la.solve(A,b) 2.77 s \u00b1 509 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) %%timeit x = la.inv(A) @ b 4.46 s \u00b1 2.04 s per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) Solving with scipy.linalg.solve is about twice as fast!","title":"Inverse or Solve"},{"location":"linear-algebra/solving-linear-systems/#exercises","text":"Under construction","title":"Exercises"},{"location":"phys221/Multiplots/","text":"Molecular Speeds lab Python data analysis - multiple gas dataset processing Take a look at the example code you have been given - or start to workthrough from here. Let's begin by importing all the modules we will need at the top of the code and adding in the variables that we know we will need for the analysis. import numpy as np from matplotlib import pyplot as plt from math import log import math V=2.03*10**-3 A=5.55113*10**-8 ef_begin=0.26 What we are going to do here is run a for loop over all the code we wrote for all files in a specific folder. This will be the folder we are in, so make sure that's where you are and you have all the data from the workshop folder. To start with we need to import the other modules we are going to use. os (or Miscellaneous Operating system interfaces) Lets us look up file paths and folder locations Glob lets us find all files matching a pattern These are file organisation tools. You can look up more about them if you like. import os import glob The first thing we want to do is set the location of our folder which is where the script is stored i.e. CWD or current working directory. folder = os.getcwd() Now we know where the files are stored we need to set the pattern (or type of files) for Glob to look for. fileformat=folder+str('/*.csv') This will make the script only look for csv files in the correct folder. We now want to create an array of the filenames, these are named after the gasses and mass numbers. files = glob.glob(fileformat) Create an array of masses from filenames to use later, as filenames are strings we need to set them as intergers. Note that -ve indicies run from the end. masses = [int(f[-6:-4]) for f in files] It might not be totally clear what this is doing unless we print the output. print(files) ['C:\\\\Users\\\\plankna\\\\Desktop\\\\PythonWorkshop\\\\Intro_documents\\\\Multiple\\\\Argon 38.csv', 'C:\\\\Users\\\\plankna\\\\Desktop\\\\PythonWorkshop\\\\Intro_documents\\\\Multiple\\\\Carbon Dioxide 40.csv', 'C:\\\\Users\\\\plankna\\\\Desktop\\\\PythonWorkshop\\\\Intro_documents\\\\Multiple\\\\Chlorine 71.csv', 'C:\\\\Users\\\\plankna\\\\Desktop\\\\PythonWorkshop\\\\Intro_documents\\\\Multiple\\\\Fluorine 38.csv', 'C:\\\\Users\\\\plankna\\\\Desktop\\\\PythonWorkshop\\\\Intro_documents\\\\Multiple\\\\Krypton 84.csv', 'C:\\\\Users\\\\plankna\\\\Desktop\\\\PythonWorkshop\\\\Intro_documents\\\\Multiple\\\\Methane 16.csv', 'C:\\\\Users\\\\plankna\\\\Desktop\\\\PythonWorkshop\\\\Intro_documents\\\\Multiple\\\\Neon 17.csv', 'C:\\\\Users\\\\plankna\\\\Desktop\\\\PythonWorkshop\\\\Intro_documents\\\\Multiple\\\\Nitrogen 28.csv', 'C:\\\\Users\\\\plankna\\\\Desktop\\\\PythonWorkshop\\\\Intro_documents\\\\Multiple\\\\Oxygen 32.csv', 'C:\\\\Users\\\\plankna\\\\Desktop\\\\PythonWorkshop\\\\Intro_documents\\\\Multiple\\\\Sulphur Dioxide 64.csv'] argh!!! depending on your filing system this might look horrible... print(masses) [38, 40, 71, 38, 84, 16, 17, 28, 32, 64] but hopefully this helps to see what has gone on. We have taken the string from the file name and turned them into an integer. To do this we counted back from the end of the file name... We now need to find out how many files we have in the folder. We know how to do that already. n=len(files) We also need to create an empty array to populate later. v=np.zeros(n) We now want to simply run though the previous code (in the single gas experiment) for all of the files in the folder. for j in range(n): #we need to indent all this code and change the argument in genfromtext #to files[j] rawdata=np.genfromtxt(files[j], delimiter=',') time=rawdata[:,0] pressure=rawdata[:,1] baseP=min(rawdata[:,1]) P_minus_baseP=[i-0.99*baseP for i in pressure] res=[abs(i-ef_begin) for i in P_minus_baseP] minres=min(res) for i in range (len(res)): if res[i]==minres: Peff_index=i break LogP=[log(i) for i in P_minus_baseP] fit=np.polyfit(time[Peff_index:1400],LogP[Peff_index:1400],1) m=fit[0] c=fit[1] note, we no longer have cats... ;-) compare this to your previous code. It is the same, just compressed. Now I am adding on to this and plotting the data. for j in range(n): #we need to indent all this code and change the argument in genfromtext #to files[j] rawdata=np.genfromtxt(files[j], delimiter=',') time=rawdata[:,0] pressure=rawdata[:,1] baseP=min(rawdata[:,1]) P_minus_baseP=[i-0.99*baseP for i in pressure] res=[abs(i-ef_begin) for i in P_minus_baseP] minres=min(res) for i in range (len(res)): if res[i]==minres: Peff_index=i break LogP=[log(i) for i in P_minus_baseP] fit=np.polyfit(time[Peff_index:1400],LogP[Peff_index:1400],1) m=fit[0] c=fit[1] #now we put each of these in one of the spots in the vector v v[j]=-4*V*m/A #now lets print v ######################print(v) #we can then plot v as a function of mass number plt.scatter(masses,v) #we can now create a theoritical line to match these to #first we need a range of mass numbers <matplotlib.collections.PathCollection at 0x2501a8d68d0> #now we simply complete the theoritical calculation vtheory=[math.sqrt(8/math.pi*1.38*(10**-23)*300/i/(1.67*10**-27)) for i in range(10,90)] #and plot the result on our plot plt.plot(range(10,90),vtheory,'k--') #we can add some labels plt.xlabel('Mass Number') plt.ylabel('Velocity') Text(0, 0.5, 'Velocity') Putting these last two parts together we find (this will be what comes up in Spyder. for j in range(n): #we need to indent all this code and change the argument in genfromtext #to files[j] rawdata=np.genfromtxt(files[j], delimiter=',') time=rawdata[:,0] pressure=rawdata[:,1] baseP=min(rawdata[:,1]) P_minus_baseP=[i-0.99*baseP for i in pressure] res=[abs(i-ef_begin) for i in P_minus_baseP] minres=min(res) for i in range (len(res)): if res[i]==minres: Peff_index=i break LogP=[log(i) for i in P_minus_baseP] fit=np.polyfit(time[Peff_index:1400],LogP[Peff_index:1400],1) m=fit[0] c=fit[1] #now we put each of these in one of the spots in the vector v v[j]=-4*V*m/A #now lets print v ######################print(v) #we can then plot v as a function of mass number plt.scatter(masses,v) #we can now create a theoritical line to match these to #first we need a range of mass numbers #now we simply complete the theoritical calculation vtheory=[math.sqrt(8/math.pi*1.38*(10**-23)*300/i/(1.67*10**-27)) for i in range(10,90)] #and plot the result on our plot plt.plot(range(10,90),vtheory,'k--') #we can add some labels plt.xlabel('Mass Number') plt.ylabel('Velocity') Text(0, 0.5, 'Velocity')","title":"Molecular Speeds lab Python data analysis - multiple gas dataset processing"},{"location":"phys221/Multiplots/#molecular-speeds-lab-python-data-analysis-multiple-gas-dataset-processing","text":"Take a look at the example code you have been given - or start to workthrough from here. Let's begin by importing all the modules we will need at the top of the code and adding in the variables that we know we will need for the analysis. import numpy as np from matplotlib import pyplot as plt from math import log import math V=2.03*10**-3 A=5.55113*10**-8 ef_begin=0.26 What we are going to do here is run a for loop over all the code we wrote for all files in a specific folder. This will be the folder we are in, so make sure that's where you are and you have all the data from the workshop folder. To start with we need to import the other modules we are going to use. os (or Miscellaneous Operating system interfaces) Lets us look up file paths and folder locations Glob lets us find all files matching a pattern These are file organisation tools. You can look up more about them if you like. import os import glob The first thing we want to do is set the location of our folder which is where the script is stored i.e. CWD or current working directory. folder = os.getcwd() Now we know where the files are stored we need to set the pattern (or type of files) for Glob to look for. fileformat=folder+str('/*.csv') This will make the script only look for csv files in the correct folder. We now want to create an array of the filenames, these are named after the gasses and mass numbers. files = glob.glob(fileformat) Create an array of masses from filenames to use later, as filenames are strings we need to set them as intergers. Note that -ve indicies run from the end. masses = [int(f[-6:-4]) for f in files] It might not be totally clear what this is doing unless we print the output. print(files) ['C:\\\\Users\\\\plankna\\\\Desktop\\\\PythonWorkshop\\\\Intro_documents\\\\Multiple\\\\Argon 38.csv', 'C:\\\\Users\\\\plankna\\\\Desktop\\\\PythonWorkshop\\\\Intro_documents\\\\Multiple\\\\Carbon Dioxide 40.csv', 'C:\\\\Users\\\\plankna\\\\Desktop\\\\PythonWorkshop\\\\Intro_documents\\\\Multiple\\\\Chlorine 71.csv', 'C:\\\\Users\\\\plankna\\\\Desktop\\\\PythonWorkshop\\\\Intro_documents\\\\Multiple\\\\Fluorine 38.csv', 'C:\\\\Users\\\\plankna\\\\Desktop\\\\PythonWorkshop\\\\Intro_documents\\\\Multiple\\\\Krypton 84.csv', 'C:\\\\Users\\\\plankna\\\\Desktop\\\\PythonWorkshop\\\\Intro_documents\\\\Multiple\\\\Methane 16.csv', 'C:\\\\Users\\\\plankna\\\\Desktop\\\\PythonWorkshop\\\\Intro_documents\\\\Multiple\\\\Neon 17.csv', 'C:\\\\Users\\\\plankna\\\\Desktop\\\\PythonWorkshop\\\\Intro_documents\\\\Multiple\\\\Nitrogen 28.csv', 'C:\\\\Users\\\\plankna\\\\Desktop\\\\PythonWorkshop\\\\Intro_documents\\\\Multiple\\\\Oxygen 32.csv', 'C:\\\\Users\\\\plankna\\\\Desktop\\\\PythonWorkshop\\\\Intro_documents\\\\Multiple\\\\Sulphur Dioxide 64.csv'] argh!!! depending on your filing system this might look horrible... print(masses) [38, 40, 71, 38, 84, 16, 17, 28, 32, 64] but hopefully this helps to see what has gone on. We have taken the string from the file name and turned them into an integer. To do this we counted back from the end of the file name... We now need to find out how many files we have in the folder. We know how to do that already. n=len(files) We also need to create an empty array to populate later. v=np.zeros(n) We now want to simply run though the previous code (in the single gas experiment) for all of the files in the folder. for j in range(n): #we need to indent all this code and change the argument in genfromtext #to files[j] rawdata=np.genfromtxt(files[j], delimiter=',') time=rawdata[:,0] pressure=rawdata[:,1] baseP=min(rawdata[:,1]) P_minus_baseP=[i-0.99*baseP for i in pressure] res=[abs(i-ef_begin) for i in P_minus_baseP] minres=min(res) for i in range (len(res)): if res[i]==minres: Peff_index=i break LogP=[log(i) for i in P_minus_baseP] fit=np.polyfit(time[Peff_index:1400],LogP[Peff_index:1400],1) m=fit[0] c=fit[1] note, we no longer have cats... ;-) compare this to your previous code. It is the same, just compressed. Now I am adding on to this and plotting the data. for j in range(n): #we need to indent all this code and change the argument in genfromtext #to files[j] rawdata=np.genfromtxt(files[j], delimiter=',') time=rawdata[:,0] pressure=rawdata[:,1] baseP=min(rawdata[:,1]) P_minus_baseP=[i-0.99*baseP for i in pressure] res=[abs(i-ef_begin) for i in P_minus_baseP] minres=min(res) for i in range (len(res)): if res[i]==minres: Peff_index=i break LogP=[log(i) for i in P_minus_baseP] fit=np.polyfit(time[Peff_index:1400],LogP[Peff_index:1400],1) m=fit[0] c=fit[1] #now we put each of these in one of the spots in the vector v v[j]=-4*V*m/A #now lets print v ######################print(v) #we can then plot v as a function of mass number plt.scatter(masses,v) #we can now create a theoritical line to match these to #first we need a range of mass numbers <matplotlib.collections.PathCollection at 0x2501a8d68d0> #now we simply complete the theoritical calculation vtheory=[math.sqrt(8/math.pi*1.38*(10**-23)*300/i/(1.67*10**-27)) for i in range(10,90)] #and plot the result on our plot plt.plot(range(10,90),vtheory,'k--') #we can add some labels plt.xlabel('Mass Number') plt.ylabel('Velocity') Text(0, 0.5, 'Velocity') Putting these last two parts together we find (this will be what comes up in Spyder. for j in range(n): #we need to indent all this code and change the argument in genfromtext #to files[j] rawdata=np.genfromtxt(files[j], delimiter=',') time=rawdata[:,0] pressure=rawdata[:,1] baseP=min(rawdata[:,1]) P_minus_baseP=[i-0.99*baseP for i in pressure] res=[abs(i-ef_begin) for i in P_minus_baseP] minres=min(res) for i in range (len(res)): if res[i]==minres: Peff_index=i break LogP=[log(i) for i in P_minus_baseP] fit=np.polyfit(time[Peff_index:1400],LogP[Peff_index:1400],1) m=fit[0] c=fit[1] #now we put each of these in one of the spots in the vector v v[j]=-4*V*m/A #now lets print v ######################print(v) #we can then plot v as a function of mass number plt.scatter(masses,v) #we can now create a theoritical line to match these to #first we need a range of mass numbers #now we simply complete the theoritical calculation vtheory=[math.sqrt(8/math.pi*1.38*(10**-23)*300/i/(1.67*10**-27)) for i in range(10,90)] #and plot the result on our plot plt.plot(range(10,90),vtheory,'k--') #we can add some labels plt.xlabel('Mass Number') plt.ylabel('Velocity') Text(0, 0.5, 'Velocity')","title":"Molecular Speeds lab Python data analysis - multiple gas dataset processing"},{"location":"phys221/Single_exp/","text":"Molecular Speeds lab Python data analysis - single gas dataset processing Start a new Code in the folder that contains the file \u2018Nitrogen 28_2.csv\u2019 I have given you an example of the full code in the workshop folder. Remember that we can 'comment out' code by using a # so the program won't try to run it. As you read through you'll see lots of print commands commented out, these were included to check the code was working. The first thing we want to do is define some constants that we will use later on. These will be the Volume of the bulb, the area of the opening and the pressure at which the effusion regime begins. You were asked to calculate some of these in the pre-workshop exercise as I reminder of the PHYS223 lab. So let\u2019s write the first piece of the code and set up same values to use later on (note capital V we are using here). V=2.03*10**-3 A=5.55113*10**-8 ef_begin=0.26 Let\u2019s check that worked by printing one of the variables print(V) 0.0020299999999999997 To start of with we need to call up the packages that help us handle our data. packages are bunches of functions that can be imported all at the same time for later use. The package we want is called \u2018numpy\u2019 so let\u2019s import that now. import numpy as np Now we want to import a module to help with plotting. Some of this may be in a slightly different order to the example .py code. Does that matter? from matplotlib import pyplot as plt We also want to load up the data that we have in our CSVs. If you remember back to the experiment the data is pressure as a function of time. Now we want to use numpy to import our data, the command we are going to use is called \u2018genfromtext\u2019. We will import the data into a variable, called rawdata: rawdata=np.genfromtxt(\"Nitrogen 28_2.csv\", delimiter=\"cat\") Hold on... What's this cat? note that the delimiter argument tells Python how the data is separated, just to prove a point I\u2019ve replaced all the commas, which are normally used to separate data, with the word \u2018cat\u2019. This seems silly, does it really help me learn? Hopefully. And think back to this when you move onto the multiple data example next. Now let\u2019s print the variable \u2018rawdata\u2019 print(rawdata) [[0.00000000e+00 3.91587981e+00] [1.00000000e+00 3.90860622e+00] [2.00000000e+00 3.89163795e+00] ... [2.28100000e+03 6.10025760e-02] [2.28200000e+03 6.10025760e-02] [2.28300000e+03 6.24196670e-02]] This looks good and along the lines of what you expect. It really makes sense to throw in a few tests here and there to make sure that the code is doing what you expect. Now we want to split this array up into two vectors, one for time and one for pressure, we can do that using the indexing we learned before. time=rawdata[:,0] pressure=rawdata[:,1] This \" : \" means [ first_row:last_row , column_0 ]. If you have a 2-dimensional list/matrix/array, this notation will give you all the values in column 0 (from all rows). We should probably test what's happening here, just to be sure... print(time) print(pressure) [0.000e+00 1.000e+00 2.000e+00 ... 2.281e+03 2.282e+03 2.283e+03] [3.91587981 3.90860622 3.89163795 ... 0.06100258 0.06100258 0.06241967] It's quite tricky to see what's really going on here, so let's plot it out to get a better idea. plt.figure(1) plt.plot(time,pressure) plt.xlabel(\"time (s)\") plt.ylabel(\"Pressure (Pa)\") Text(0, 0.5, 'Pressure (Pa)') Note that I am planning on having multiple figures so I have given this one a number. This should help as we move along.I even remembered to label my axes and to put in units. If you remember back to the experiment and what we actually have to do to from the basis of our analysis here, we need to find the minimum pressure we reached. To do this we will use an inbuilt python function \u2018min\u2019 and set the result as a new variable \u2018baseP\u2019. baseP=min(rawdata[:,1]) print(baseP) 0.061002576 Have a bit of a think about what that function is doing. It is going from the first data point and last data point in our pressure column (here 1) and finding the minimum. If you want to know more you can easily google this function and see how it operates. We are now going to use a list comprehension to subtract the base pressure from each value in \u2018Pressure\u2019 as we will need to take the log of this later (everyone remembers the experiment and you all definitely read ahead to see where this is going...). We therefore want to avoid 0 values, and as baseP is in \u2018Pressure\u2019 it will return a zero, so we can just multiply it by 0.99 to avoid this. P_minus_baseP=[i-0.99*baseP for i in pressure] print(P_minus_baseP) - do this at your peril. It gives a big list... Now we have our pressure minus base pressure we need to find the point at which the effusion regime begins, to do this we are going to make a new vector of residuals. We already know the pressure at which the effusion regime begins, we called it \u2018ef_begin\u2019, what we don't know is the INDEX of this value in the pressure vector. We are going to find this using residuals. This vector \u2018Res\u2019 will be a vector where we take the value we are looking for \u2018ef_begin\u2019 from all values of the pressure vector the smallest value of this vector will have an index equal to that of when the effusion regime begins, in the vector \u2018Pressure\u2019. res=[abs(i-ef_begin) for i in P_minus_baseP] You should recognice the look comprehension in the line above. We've made a new array as described above. We now need to take the minimum value. minres=min(res) print(minres) 0.00043142575999999266 I get 0.00043142575999999266, you should get something similar\u2026. Or the same. We now need to find the index of the minimum value, for this we will use a for loop, we want the loop to run for as many entries as we have in res so we can make it run for \u2018len(res)\u2019 we then want to use an if statement, so when \u2018res[i]=minres\u2019 we assign that \u2018I\u2019 to a variable, then stop. Just take a moment and think that through. Can you write it yourself? for i in range (len(res)): if res[i]==minres: Peff_index=i break print(Peff_index) 691 Now we have the value of the index where the effusion regime begins we can move on. The next step is to take the log of our data, to do this we need to import another module called \u2018math\u2019. Maybe we could have added that to the top with numpy and matplotlib, but here we are. from math import log import math We are going to use another list comprehension to create a new vector with all the logged values LogP=[log(i) for i in P_minus_baseP] print(LogP) - if you want to check things. I find it better to plot. Especially as you have your own data that you can double check against. plt.figure(2) plt.plot(time,LogP) plt.xlabel(\"time (s)\") plt.ylabel(\"log Pressure (Pa)\") Text(0, 0.5, 'log Pressure (Pa)') We can also plot only the data after we reach the effusion regime, on the same figure, the \u2018r\u2019 makes it red. plt.plot(time[Peff_index:],LogP[Peff_index:],\"r\") [<matplotlib.lines.Line2D at 0x7fca48843e10>] Actually, in spyder that just plots ontop.. plt.figure(2) plt.plot(time,LogP) plt.xlabel(\"time (s)\") plt.ylabel(\"log Pressure (Pa)\") plt.plot(time[Peff_index:],LogP[Peff_index:],\"r\") [<matplotlib.lines.Line2D at 0x7fca88a9e790>] Here in the Jupyter environment I had to put them together in one code section. So if anyone is using Jupyter you will have to do what I just did here. Now I want to fit a trend line to the section of the data in the effusion regime. To do this I'll use a fitting tool and create a new variable. fit=np.polyfit(time[Peff_index:1400],LogP[Peff_index:1400],1) It is worth having a bit of a think about what this polyfit is doing. It is a numpy function. polyfit(x,y, degree of polynomial). What is 1400 representing? Why is that the cut-off? Maybe take a look at your own lab report. But the plot here is helpful too I think. Now is probably a good time for another print... print(fit[0]) print(fit[1]) -0.0032100701686121782 0.8597164594476661 We were fitting a straight line! The fit function returns two values, one is the gradient and one is the intercept, we can make these into their own variable. m=fit[0] c=fit[1] Now we can plot this. plt.plot(time[Peff_index:1400],time[Peff_index:1400]*m+c, \"k--\") [<matplotlib.lines.Line2D at 0x7fca68e3b250>] For me, I need to plot it ontop of the existing plots again. plt.figure(2) plt.plot(time,LogP) plt.xlabel(\"time (s)\") plt.ylabel(\"log Pressure (Pa)\") plt.plot(time[Peff_index:],LogP[Peff_index:],\"r\") plt.plot(time[Peff_index:1400],time[Peff_index:1400]*m+c, \"k--\") [<matplotlib.lines.Line2D at 0x7fca48899f90>] Hopefully you can see it all, and the small black dashes. You can look up the plot instructions to see what k means. We now can calculate the velocity of the nitrogen from the fit. Which remember, is the reason we\u2019ve done all this work... and let's print it. v=-4*V*m/A print(v) 469.5579056720142 Do you get the same? Does it agree with your lab report?","title":"Molecular Speeds lab Python data analysis - single gas dataset processing"},{"location":"phys221/Single_exp/#molecular-speeds-lab-python-data-analysis-single-gas-dataset-processing","text":"Start a new Code in the folder that contains the file \u2018Nitrogen 28_2.csv\u2019 I have given you an example of the full code in the workshop folder. Remember that we can 'comment out' code by using a # so the program won't try to run it. As you read through you'll see lots of print commands commented out, these were included to check the code was working. The first thing we want to do is define some constants that we will use later on. These will be the Volume of the bulb, the area of the opening and the pressure at which the effusion regime begins. You were asked to calculate some of these in the pre-workshop exercise as I reminder of the PHYS223 lab. So let\u2019s write the first piece of the code and set up same values to use later on (note capital V we are using here). V=2.03*10**-3 A=5.55113*10**-8 ef_begin=0.26 Let\u2019s check that worked by printing one of the variables print(V) 0.0020299999999999997 To start of with we need to call up the packages that help us handle our data. packages are bunches of functions that can be imported all at the same time for later use. The package we want is called \u2018numpy\u2019 so let\u2019s import that now. import numpy as np Now we want to import a module to help with plotting. Some of this may be in a slightly different order to the example .py code. Does that matter? from matplotlib import pyplot as plt We also want to load up the data that we have in our CSVs. If you remember back to the experiment the data is pressure as a function of time. Now we want to use numpy to import our data, the command we are going to use is called \u2018genfromtext\u2019. We will import the data into a variable, called rawdata: rawdata=np.genfromtxt(\"Nitrogen 28_2.csv\", delimiter=\"cat\") Hold on... What's this cat? note that the delimiter argument tells Python how the data is separated, just to prove a point I\u2019ve replaced all the commas, which are normally used to separate data, with the word \u2018cat\u2019. This seems silly, does it really help me learn? Hopefully. And think back to this when you move onto the multiple data example next. Now let\u2019s print the variable \u2018rawdata\u2019 print(rawdata) [[0.00000000e+00 3.91587981e+00] [1.00000000e+00 3.90860622e+00] [2.00000000e+00 3.89163795e+00] ... [2.28100000e+03 6.10025760e-02] [2.28200000e+03 6.10025760e-02] [2.28300000e+03 6.24196670e-02]] This looks good and along the lines of what you expect. It really makes sense to throw in a few tests here and there to make sure that the code is doing what you expect. Now we want to split this array up into two vectors, one for time and one for pressure, we can do that using the indexing we learned before. time=rawdata[:,0] pressure=rawdata[:,1] This \" : \" means [ first_row:last_row , column_0 ]. If you have a 2-dimensional list/matrix/array, this notation will give you all the values in column 0 (from all rows). We should probably test what's happening here, just to be sure... print(time) print(pressure) [0.000e+00 1.000e+00 2.000e+00 ... 2.281e+03 2.282e+03 2.283e+03] [3.91587981 3.90860622 3.89163795 ... 0.06100258 0.06100258 0.06241967] It's quite tricky to see what's really going on here, so let's plot it out to get a better idea. plt.figure(1) plt.plot(time,pressure) plt.xlabel(\"time (s)\") plt.ylabel(\"Pressure (Pa)\") Text(0, 0.5, 'Pressure (Pa)') Note that I am planning on having multiple figures so I have given this one a number. This should help as we move along.I even remembered to label my axes and to put in units. If you remember back to the experiment and what we actually have to do to from the basis of our analysis here, we need to find the minimum pressure we reached. To do this we will use an inbuilt python function \u2018min\u2019 and set the result as a new variable \u2018baseP\u2019. baseP=min(rawdata[:,1]) print(baseP) 0.061002576 Have a bit of a think about what that function is doing. It is going from the first data point and last data point in our pressure column (here 1) and finding the minimum. If you want to know more you can easily google this function and see how it operates. We are now going to use a list comprehension to subtract the base pressure from each value in \u2018Pressure\u2019 as we will need to take the log of this later (everyone remembers the experiment and you all definitely read ahead to see where this is going...). We therefore want to avoid 0 values, and as baseP is in \u2018Pressure\u2019 it will return a zero, so we can just multiply it by 0.99 to avoid this. P_minus_baseP=[i-0.99*baseP for i in pressure] print(P_minus_baseP) - do this at your peril. It gives a big list... Now we have our pressure minus base pressure we need to find the point at which the effusion regime begins, to do this we are going to make a new vector of residuals. We already know the pressure at which the effusion regime begins, we called it \u2018ef_begin\u2019, what we don't know is the INDEX of this value in the pressure vector. We are going to find this using residuals. This vector \u2018Res\u2019 will be a vector where we take the value we are looking for \u2018ef_begin\u2019 from all values of the pressure vector the smallest value of this vector will have an index equal to that of when the effusion regime begins, in the vector \u2018Pressure\u2019. res=[abs(i-ef_begin) for i in P_minus_baseP] You should recognice the look comprehension in the line above. We've made a new array as described above. We now need to take the minimum value. minres=min(res) print(minres) 0.00043142575999999266 I get 0.00043142575999999266, you should get something similar\u2026. Or the same. We now need to find the index of the minimum value, for this we will use a for loop, we want the loop to run for as many entries as we have in res so we can make it run for \u2018len(res)\u2019 we then want to use an if statement, so when \u2018res[i]=minres\u2019 we assign that \u2018I\u2019 to a variable, then stop. Just take a moment and think that through. Can you write it yourself? for i in range (len(res)): if res[i]==minres: Peff_index=i break print(Peff_index) 691 Now we have the value of the index where the effusion regime begins we can move on. The next step is to take the log of our data, to do this we need to import another module called \u2018math\u2019. Maybe we could have added that to the top with numpy and matplotlib, but here we are. from math import log import math We are going to use another list comprehension to create a new vector with all the logged values LogP=[log(i) for i in P_minus_baseP] print(LogP) - if you want to check things. I find it better to plot. Especially as you have your own data that you can double check against. plt.figure(2) plt.plot(time,LogP) plt.xlabel(\"time (s)\") plt.ylabel(\"log Pressure (Pa)\") Text(0, 0.5, 'log Pressure (Pa)') We can also plot only the data after we reach the effusion regime, on the same figure, the \u2018r\u2019 makes it red. plt.plot(time[Peff_index:],LogP[Peff_index:],\"r\") [<matplotlib.lines.Line2D at 0x7fca48843e10>] Actually, in spyder that just plots ontop.. plt.figure(2) plt.plot(time,LogP) plt.xlabel(\"time (s)\") plt.ylabel(\"log Pressure (Pa)\") plt.plot(time[Peff_index:],LogP[Peff_index:],\"r\") [<matplotlib.lines.Line2D at 0x7fca88a9e790>] Here in the Jupyter environment I had to put them together in one code section. So if anyone is using Jupyter you will have to do what I just did here. Now I want to fit a trend line to the section of the data in the effusion regime. To do this I'll use a fitting tool and create a new variable. fit=np.polyfit(time[Peff_index:1400],LogP[Peff_index:1400],1) It is worth having a bit of a think about what this polyfit is doing. It is a numpy function. polyfit(x,y, degree of polynomial). What is 1400 representing? Why is that the cut-off? Maybe take a look at your own lab report. But the plot here is helpful too I think. Now is probably a good time for another print... print(fit[0]) print(fit[1]) -0.0032100701686121782 0.8597164594476661 We were fitting a straight line! The fit function returns two values, one is the gradient and one is the intercept, we can make these into their own variable. m=fit[0] c=fit[1] Now we can plot this. plt.plot(time[Peff_index:1400],time[Peff_index:1400]*m+c, \"k--\") [<matplotlib.lines.Line2D at 0x7fca68e3b250>] For me, I need to plot it ontop of the existing plots again. plt.figure(2) plt.plot(time,LogP) plt.xlabel(\"time (s)\") plt.ylabel(\"log Pressure (Pa)\") plt.plot(time[Peff_index:],LogP[Peff_index:],\"r\") plt.plot(time[Peff_index:1400],time[Peff_index:1400]*m+c, \"k--\") [<matplotlib.lines.Line2D at 0x7fca48899f90>] Hopefully you can see it all, and the small black dashes. You can look up the plot instructions to see what k means. We now can calculate the velocity of the nitrogen from the fit. Which remember, is the reason we\u2019ve done all this work... and let's print it. v=-4*V*m/A print(v) 469.5579056720142 Do you get the same? Does it agree with your lab report?","title":"Molecular Speeds lab Python data analysis - single gas dataset processing"},{"location":"phys304/Ylm/","text":"adapted from https://scipython.com/book/chapter-8-scipy/examples/visualizing-the-spherical-harmonics/ Required dependencies import numpy as np import scipy as sp from scipy.special import sph_harm Spherical grid ## first, evaluate the potential on a fine grid # at r=10. R = 10. Np = 36 Nt=18 theta = -np.arccos(np.linspace(-1, 1, Nt)) phi = np.linspace(0, 2*np.pi, Np) theta, phi = np.meshgrid(theta, phi) x = R * np.sin(theta) * np.cos(phi) y = R * np.sin(theta) * np.sin(phi) z = R * np.cos(theta) Spherical harmonics m = 0 l = 1 Y01 = 1/R**2 * sph_harm(m, l, phi, theta).real Plotting (static) import matplotlib.pyplot as plt from matplotlib import cm, colors from mpl_toolkits.mplot3d import Axes3D fmax, fmin = Y01.max(), Y01.min() Y01 = (Y01 - fmin)/(fmax - fmin) # Set the aspect ratio to 1 so our sphere looks spherical fig = plt.figure(figsize=plt.figaspect(1.)) ax = fig.add_subplot(111, projection='3d') ax.plot_surface(x, y, z, rstride=1, cstride=1, facecolors=cm.seismic(Y01)) # Turn off the axis planes ax.set_axis_off() plt.show() Plotting (interactive) import plotly.graph_objects as go import chart_studio.plotly as py fig = go.Figure() fig.add_trace(go.Surface(x=x, y=y, z=z, surfacecolor=Y01, showscale=False, colorscale='PrGN')) fig.show() require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {}; if (document.getElementById(\"ef403284-6a59-48e2-b0f4-de24074c0eb6\")) { Plotly.newPlot( 'ef403284-6a59-48e2-b0f4-de24074c0eb6', [{\"colorscale\": [[0.0, \"rgb(64,0,75)\"], [0.1, \"rgb(118,42,131)\"], [0.2, \"rgb(153,112,171)\"], [0.3, \"rgb(194,165,207)\"], [0.4, \"rgb(231,212,232)\"], [0.5, \"rgb(247,247,247)\"], [0.6, \"rgb(217,240,211)\"], [0.7, \"rgb(166,219,160)\"], [0.8, \"rgb(90,174,97)\"], [0.9, \"rgb(27,120,55)\"], [1.0, \"rgb(0,68,27)\"]], \"showscale\": false, \"surfacecolor\": [[0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0]], \"type\": \"surface\", \"x\": [[-1.2246467991473533e-15, -4.705882352941178, -6.443794794178425, -7.624400821656306, -8.483650059915268, -9.112901991076274, -9.557692240748189, -9.843059135695006, -9.982683969692435, -9.982683969692435, -9.843059135695006, -9.557692240748189, -9.112901991076276, -8.483650059915268, -7.624400821656307, -6.443794794178426, -4.7058823529411775, -0.0], [-1.204966221263684e-15, -4.630256887522965, -6.340240360849969, -7.501873563763343, -8.34731431326717, -8.966453907019313, -9.40409619439168, -9.68487712593637, -9.822258131409612, -9.822258131409612, -9.68487712593637, -9.40409619439168, -8.966453907019314, -8.34731431326717, -7.501873563763344, -6.34024036084997, -4.630256887522965, -0.0], [-1.1465570375790906e-15, -4.405811155951707, -6.032905385556649, -7.138229916968898, -7.94268901639757, -8.5318166167679, -8.9482447586313, -9.215415196606697, -9.346136835002374, -9.346136835002374, -9.215415196606697, -8.9482447586313, -8.531816616767902, -7.94268901639757, -7.138229916968899, -6.03290538555665, -4.405811155951706, -0.0], [-1.0512965673164322e-15, -4.039759028714665, -5.531667867280454, -6.545157687287933, -7.282779159274661, -7.822959720451471, -8.204789373688198, -8.449762240389205, -8.569623010691158, -8.569623010691158, -8.449762240389205, -8.204789373688198, -7.822959720451473, -7.282779159274661, -6.545157687287934, -5.531667867280454, -4.0397590287146645, -0.0], [-9.22246560370527e-16, -3.5438657223699352, -4.852637992278383, -5.74171870416385, -6.388794787682013, -6.862666461967035, -7.197625307351576, -7.412526973278074, -7.517674451707029, -7.517674451707029, -7.412526973278074, -7.197625307351576, -6.862666461967036, -6.388794787682013, -5.741718704163851, -4.8526379922783835, -3.543865722369935, -0.0], [-7.635547901473156e-16, -2.934069655805806, -4.0176403394406455, -4.753736157586056, -5.289469294895404, -5.681801456774205, -5.9591236414108435, -6.137046990198277, -6.224101650281892, -6.224101650281892, -6.137046990198277, -5.9591236414108435, -5.681801456774206, -5.289469294895404, -4.753736157586056, -4.0176403394406455, -2.9340696558058057, -0.0], [-5.803217407137954e-16, -2.229970176343524, -3.053512420367802, -3.612964619516306, -4.020135906781023, -4.318318677758841, -4.529090838451902, -4.664317267274423, -4.730481100608799, -4.730481100608799, -4.664317267274423, -4.529090838451902, -4.318318677758842, -4.020135906781023, -3.6129646195163065, -3.0535124203678023, -2.2299701763435236, -0.0], [-3.7843667304341507e-16, -1.4541976205879885, -1.99124209966595, -2.3560694258181116, -2.621592042843859, -2.8160415833158643, -2.953489329396762, -3.041672549567339, -3.084818996109325, -3.084818996109325, -3.041672549567339, -2.953489329396762, -2.816041583315865, -2.621592042843859, -2.3560694258181116, -1.9912420996659503, -1.4541976205879883, -0.0], [-1.6438833932268765e-16, -0.6316859567889674, -0.8649716194813774, -1.023448222193742, -1.1387880535965753, -1.2232545953383838, -1.2829602431556952, -1.3212659734206502, -1.340008270877373, -1.340008270877373, -1.3212659734206502, -1.2829602431556952, -1.223254595338384, -1.1387880535965753, -1.0234482221937422, -0.8649716194813775, -0.6316859567889673, -0.0], [5.4943570883047055e-17, 0.21112861341418768, 0.28909976025434586, 0.3420674493879363, 0.3806175206912337, 0.40884880183050615, 0.42880424092359976, 0.44160717825304185, 0.4478714227430553, 0.4478714227430553, 0.44160717825304185, 0.42880424092359976, 0.4088488018305062, 0.3806175206912337, 0.3420674493879363, 0.2890997602543459, 0.21112861341418762, 0.0], [2.7250954951287997e-16, 1.047157336265009, 1.4338792358234194, 1.6965887916922517, 1.8877897346908876, 2.027811462106649, 2.1267866038783056, 2.190286711862085, 2.221356160326688, 2.221356160326688, 2.190286711862085, 2.1267866038783056, 2.0278114621066496, 1.8877897346908876, 1.696588791692252, 1.4338792358234196, 1.0471573362650088, 0.0], [4.813168469997646e-16, 1.849529560724347, 2.5325726529533634, 2.9965803742736705, 3.3342868333390085, 3.5815985935018557, 3.7564122954585164, 3.868568628377971, 3.9234446831794845, 3.9234446831794845, 3.868568628377971, 3.7564122954585164, 3.581598593501856, 3.3342868333390085, 2.996580374273671, 2.5325726529533634, 1.8495295607243465, 0.0], [6.74654224995256e-16, 2.5924563833040124, 3.549867101209666, 4.200259398031388, 4.673617209703269, 5.020270199152773, 5.265303805076358, 5.422511566108919, 5.4994304656938535, 5.4994304656938535, 5.422511566108919, 5.265303805076358, 5.020270199152774, 4.673617209703269, 4.200259398031389, 3.5498671012096663, 2.592456383304012, 0.0], [8.463076610920545e-16, 3.2520595246440696, 4.45306589999271, 5.2689386287514335, 5.862733683482618, 6.2975861899108425, 6.604964118092644, 6.802170520447748, 6.898660028094362, 6.898660028094362, 6.802170520447748, 6.604964118092644, 6.297586189910843, 5.862733683482618, 5.268938628751434, 4.45306589999271, 3.252059524644069, 0.0], [9.907600726170915e-16, 3.8071387970585775, 5.213139496755161, 6.168269836646264, 6.863417072801492, 7.3724925788540006, 7.732335449770855, 7.96320211741484, 8.07616098095554, 8.07616098095554, 7.96320211741484, 7.732335449770855, 7.372492578854002, 6.863417072801492, 6.168269836646265, 5.213139496755162, 3.8071387970585766, 0.0], [1.103368640208112e-15, 4.239853496011386, 5.8056585007064365, 6.8693477767219555, 7.643504590162149, 8.210440990205692, 8.61118315790663, 8.868289846183693, 8.99408747480142, 8.99408747480142, 8.868289846183693, 8.61118315790663, 8.210440990205694, 7.643504590162149, 6.869347776721956, 5.805658500706437, 4.239853496011385, 0.0], [1.1805140318481027e-15, 4.536295815039312, 6.211578863533282, 7.349639227135627, 8.177923580898469, 8.784499072558821, 9.213260354042184, 9.48834344244301, 9.622936596847355, 9.622936596847355, 9.48834344244301, 9.213260354042184, 8.784499072558823, 8.177923580898469, 7.3496392271356275, 6.2115788635332825, 4.536295815039311, 0.0], [1.2197167311743145e-15, 4.686937854095245, 6.417853970782054, 7.59370722548586, 8.449497378926777, 9.076216126810001, 9.519215781702952, 9.803433873427222, 9.942496618892013, 9.942496618892013, 9.803433873427222, 9.519215781702952, 9.076216126810003, 8.449497378926777, 7.593707225485861, 6.417853970782055, 4.686937854095244, 0.0], [1.2197167311743145e-15, 4.686937854095245, 6.417853970782054, 7.59370722548586, 8.449497378926777, 9.076216126810001, 9.519215781702952, 9.803433873427222, 9.942496618892013, 9.942496618892013, 9.803433873427222, 9.519215781702952, 9.076216126810003, 8.449497378926777, 7.593707225485861, 6.417853970782055, 4.686937854095244, 0.0], [1.1805140318481027e-15, 4.536295815039312, 6.211578863533282, 7.3496392271356275, 8.17792358089847, 8.784499072558823, 9.213260354042184, 9.48834344244301, 9.622936596847357, 9.622936596847357, 9.48834344244301, 9.213260354042184, 8.784499072558825, 8.17792358089847, 7.349639227135628, 6.2115788635332825, 4.536295815039311, 0.0], [1.1033686402081122e-15, 4.239853496011386, 5.805658500706437, 6.869347776721956, 7.6435045901621494, 8.210440990205692, 8.611183157906632, 8.868289846183693, 8.99408747480142, 8.99408747480142, 8.868289846183693, 8.611183157906632, 8.210440990205694, 7.6435045901621494, 6.869347776721957, 5.805658500706438, 4.239853496011385, 0.0], [9.907600726170917e-16, 3.807138797058578, 5.213139496755162, 6.168269836646265, 6.863417072801493, 7.372492578854001, 7.732335449770856, 7.963202117414841, 8.076160980955542, 8.076160980955542, 7.963202117414841, 7.732335449770856, 7.372492578854003, 6.863417072801493, 6.168269836646266, 5.213139496755163, 3.807138797058577, 0.0], [8.463076610920548e-16, 3.252059524644071, 4.453065899992711, 5.268938628751435, 5.862733683482619, 6.297586189910844, 6.604964118092647, 6.80217052044775, 6.898660028094365, 6.898660028094365, 6.80217052044775, 6.604964118092647, 6.297586189910845, 5.862733683482619, 5.268938628751436, 4.453065899992712, 3.25205952464407, 0.0], [6.746542249952563e-16, 2.5924563833040133, 3.549867101209667, 4.20025939803139, 4.673617209703271, 5.020270199152775, 5.2653038050763605, 5.422511566108921, 5.499430465693855, 5.499430465693855, 5.422511566108921, 5.2653038050763605, 5.020270199152776, 4.673617209703271, 4.200259398031391, 3.5498671012096676, 2.592456383304013, 0.0], [4.813168469997649e-16, 1.8495295607243478, 2.5325726529533648, 2.9965803742736723, 3.3342868333390108, 3.5815985935018575, 3.7564122954585186, 3.868568628377973, 3.9234446831794867, 3.9234446831794867, 3.868568628377973, 3.7564122954585186, 3.5815985935018584, 3.3342868333390108, 2.9965803742736723, 2.532572652953365, 1.8495295607243476, 0.0], [2.7250954951288026e-16, 1.0471573362650102, 1.433879235823421, 1.6965887916922535, 1.8877897346908896, 2.0278114621066514, 2.1267866038783083, 2.1902867118620875, 2.2213561603266907, 2.2213561603266907, 2.1902867118620875, 2.1267866038783083, 2.027811462106652, 1.8877897346908896, 1.6965887916922537, 1.4338792358234211, 1.04715733626501, 0.0], [5.494357088304735e-17, 0.21112861341418881, 0.2890997602543474, 0.34206744938793815, 0.38061752069123583, 0.40884880183050837, 0.42880424092360203, 0.44160717825304424, 0.44787142274305775, 0.44787142274305775, 0.44160717825304424, 0.42880424092360203, 0.4088488018305084, 0.38061752069123583, 0.3420674493879382, 0.28909976025434747, 0.2111286134141888, 0.0], [-1.6438833932268735e-16, -0.6316859567889662, -0.8649716194813757, -1.0234482221937402, -1.1387880535965733, -1.2232545953383815, -1.2829602431556928, -1.3212659734206478, -1.3400082708773706, -1.3400082708773706, -1.3212659734206478, -1.2829602431556928, -1.2232545953383818, -1.1387880535965733, -1.0234482221937402, -0.8649716194813758, -0.6316859567889661, -0.0], [-3.7843667304341477e-16, -1.4541976205879876, -1.9912420996659486, -2.35606942581811, -2.621592042843857, -2.8160415833158625, -2.95348932939676, -3.0416725495673367, -3.084818996109323, -3.084818996109323, -3.0416725495673367, -2.95348932939676, -2.816041583315863, -2.621592042843857, -2.35606942581811, -1.9912420996659488, -1.4541976205879872, -0.0], [-5.803217407137952e-16, -2.2299701763435236, -3.053512420367801, -3.6129646195163048, -4.020135906781022, -4.318318677758839, -4.529090838451901, -4.664317267274421, -4.730481100608797, -4.730481100608797, -4.664317267274421, -4.529090838451901, -4.31831867775884, -4.020135906781022, -3.612964619516305, -3.0535124203678015, -2.229970176343523, -0.0], [-7.635547901473153e-16, -2.9340696558058053, -4.017640339440644, -4.753736157586054, -5.289469294895402, -5.6818014567742035, -5.959123641410842, -6.137046990198274, -6.22410165028189, -6.22410165028189, -6.137046990198274, -5.959123641410842, -5.681801456774204, -5.289469294895402, -4.753736157586054, -4.017640339440645, -2.934069655805805, -0.0], [-9.22246560370527e-16, -3.543865722369935, -4.852637992278383, -5.7417187041638496, -6.388794787682012, -6.862666461967034, -7.197625307351575, -7.412526973278073, -7.517674451707027, -7.517674451707027, -7.412526973278073, -7.197625307351575, -6.862666461967035, -6.388794787682012, -5.74171870416385, -4.852637992278383, -3.5438657223699344, -0.0], [-1.051296567316432e-15, -4.039759028714665, -5.531667867280453, -6.545157687287932, -7.28277915927466, -7.82295972045147, -8.204789373688198, -8.449762240389203, -8.569623010691156, -8.569623010691156, -8.449762240389203, -8.204789373688198, -7.822959720451472, -7.28277915927466, -6.545157687287933, -5.531667867280454, -4.0397590287146645, -0.0], [-1.1465570375790904e-15, -4.405811155951706, -6.032905385556649, -7.138229916968897, -7.942689016397569, -8.531816616767898, -8.948244758631299, -9.215415196606696, -9.346136835002374, -9.346136835002374, -9.215415196606696, -8.948244758631299, -8.5318166167679, -7.942689016397569, -7.138229916968898, -6.03290538555665, -4.405811155951705, -0.0], [-1.204966221263684e-15, -4.630256887522965, -6.340240360849969, -7.501873563763343, -8.34731431326717, -8.966453907019313, -9.40409619439168, -9.68487712593637, -9.822258131409612, -9.822258131409612, -9.68487712593637, -9.40409619439168, -8.966453907019314, -8.34731431326717, -7.501873563763344, -6.34024036084997, -4.630256887522965, -0.0], [-1.2246467991473533e-15, -4.705882352941178, -6.443794794178425, -7.624400821656306, -8.483650059915268, -9.112901991076274, -9.557692240748189, -9.843059135695006, -9.982683969692435, -9.982683969692435, -9.843059135695006, -9.557692240748189, -9.112901991076276, -8.483650059915268, -7.624400821656307, -6.443794794178426, -4.7058823529411775, -0.0]], \"y\": [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0], [-2.1866912968084107e-16, -0.8402677402288787, -1.1505839891681195, -1.3613893354151239, -1.514814211256738, -1.6271714821308927, -1.70659184794902, -1.7575460745890525, -1.7824770513844086, -1.7824770513844086, -1.7575460745890525, -1.70659184794902, -1.6271714821308931, -1.514814211256738, -1.361389335415124, -1.1505839891681198, -0.8402677402288785, -0.0], [-4.3031005361218065e-16, -1.6535285839122016, -2.264187262220716, -2.6790224974351293, -2.9809410473703997, -3.202044333984943, -3.358332429716509, -3.4586031722270856, -3.507663823710319, -3.507663823710319, -3.4586031722270856, -3.358332429716509, -3.202044333984944, -2.9809410473703997, -2.6790224974351293, -2.264187262220716, -1.6535285839122011, -0.0], [-6.281204583601334e-16, -2.4136436583807357, -3.305017693686054, -3.910549672080516, -4.3512579854951134, -4.674000846293865, -4.902133443947782, -5.048497918161571, -5.120111394626772, -5.120111394626772, -5.048497918161571, -4.902133443947782, -4.674000846293866, -4.3512579854951134, -3.910549672080517, -3.3050176936860542, -2.4136436583807352, -0.0], [-8.0574255475715675e-16, -3.096182239716296, -4.2396221370987055, -5.016388562654248, -5.5817219117390175, -5.995731125622194, -6.28837585580174, -6.4761297870884205, -6.567994372478233, -6.567994372478233, -6.4761297870884205, -6.28837585580174, -5.9957311256221955, -5.5817219117390175, -5.016388562654249, -4.2396221370987055, -3.096182239716295, -0.0], [-9.574674224771025e-16, -3.6792069763201414, -5.03796163665229, -5.960996597326013, -6.632784703083543, -7.124753673269023, -7.472504693557341, -7.695613516080909, -7.804776607034472, -7.804776607034472, -7.695613516080909, -7.472504693557341, -7.124753673269025, -6.632784703083543, -5.960996597326014, -5.037961636652291, -3.6792069763201405, -0.0], [-1.0784184994318154e-15, -4.143978973443475, -5.674376903955229, -6.714013296635385, -7.470664336597533, -8.024780775590138, -8.41646108206467, -8.667753894694668, -8.790706899649042, -8.790706899649042, -8.667753894694668, -8.41646108206467, -8.02478077559014, -7.470664336597533, -6.714013296635386, -5.67437690395523, -4.143978973443474, -0.0], [-1.1647083184890924e-15, -4.475560076683077, -6.1284130286721785, -7.251236084282353, -8.068430671450185, -8.66688482097217, -9.089905486307192, -9.361305531281277, -9.494096639491161, -9.494096639491161, -9.361305531281277, -9.089905486307192, -8.666884820972172, -8.068430671450185, -7.251236084282354, -6.128413028672179, -4.4755600766830765, -0.0], [-1.2135634538649334e-15, -4.663292996554989, -6.385476916172568, -7.555398177843562, -8.40687100579556, -9.030428057071571, -9.471192849020655, -9.753977105584658, -9.892338301571298, -9.892338301571298, -9.753977105584658, -9.471192849020655, -9.030428057071573, -8.40687100579556, -7.555398177843563, -6.385476916172569, -4.663292996554988, -0.0], [-1.2234136613102199e-15, -4.701143842547365, -6.437306321599264, -7.616723557366552, -8.475107588818162, -9.10372590515574, -9.548068280643163, -9.833147830115456, -9.97263207119587, -9.97263207119587, -9.833147830115456, -9.548068280643163, -9.103725905155741, -8.475107588818162, -7.616723557366553, -6.437306321599265, -4.701143842547364, -0.0], [-1.1939423470528821e-15, -4.587896057326231, -6.2822354052164755, -7.433241174694763, -8.270947240594396, -8.884422512077576, -9.318060941549048, -9.596273092645356, -9.732397240543204, -9.732397240543204, -9.596273092645356, -9.318060941549048, -8.884422512077577, -8.270947240594396, -7.433241174694764, -6.282235405216476, -4.58789605732623, -0.0], [-1.1260967433822296e-15, -4.327189517889181, -5.925248273869521, -7.010848304577074, -7.800951842699868, -8.379566469334046, -8.788563456867466, -9.050966242137836, -9.179355154736358, -9.179355154736358, -9.050966242137836, -8.788563456867466, -8.379566469334048, -7.800951842699868, -7.010848304577075, -5.925248273869522, -4.327189517889181, -0.0], [-1.0220574638237853e-15, -3.927403546923779, -5.37781878768988, -6.363121001405077, -7.08022743393641, -7.605384265535864, -7.976594311428065, -8.214753889448176, -8.331281041457705, -8.331281041457705, -8.214753889448176, -7.976594311428065, -7.605384265535866, -7.08022743393641, -6.363121001405078, -5.377818787689881, -3.9274035469237787, -0.0], [-8.851684164263621e-16, -3.401387594481844, -4.657541780789849, -5.510877753654522, -6.131938689815699, -6.586758753712341, -6.908250861655704, -7.114512587629634, -7.215432700505728, -7.215432700505728, -7.114512587629634, -6.908250861655704, -6.586758753712342, -6.131938689815699, -5.510877753654523, -4.65754178078985, -3.4013875944818435, -0.0], [-7.198293278059968e-16, -2.766048246082228, -3.787567548817091, -4.481510360536192, -4.9865643908283515, -5.356429395941349, -5.617870545061988, -5.7856049974042225, -5.867674415681696, -5.867674415681696, -5.7856049974042225, -5.617870545061988, -5.356429395941351, -4.9865643908283515, -4.481510360536193, -3.787567548817092, -2.7660482460822275, -0.0], [-5.313543323124029e-16, -2.0418058311414513, -2.7958577794043915, -3.3081035370312213, -3.6809178093609334, -3.953939990100015, -4.146927246750698, -4.27074330215059, -4.3313242471990625, -4.3313242471990625, -4.27074330215059, -4.146927246750698, -3.953939990100016, -3.6809178093609334, -3.3081035370312217, -2.795857779404392, -2.041805831141451, -0.0], [-3.2580117137848757e-16, -1.2519380967843545, -1.7142868405221914, -2.0283715439294103, -2.256963500831393, -2.424367699664206, -2.542698294625736, -2.618616403186544, -2.6557617535859905, -2.6557617535859905, -2.618616403186544, -2.542698294625736, -2.4243676996642063, -2.256963500831393, -2.0283715439294108, -1.7142868405221916, -1.2519380967843543, -0.0], [-1.0977649272637083e-16, -0.4218320418985113, -0.5776173120656973, -0.6834460204560427, -0.7604685283493778, -0.8168742365848014, -0.8567449271723776, -0.882325018419329, -0.8948408920446151, -0.8948408920446151, -0.882325018419329, -0.8567449271723776, -0.8168742365848016, -0.7604685283493778, -0.6834460204560429, -0.5776173120656973, -0.42183204189851126, -0.0], [1.0977649272637052e-16, 0.42183204189851015, 0.5776173120656957, 0.6834460204560409, 0.7604685283493757, 0.8168742365847992, 0.8567449271723752, 0.8823250184193265, 0.8948408920446126, 0.8948408920446126, 0.8823250184193265, 0.8567449271723752, 0.8168742365847993, 0.7604685283493757, 0.6834460204560409, 0.5776173120656958, 0.4218320418985101, 0.0], [3.2580117137848727e-16, 1.2519380967843534, 1.71428684052219, 2.0283715439294085, 2.2569635008313913, 2.424367699664204, 2.5426982946257337, 2.6186164031865418, 2.6557617535859883, 2.6557617535859883, 2.6186164031865418, 2.5426982946257337, 2.4243676996642045, 2.2569635008313913, 2.028371543929409, 1.7142868405221903, 1.2519380967843532, 0.0], [5.313543323124027e-16, 2.0418058311414504, 2.79585777940439, 3.3081035370312195, 3.6809178093609316, 3.953939990100013, 4.146927246750695, 4.270743302150588, 4.331324247199061, 4.331324247199061, 4.270743302150588, 4.146927246750695, 3.953939990100014, 3.6809178093609316, 3.30810353703122, 2.7958577794043906, 2.04180583114145, 0.0], [7.198293278059966e-16, 2.766048246082227, 3.7875675488170897, 4.48151036053619, 4.98656439082835, 5.356429395941348, 5.617870545061986, 5.785604997404221, 5.867674415681694, 5.867674415681694, 5.785604997404221, 5.617870545061986, 5.3564293959413485, 4.98656439082835, 4.481510360536191, 3.78756754881709, 2.7660482460822267, 0.0], [8.851684164263618e-16, 3.401387594481843, 4.657541780789848, 5.510877753654521, 6.131938689815697, 6.586758753712339, 6.908250861655702, 7.114512587629632, 7.215432700505725, 7.215432700505725, 7.114512587629632, 6.908250861655702, 6.58675875371234, 6.131938689815697, 5.510877753654521, 4.657541780789848, 3.401387594481842, 0.0], [1.022057463823785e-15, 3.9274035469237782, 5.377818787689879, 6.363121001405076, 7.080227433936408, 7.6053842655358626, 7.976594311428062, 8.214753889448172, 8.331281041457704, 8.331281041457704, 8.214753889448172, 7.976594311428062, 7.605384265535864, 7.080227433936408, 6.3631210014050765, 5.37781878768988, 3.9274035469237774, 0.0], [1.1260967433822294e-15, 4.327189517889181, 5.92524827386952, 7.010848304577073, 7.800951842699867, 8.379566469334046, 8.788563456867465, 9.050966242137834, 9.179355154736356, 9.179355154736356, 9.050966242137834, 8.788563456867465, 8.379566469334048, 7.800951842699867, 7.010848304577074, 5.925248273869521, 4.32718951788918, 0.0], [1.1939423470528821e-15, 4.58789605732623, 6.282235405216475, 7.433241174694762, 8.270947240594394, 8.884422512077574, 9.318060941549046, 9.596273092645356, 9.732397240543204, 9.732397240543204, 9.596273092645356, 9.318060941549046, 8.884422512077576, 8.270947240594394, 7.433241174694763, 6.2822354052164755, 4.587896057326229, 0.0], [1.2234136613102199e-15, 4.701143842547364, 6.437306321599264, 7.6167235573665515, 8.475107588818162, 9.10372590515574, 9.548068280643161, 9.833147830115456, 9.97263207119587, 9.97263207119587, 9.833147830115456, 9.548068280643161, 9.103725905155741, 8.475107588818162, 7.616723557366552, 6.437306321599265, 4.7011438425473635, 0.0], [1.2135634538649336e-15, 4.663292996554989, 6.385476916172569, 7.555398177843563, 8.40687100579556, 9.030428057071573, 9.471192849020657, 9.75397710558466, 9.8923383015713, 9.8923383015713, 9.75397710558466, 9.471192849020657, 9.030428057071575, 8.40687100579556, 7.555398177843564, 6.3854769161725695, 4.663292996554988, 0.0], [1.1647083184890926e-15, 4.475560076683077, 6.128413028672179, 7.251236084282354, 8.068430671450187, 8.666884820972172, 9.089905486307194, 9.361305531281278, 9.494096639491161, 9.494096639491161, 9.361305531281278, 9.089905486307194, 8.666884820972172, 8.068430671450187, 7.251236084282354, 6.12841302867218, 4.4755600766830765, 0.0], [1.0784184994318154e-15, 4.143978973443475, 5.67437690395523, 6.714013296635386, 7.470664336597534, 8.02478077559014, 8.41646108206467, 8.667753894694668, 8.790706899649043, 8.790706899649043, 8.667753894694668, 8.41646108206467, 8.024780775590141, 7.470664336597534, 6.714013296635387, 5.674376903955231, 4.143978973443474, 0.0], [9.57467422477103e-16, 3.6792069763201423, 5.037961636652292, 5.960996597326015, 6.632784703083545, 7.124753673269025, 7.472504693557343, 7.695613516080911, 7.804776607034474, 7.804776607034474, 7.695613516080911, 7.472504693557343, 7.124753673269026, 6.632784703083545, 5.960996597326016, 5.037961636652292, 3.6792069763201414, 0.0], [8.057425547571569e-16, 3.096182239716297, 4.239622137098706, 5.0163885626542495, 5.58172191173902, 5.995731125622196, 6.288375855801743, 6.476129787088423, 6.567994372478235, 6.567994372478235, 6.476129787088423, 6.288375855801743, 5.995731125622197, 5.58172191173902, 5.01638856265425, 4.239622137098707, 3.0961822397162964, 0.0], [6.281204583601337e-16, 2.4136436583807366, 3.305017693686055, 3.910549672080518, 4.351257985495115, 4.6740008462938665, 4.902133443947784, 5.048497918161574, 5.1201113946267744, 5.1201113946267744, 5.048497918161574, 4.902133443947784, 4.674000846293867, 4.351257985495115, 3.9105496720805184, 3.3050176936860556, 2.413643658380736, 0.0], [4.3031005361218095e-16, 1.6535285839122027, 2.2641872622207173, 2.679022497435131, 2.9809410473704014, 3.2020443339849454, 3.358332429716511, 3.458603172227088, 3.5076638237103213, 3.5076638237103213, 3.458603172227088, 3.358332429716511, 3.202044333984946, 2.9809410473704014, 2.679022497435131, 2.2641872622207178, 1.6535285839122023, 0.0], [2.1866912968084137e-16, 0.8402677402288798, 1.150583989168121, 1.3613893354151259, 1.5148142112567402, 1.6271714821308951, 1.7065918479490225, 1.757546074589055, 1.782477051384411, 1.782477051384411, 1.757546074589055, 1.7065918479490225, 1.6271714821308954, 1.5148142112567402, 1.3613893354151259, 1.1505839891681213, 0.8402677402288797, 0.0], [2.9995195653237157e-31, 1.1526087521386858e-15, 1.5782745338105972e-15, 1.867439612331569e-15, 2.077894978192297e-15, 2.23201725086302e-15, 2.3409594419735527e-15, 2.4108541728694004e-15, 2.4450523940766866e-15, 2.4450523940766866e-15, 2.4108541728694004e-15, 2.3409594419735527e-15, 2.2320172508630206e-15, 2.077894978192297e-15, 1.8674396123315694e-15, 1.5782745338105974e-15, 1.1526087521386856e-15, 0.0]], \"z\": [[-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0]]}], {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}}, {\"responsive\": true} ).then(function(){ var gd = document.getElementById('ef403284-6a59-48e2-b0f4-de24074c0eb6'); var x = new MutationObserver(function (mutations, observer) {{ var display = window.getComputedStyle(gd).display; if (!display || display === 'none') {{ console.log([gd, 'removed!']); Plotly.purge(gd); observer.disconnect(); }} }}); // Listen for the removal of the full notebook cells var notebookContainer = gd.closest('#notebook-container'); if (notebookContainer) {{ x.observe(notebookContainer, {childList: true}); }} // Listen for the clearing of the current output cell var outputEl = gd.closest('.output'); if (outputEl) {{ x.observe(outputEl, {childList: true}); }} }) }; });","title":"Ylm"},{"location":"phys304/Ylm/#required-dependencies","text":"import numpy as np import scipy as sp from scipy.special import sph_harm","title":"Required dependencies"},{"location":"phys304/Ylm/#spherical-grid","text":"## first, evaluate the potential on a fine grid # at r=10. R = 10. Np = 36 Nt=18 theta = -np.arccos(np.linspace(-1, 1, Nt)) phi = np.linspace(0, 2*np.pi, Np) theta, phi = np.meshgrid(theta, phi) x = R * np.sin(theta) * np.cos(phi) y = R * np.sin(theta) * np.sin(phi) z = R * np.cos(theta)","title":"Spherical grid"},{"location":"phys304/Ylm/#spherical-harmonics","text":"m = 0 l = 1 Y01 = 1/R**2 * sph_harm(m, l, phi, theta).real","title":"Spherical harmonics"},{"location":"phys304/Ylm/#plotting-static","text":"import matplotlib.pyplot as plt from matplotlib import cm, colors from mpl_toolkits.mplot3d import Axes3D fmax, fmin = Y01.max(), Y01.min() Y01 = (Y01 - fmin)/(fmax - fmin) # Set the aspect ratio to 1 so our sphere looks spherical fig = plt.figure(figsize=plt.figaspect(1.)) ax = fig.add_subplot(111, projection='3d') ax.plot_surface(x, y, z, rstride=1, cstride=1, facecolors=cm.seismic(Y01)) # Turn off the axis planes ax.set_axis_off() plt.show()","title":"Plotting (static)"},{"location":"phys304/Ylm/#plotting-interactive","text":"import plotly.graph_objects as go import chart_studio.plotly as py fig = go.Figure() fig.add_trace(go.Surface(x=x, y=y, z=z, surfacecolor=Y01, showscale=False, colorscale='PrGN')) fig.show() require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {}; if (document.getElementById(\"ef403284-6a59-48e2-b0f4-de24074c0eb6\")) { Plotly.newPlot( 'ef403284-6a59-48e2-b0f4-de24074c0eb6', [{\"colorscale\": [[0.0, \"rgb(64,0,75)\"], [0.1, \"rgb(118,42,131)\"], [0.2, \"rgb(153,112,171)\"], [0.3, \"rgb(194,165,207)\"], [0.4, \"rgb(231,212,232)\"], [0.5, \"rgb(247,247,247)\"], [0.6, \"rgb(217,240,211)\"], [0.7, \"rgb(166,219,160)\"], [0.8, \"rgb(90,174,97)\"], [0.9, \"rgb(27,120,55)\"], [1.0, \"rgb(0,68,27)\"]], \"showscale\": false, \"surfacecolor\": [[0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0], [0.0, 0.05882352941176477, 0.11764705882352945, 0.17647058823529407, 0.23529411764705882, 0.2941176470588235, 0.35294117647058815, 0.4117647058823529, 0.47058823529411764, 0.5294117647058824, 0.5882352941176472, 0.6470588235294119, 0.7058823529411764, 0.7647058823529411, 0.8235294117647058, 0.8823529411764707, 0.9411764705882353, 1.0]], \"type\": \"surface\", \"x\": [[-1.2246467991473533e-15, -4.705882352941178, -6.443794794178425, -7.624400821656306, -8.483650059915268, -9.112901991076274, -9.557692240748189, -9.843059135695006, -9.982683969692435, -9.982683969692435, -9.843059135695006, -9.557692240748189, -9.112901991076276, -8.483650059915268, -7.624400821656307, -6.443794794178426, -4.7058823529411775, -0.0], [-1.204966221263684e-15, -4.630256887522965, -6.340240360849969, -7.501873563763343, -8.34731431326717, -8.966453907019313, -9.40409619439168, -9.68487712593637, -9.822258131409612, -9.822258131409612, -9.68487712593637, -9.40409619439168, -8.966453907019314, -8.34731431326717, -7.501873563763344, -6.34024036084997, -4.630256887522965, -0.0], [-1.1465570375790906e-15, -4.405811155951707, -6.032905385556649, -7.138229916968898, -7.94268901639757, -8.5318166167679, -8.9482447586313, -9.215415196606697, -9.346136835002374, -9.346136835002374, -9.215415196606697, -8.9482447586313, -8.531816616767902, -7.94268901639757, -7.138229916968899, -6.03290538555665, -4.405811155951706, -0.0], [-1.0512965673164322e-15, -4.039759028714665, -5.531667867280454, -6.545157687287933, -7.282779159274661, -7.822959720451471, -8.204789373688198, -8.449762240389205, -8.569623010691158, -8.569623010691158, -8.449762240389205, -8.204789373688198, -7.822959720451473, -7.282779159274661, -6.545157687287934, -5.531667867280454, -4.0397590287146645, -0.0], [-9.22246560370527e-16, -3.5438657223699352, -4.852637992278383, -5.74171870416385, -6.388794787682013, -6.862666461967035, -7.197625307351576, -7.412526973278074, -7.517674451707029, -7.517674451707029, -7.412526973278074, -7.197625307351576, -6.862666461967036, -6.388794787682013, -5.741718704163851, -4.8526379922783835, -3.543865722369935, -0.0], [-7.635547901473156e-16, -2.934069655805806, -4.0176403394406455, -4.753736157586056, -5.289469294895404, -5.681801456774205, -5.9591236414108435, -6.137046990198277, -6.224101650281892, -6.224101650281892, -6.137046990198277, -5.9591236414108435, -5.681801456774206, -5.289469294895404, -4.753736157586056, -4.0176403394406455, -2.9340696558058057, -0.0], [-5.803217407137954e-16, -2.229970176343524, -3.053512420367802, -3.612964619516306, -4.020135906781023, -4.318318677758841, -4.529090838451902, -4.664317267274423, -4.730481100608799, -4.730481100608799, -4.664317267274423, -4.529090838451902, -4.318318677758842, -4.020135906781023, -3.6129646195163065, -3.0535124203678023, -2.2299701763435236, -0.0], [-3.7843667304341507e-16, -1.4541976205879885, -1.99124209966595, -2.3560694258181116, -2.621592042843859, -2.8160415833158643, -2.953489329396762, -3.041672549567339, -3.084818996109325, -3.084818996109325, -3.041672549567339, -2.953489329396762, -2.816041583315865, -2.621592042843859, -2.3560694258181116, -1.9912420996659503, -1.4541976205879883, -0.0], [-1.6438833932268765e-16, -0.6316859567889674, -0.8649716194813774, -1.023448222193742, -1.1387880535965753, -1.2232545953383838, -1.2829602431556952, -1.3212659734206502, -1.340008270877373, -1.340008270877373, -1.3212659734206502, -1.2829602431556952, -1.223254595338384, -1.1387880535965753, -1.0234482221937422, -0.8649716194813775, -0.6316859567889673, -0.0], [5.4943570883047055e-17, 0.21112861341418768, 0.28909976025434586, 0.3420674493879363, 0.3806175206912337, 0.40884880183050615, 0.42880424092359976, 0.44160717825304185, 0.4478714227430553, 0.4478714227430553, 0.44160717825304185, 0.42880424092359976, 0.4088488018305062, 0.3806175206912337, 0.3420674493879363, 0.2890997602543459, 0.21112861341418762, 0.0], [2.7250954951287997e-16, 1.047157336265009, 1.4338792358234194, 1.6965887916922517, 1.8877897346908876, 2.027811462106649, 2.1267866038783056, 2.190286711862085, 2.221356160326688, 2.221356160326688, 2.190286711862085, 2.1267866038783056, 2.0278114621066496, 1.8877897346908876, 1.696588791692252, 1.4338792358234196, 1.0471573362650088, 0.0], [4.813168469997646e-16, 1.849529560724347, 2.5325726529533634, 2.9965803742736705, 3.3342868333390085, 3.5815985935018557, 3.7564122954585164, 3.868568628377971, 3.9234446831794845, 3.9234446831794845, 3.868568628377971, 3.7564122954585164, 3.581598593501856, 3.3342868333390085, 2.996580374273671, 2.5325726529533634, 1.8495295607243465, 0.0], [6.74654224995256e-16, 2.5924563833040124, 3.549867101209666, 4.200259398031388, 4.673617209703269, 5.020270199152773, 5.265303805076358, 5.422511566108919, 5.4994304656938535, 5.4994304656938535, 5.422511566108919, 5.265303805076358, 5.020270199152774, 4.673617209703269, 4.200259398031389, 3.5498671012096663, 2.592456383304012, 0.0], [8.463076610920545e-16, 3.2520595246440696, 4.45306589999271, 5.2689386287514335, 5.862733683482618, 6.2975861899108425, 6.604964118092644, 6.802170520447748, 6.898660028094362, 6.898660028094362, 6.802170520447748, 6.604964118092644, 6.297586189910843, 5.862733683482618, 5.268938628751434, 4.45306589999271, 3.252059524644069, 0.0], [9.907600726170915e-16, 3.8071387970585775, 5.213139496755161, 6.168269836646264, 6.863417072801492, 7.3724925788540006, 7.732335449770855, 7.96320211741484, 8.07616098095554, 8.07616098095554, 7.96320211741484, 7.732335449770855, 7.372492578854002, 6.863417072801492, 6.168269836646265, 5.213139496755162, 3.8071387970585766, 0.0], [1.103368640208112e-15, 4.239853496011386, 5.8056585007064365, 6.8693477767219555, 7.643504590162149, 8.210440990205692, 8.61118315790663, 8.868289846183693, 8.99408747480142, 8.99408747480142, 8.868289846183693, 8.61118315790663, 8.210440990205694, 7.643504590162149, 6.869347776721956, 5.805658500706437, 4.239853496011385, 0.0], [1.1805140318481027e-15, 4.536295815039312, 6.211578863533282, 7.349639227135627, 8.177923580898469, 8.784499072558821, 9.213260354042184, 9.48834344244301, 9.622936596847355, 9.622936596847355, 9.48834344244301, 9.213260354042184, 8.784499072558823, 8.177923580898469, 7.3496392271356275, 6.2115788635332825, 4.536295815039311, 0.0], [1.2197167311743145e-15, 4.686937854095245, 6.417853970782054, 7.59370722548586, 8.449497378926777, 9.076216126810001, 9.519215781702952, 9.803433873427222, 9.942496618892013, 9.942496618892013, 9.803433873427222, 9.519215781702952, 9.076216126810003, 8.449497378926777, 7.593707225485861, 6.417853970782055, 4.686937854095244, 0.0], [1.2197167311743145e-15, 4.686937854095245, 6.417853970782054, 7.59370722548586, 8.449497378926777, 9.076216126810001, 9.519215781702952, 9.803433873427222, 9.942496618892013, 9.942496618892013, 9.803433873427222, 9.519215781702952, 9.076216126810003, 8.449497378926777, 7.593707225485861, 6.417853970782055, 4.686937854095244, 0.0], [1.1805140318481027e-15, 4.536295815039312, 6.211578863533282, 7.3496392271356275, 8.17792358089847, 8.784499072558823, 9.213260354042184, 9.48834344244301, 9.622936596847357, 9.622936596847357, 9.48834344244301, 9.213260354042184, 8.784499072558825, 8.17792358089847, 7.349639227135628, 6.2115788635332825, 4.536295815039311, 0.0], [1.1033686402081122e-15, 4.239853496011386, 5.805658500706437, 6.869347776721956, 7.6435045901621494, 8.210440990205692, 8.611183157906632, 8.868289846183693, 8.99408747480142, 8.99408747480142, 8.868289846183693, 8.611183157906632, 8.210440990205694, 7.6435045901621494, 6.869347776721957, 5.805658500706438, 4.239853496011385, 0.0], [9.907600726170917e-16, 3.807138797058578, 5.213139496755162, 6.168269836646265, 6.863417072801493, 7.372492578854001, 7.732335449770856, 7.963202117414841, 8.076160980955542, 8.076160980955542, 7.963202117414841, 7.732335449770856, 7.372492578854003, 6.863417072801493, 6.168269836646266, 5.213139496755163, 3.807138797058577, 0.0], [8.463076610920548e-16, 3.252059524644071, 4.453065899992711, 5.268938628751435, 5.862733683482619, 6.297586189910844, 6.604964118092647, 6.80217052044775, 6.898660028094365, 6.898660028094365, 6.80217052044775, 6.604964118092647, 6.297586189910845, 5.862733683482619, 5.268938628751436, 4.453065899992712, 3.25205952464407, 0.0], [6.746542249952563e-16, 2.5924563833040133, 3.549867101209667, 4.20025939803139, 4.673617209703271, 5.020270199152775, 5.2653038050763605, 5.422511566108921, 5.499430465693855, 5.499430465693855, 5.422511566108921, 5.2653038050763605, 5.020270199152776, 4.673617209703271, 4.200259398031391, 3.5498671012096676, 2.592456383304013, 0.0], [4.813168469997649e-16, 1.8495295607243478, 2.5325726529533648, 2.9965803742736723, 3.3342868333390108, 3.5815985935018575, 3.7564122954585186, 3.868568628377973, 3.9234446831794867, 3.9234446831794867, 3.868568628377973, 3.7564122954585186, 3.5815985935018584, 3.3342868333390108, 2.9965803742736723, 2.532572652953365, 1.8495295607243476, 0.0], [2.7250954951288026e-16, 1.0471573362650102, 1.433879235823421, 1.6965887916922535, 1.8877897346908896, 2.0278114621066514, 2.1267866038783083, 2.1902867118620875, 2.2213561603266907, 2.2213561603266907, 2.1902867118620875, 2.1267866038783083, 2.027811462106652, 1.8877897346908896, 1.6965887916922537, 1.4338792358234211, 1.04715733626501, 0.0], [5.494357088304735e-17, 0.21112861341418881, 0.2890997602543474, 0.34206744938793815, 0.38061752069123583, 0.40884880183050837, 0.42880424092360203, 0.44160717825304424, 0.44787142274305775, 0.44787142274305775, 0.44160717825304424, 0.42880424092360203, 0.4088488018305084, 0.38061752069123583, 0.3420674493879382, 0.28909976025434747, 0.2111286134141888, 0.0], [-1.6438833932268735e-16, -0.6316859567889662, -0.8649716194813757, -1.0234482221937402, -1.1387880535965733, -1.2232545953383815, -1.2829602431556928, -1.3212659734206478, -1.3400082708773706, -1.3400082708773706, -1.3212659734206478, -1.2829602431556928, -1.2232545953383818, -1.1387880535965733, -1.0234482221937402, -0.8649716194813758, -0.6316859567889661, -0.0], [-3.7843667304341477e-16, -1.4541976205879876, -1.9912420996659486, -2.35606942581811, -2.621592042843857, -2.8160415833158625, -2.95348932939676, -3.0416725495673367, -3.084818996109323, -3.084818996109323, -3.0416725495673367, -2.95348932939676, -2.816041583315863, -2.621592042843857, -2.35606942581811, -1.9912420996659488, -1.4541976205879872, -0.0], [-5.803217407137952e-16, -2.2299701763435236, -3.053512420367801, -3.6129646195163048, -4.020135906781022, -4.318318677758839, -4.529090838451901, -4.664317267274421, -4.730481100608797, -4.730481100608797, -4.664317267274421, -4.529090838451901, -4.31831867775884, -4.020135906781022, -3.612964619516305, -3.0535124203678015, -2.229970176343523, -0.0], [-7.635547901473153e-16, -2.9340696558058053, -4.017640339440644, -4.753736157586054, -5.289469294895402, -5.6818014567742035, -5.959123641410842, -6.137046990198274, -6.22410165028189, -6.22410165028189, -6.137046990198274, -5.959123641410842, -5.681801456774204, -5.289469294895402, -4.753736157586054, -4.017640339440645, -2.934069655805805, -0.0], [-9.22246560370527e-16, -3.543865722369935, -4.852637992278383, -5.7417187041638496, -6.388794787682012, -6.862666461967034, -7.197625307351575, -7.412526973278073, -7.517674451707027, -7.517674451707027, -7.412526973278073, -7.197625307351575, -6.862666461967035, -6.388794787682012, -5.74171870416385, -4.852637992278383, -3.5438657223699344, -0.0], [-1.051296567316432e-15, -4.039759028714665, -5.531667867280453, -6.545157687287932, -7.28277915927466, -7.82295972045147, -8.204789373688198, -8.449762240389203, -8.569623010691156, -8.569623010691156, -8.449762240389203, -8.204789373688198, -7.822959720451472, -7.28277915927466, -6.545157687287933, -5.531667867280454, -4.0397590287146645, -0.0], [-1.1465570375790904e-15, -4.405811155951706, -6.032905385556649, -7.138229916968897, -7.942689016397569, -8.531816616767898, -8.948244758631299, -9.215415196606696, -9.346136835002374, -9.346136835002374, -9.215415196606696, -8.948244758631299, -8.5318166167679, -7.942689016397569, -7.138229916968898, -6.03290538555665, -4.405811155951705, -0.0], [-1.204966221263684e-15, -4.630256887522965, -6.340240360849969, -7.501873563763343, -8.34731431326717, -8.966453907019313, -9.40409619439168, -9.68487712593637, -9.822258131409612, -9.822258131409612, -9.68487712593637, -9.40409619439168, -8.966453907019314, -8.34731431326717, -7.501873563763344, -6.34024036084997, -4.630256887522965, -0.0], [-1.2246467991473533e-15, -4.705882352941178, -6.443794794178425, -7.624400821656306, -8.483650059915268, -9.112901991076274, -9.557692240748189, -9.843059135695006, -9.982683969692435, -9.982683969692435, -9.843059135695006, -9.557692240748189, -9.112901991076276, -8.483650059915268, -7.624400821656307, -6.443794794178426, -4.7058823529411775, -0.0]], \"y\": [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0], [-2.1866912968084107e-16, -0.8402677402288787, -1.1505839891681195, -1.3613893354151239, -1.514814211256738, -1.6271714821308927, -1.70659184794902, -1.7575460745890525, -1.7824770513844086, -1.7824770513844086, -1.7575460745890525, -1.70659184794902, -1.6271714821308931, -1.514814211256738, -1.361389335415124, -1.1505839891681198, -0.8402677402288785, -0.0], [-4.3031005361218065e-16, -1.6535285839122016, -2.264187262220716, -2.6790224974351293, -2.9809410473703997, -3.202044333984943, -3.358332429716509, -3.4586031722270856, -3.507663823710319, -3.507663823710319, -3.4586031722270856, -3.358332429716509, -3.202044333984944, -2.9809410473703997, -2.6790224974351293, -2.264187262220716, -1.6535285839122011, -0.0], [-6.281204583601334e-16, -2.4136436583807357, -3.305017693686054, -3.910549672080516, -4.3512579854951134, -4.674000846293865, -4.902133443947782, -5.048497918161571, -5.120111394626772, -5.120111394626772, -5.048497918161571, -4.902133443947782, -4.674000846293866, -4.3512579854951134, -3.910549672080517, -3.3050176936860542, -2.4136436583807352, -0.0], [-8.0574255475715675e-16, -3.096182239716296, -4.2396221370987055, -5.016388562654248, -5.5817219117390175, -5.995731125622194, -6.28837585580174, -6.4761297870884205, -6.567994372478233, -6.567994372478233, -6.4761297870884205, -6.28837585580174, -5.9957311256221955, -5.5817219117390175, -5.016388562654249, -4.2396221370987055, -3.096182239716295, -0.0], [-9.574674224771025e-16, -3.6792069763201414, -5.03796163665229, -5.960996597326013, -6.632784703083543, -7.124753673269023, -7.472504693557341, -7.695613516080909, -7.804776607034472, -7.804776607034472, -7.695613516080909, -7.472504693557341, -7.124753673269025, -6.632784703083543, -5.960996597326014, -5.037961636652291, -3.6792069763201405, -0.0], [-1.0784184994318154e-15, -4.143978973443475, -5.674376903955229, -6.714013296635385, -7.470664336597533, -8.024780775590138, -8.41646108206467, -8.667753894694668, -8.790706899649042, -8.790706899649042, -8.667753894694668, -8.41646108206467, -8.02478077559014, -7.470664336597533, -6.714013296635386, -5.67437690395523, -4.143978973443474, -0.0], [-1.1647083184890924e-15, -4.475560076683077, -6.1284130286721785, -7.251236084282353, -8.068430671450185, -8.66688482097217, -9.089905486307192, -9.361305531281277, -9.494096639491161, -9.494096639491161, -9.361305531281277, -9.089905486307192, -8.666884820972172, -8.068430671450185, -7.251236084282354, -6.128413028672179, -4.4755600766830765, -0.0], [-1.2135634538649334e-15, -4.663292996554989, -6.385476916172568, -7.555398177843562, -8.40687100579556, -9.030428057071571, -9.471192849020655, -9.753977105584658, -9.892338301571298, -9.892338301571298, -9.753977105584658, -9.471192849020655, -9.030428057071573, -8.40687100579556, -7.555398177843563, -6.385476916172569, -4.663292996554988, -0.0], [-1.2234136613102199e-15, -4.701143842547365, -6.437306321599264, -7.616723557366552, -8.475107588818162, -9.10372590515574, -9.548068280643163, -9.833147830115456, -9.97263207119587, -9.97263207119587, -9.833147830115456, -9.548068280643163, -9.103725905155741, -8.475107588818162, -7.616723557366553, -6.437306321599265, -4.701143842547364, -0.0], [-1.1939423470528821e-15, -4.587896057326231, -6.2822354052164755, -7.433241174694763, -8.270947240594396, -8.884422512077576, -9.318060941549048, -9.596273092645356, -9.732397240543204, -9.732397240543204, -9.596273092645356, -9.318060941549048, -8.884422512077577, -8.270947240594396, -7.433241174694764, -6.282235405216476, -4.58789605732623, -0.0], [-1.1260967433822296e-15, -4.327189517889181, -5.925248273869521, -7.010848304577074, -7.800951842699868, -8.379566469334046, -8.788563456867466, -9.050966242137836, -9.179355154736358, -9.179355154736358, -9.050966242137836, -8.788563456867466, -8.379566469334048, -7.800951842699868, -7.010848304577075, -5.925248273869522, -4.327189517889181, -0.0], [-1.0220574638237853e-15, -3.927403546923779, -5.37781878768988, -6.363121001405077, -7.08022743393641, -7.605384265535864, -7.976594311428065, -8.214753889448176, -8.331281041457705, -8.331281041457705, -8.214753889448176, -7.976594311428065, -7.605384265535866, -7.08022743393641, -6.363121001405078, -5.377818787689881, -3.9274035469237787, -0.0], [-8.851684164263621e-16, -3.401387594481844, -4.657541780789849, -5.510877753654522, -6.131938689815699, -6.586758753712341, -6.908250861655704, -7.114512587629634, -7.215432700505728, -7.215432700505728, -7.114512587629634, -6.908250861655704, -6.586758753712342, -6.131938689815699, -5.510877753654523, -4.65754178078985, -3.4013875944818435, -0.0], [-7.198293278059968e-16, -2.766048246082228, -3.787567548817091, -4.481510360536192, -4.9865643908283515, -5.356429395941349, -5.617870545061988, -5.7856049974042225, -5.867674415681696, -5.867674415681696, -5.7856049974042225, -5.617870545061988, -5.356429395941351, -4.9865643908283515, -4.481510360536193, -3.787567548817092, -2.7660482460822275, -0.0], [-5.313543323124029e-16, -2.0418058311414513, -2.7958577794043915, -3.3081035370312213, -3.6809178093609334, -3.953939990100015, -4.146927246750698, -4.27074330215059, -4.3313242471990625, -4.3313242471990625, -4.27074330215059, -4.146927246750698, -3.953939990100016, -3.6809178093609334, -3.3081035370312217, -2.795857779404392, -2.041805831141451, -0.0], [-3.2580117137848757e-16, -1.2519380967843545, -1.7142868405221914, -2.0283715439294103, -2.256963500831393, -2.424367699664206, -2.542698294625736, -2.618616403186544, -2.6557617535859905, -2.6557617535859905, -2.618616403186544, -2.542698294625736, -2.4243676996642063, -2.256963500831393, -2.0283715439294108, -1.7142868405221916, -1.2519380967843543, -0.0], [-1.0977649272637083e-16, -0.4218320418985113, -0.5776173120656973, -0.6834460204560427, -0.7604685283493778, -0.8168742365848014, -0.8567449271723776, -0.882325018419329, -0.8948408920446151, -0.8948408920446151, -0.882325018419329, -0.8567449271723776, -0.8168742365848016, -0.7604685283493778, -0.6834460204560429, -0.5776173120656973, -0.42183204189851126, -0.0], [1.0977649272637052e-16, 0.42183204189851015, 0.5776173120656957, 0.6834460204560409, 0.7604685283493757, 0.8168742365847992, 0.8567449271723752, 0.8823250184193265, 0.8948408920446126, 0.8948408920446126, 0.8823250184193265, 0.8567449271723752, 0.8168742365847993, 0.7604685283493757, 0.6834460204560409, 0.5776173120656958, 0.4218320418985101, 0.0], [3.2580117137848727e-16, 1.2519380967843534, 1.71428684052219, 2.0283715439294085, 2.2569635008313913, 2.424367699664204, 2.5426982946257337, 2.6186164031865418, 2.6557617535859883, 2.6557617535859883, 2.6186164031865418, 2.5426982946257337, 2.4243676996642045, 2.2569635008313913, 2.028371543929409, 1.7142868405221903, 1.2519380967843532, 0.0], [5.313543323124027e-16, 2.0418058311414504, 2.79585777940439, 3.3081035370312195, 3.6809178093609316, 3.953939990100013, 4.146927246750695, 4.270743302150588, 4.331324247199061, 4.331324247199061, 4.270743302150588, 4.146927246750695, 3.953939990100014, 3.6809178093609316, 3.30810353703122, 2.7958577794043906, 2.04180583114145, 0.0], [7.198293278059966e-16, 2.766048246082227, 3.7875675488170897, 4.48151036053619, 4.98656439082835, 5.356429395941348, 5.617870545061986, 5.785604997404221, 5.867674415681694, 5.867674415681694, 5.785604997404221, 5.617870545061986, 5.3564293959413485, 4.98656439082835, 4.481510360536191, 3.78756754881709, 2.7660482460822267, 0.0], [8.851684164263618e-16, 3.401387594481843, 4.657541780789848, 5.510877753654521, 6.131938689815697, 6.586758753712339, 6.908250861655702, 7.114512587629632, 7.215432700505725, 7.215432700505725, 7.114512587629632, 6.908250861655702, 6.58675875371234, 6.131938689815697, 5.510877753654521, 4.657541780789848, 3.401387594481842, 0.0], [1.022057463823785e-15, 3.9274035469237782, 5.377818787689879, 6.363121001405076, 7.080227433936408, 7.6053842655358626, 7.976594311428062, 8.214753889448172, 8.331281041457704, 8.331281041457704, 8.214753889448172, 7.976594311428062, 7.605384265535864, 7.080227433936408, 6.3631210014050765, 5.37781878768988, 3.9274035469237774, 0.0], [1.1260967433822294e-15, 4.327189517889181, 5.92524827386952, 7.010848304577073, 7.800951842699867, 8.379566469334046, 8.788563456867465, 9.050966242137834, 9.179355154736356, 9.179355154736356, 9.050966242137834, 8.788563456867465, 8.379566469334048, 7.800951842699867, 7.010848304577074, 5.925248273869521, 4.32718951788918, 0.0], [1.1939423470528821e-15, 4.58789605732623, 6.282235405216475, 7.433241174694762, 8.270947240594394, 8.884422512077574, 9.318060941549046, 9.596273092645356, 9.732397240543204, 9.732397240543204, 9.596273092645356, 9.318060941549046, 8.884422512077576, 8.270947240594394, 7.433241174694763, 6.2822354052164755, 4.587896057326229, 0.0], [1.2234136613102199e-15, 4.701143842547364, 6.437306321599264, 7.6167235573665515, 8.475107588818162, 9.10372590515574, 9.548068280643161, 9.833147830115456, 9.97263207119587, 9.97263207119587, 9.833147830115456, 9.548068280643161, 9.103725905155741, 8.475107588818162, 7.616723557366552, 6.437306321599265, 4.7011438425473635, 0.0], [1.2135634538649336e-15, 4.663292996554989, 6.385476916172569, 7.555398177843563, 8.40687100579556, 9.030428057071573, 9.471192849020657, 9.75397710558466, 9.8923383015713, 9.8923383015713, 9.75397710558466, 9.471192849020657, 9.030428057071575, 8.40687100579556, 7.555398177843564, 6.3854769161725695, 4.663292996554988, 0.0], [1.1647083184890926e-15, 4.475560076683077, 6.128413028672179, 7.251236084282354, 8.068430671450187, 8.666884820972172, 9.089905486307194, 9.361305531281278, 9.494096639491161, 9.494096639491161, 9.361305531281278, 9.089905486307194, 8.666884820972172, 8.068430671450187, 7.251236084282354, 6.12841302867218, 4.4755600766830765, 0.0], [1.0784184994318154e-15, 4.143978973443475, 5.67437690395523, 6.714013296635386, 7.470664336597534, 8.02478077559014, 8.41646108206467, 8.667753894694668, 8.790706899649043, 8.790706899649043, 8.667753894694668, 8.41646108206467, 8.024780775590141, 7.470664336597534, 6.714013296635387, 5.674376903955231, 4.143978973443474, 0.0], [9.57467422477103e-16, 3.6792069763201423, 5.037961636652292, 5.960996597326015, 6.632784703083545, 7.124753673269025, 7.472504693557343, 7.695613516080911, 7.804776607034474, 7.804776607034474, 7.695613516080911, 7.472504693557343, 7.124753673269026, 6.632784703083545, 5.960996597326016, 5.037961636652292, 3.6792069763201414, 0.0], [8.057425547571569e-16, 3.096182239716297, 4.239622137098706, 5.0163885626542495, 5.58172191173902, 5.995731125622196, 6.288375855801743, 6.476129787088423, 6.567994372478235, 6.567994372478235, 6.476129787088423, 6.288375855801743, 5.995731125622197, 5.58172191173902, 5.01638856265425, 4.239622137098707, 3.0961822397162964, 0.0], [6.281204583601337e-16, 2.4136436583807366, 3.305017693686055, 3.910549672080518, 4.351257985495115, 4.6740008462938665, 4.902133443947784, 5.048497918161574, 5.1201113946267744, 5.1201113946267744, 5.048497918161574, 4.902133443947784, 4.674000846293867, 4.351257985495115, 3.9105496720805184, 3.3050176936860556, 2.413643658380736, 0.0], [4.3031005361218095e-16, 1.6535285839122027, 2.2641872622207173, 2.679022497435131, 2.9809410473704014, 3.2020443339849454, 3.358332429716511, 3.458603172227088, 3.5076638237103213, 3.5076638237103213, 3.458603172227088, 3.358332429716511, 3.202044333984946, 2.9809410473704014, 2.679022497435131, 2.2641872622207178, 1.6535285839122023, 0.0], [2.1866912968084137e-16, 0.8402677402288798, 1.150583989168121, 1.3613893354151259, 1.5148142112567402, 1.6271714821308951, 1.7065918479490225, 1.757546074589055, 1.782477051384411, 1.782477051384411, 1.757546074589055, 1.7065918479490225, 1.6271714821308954, 1.5148142112567402, 1.3613893354151259, 1.1505839891681213, 0.8402677402288797, 0.0], [2.9995195653237157e-31, 1.1526087521386858e-15, 1.5782745338105972e-15, 1.867439612331569e-15, 2.077894978192297e-15, 2.23201725086302e-15, 2.3409594419735527e-15, 2.4108541728694004e-15, 2.4450523940766866e-15, 2.4450523940766866e-15, 2.4108541728694004e-15, 2.3409594419735527e-15, 2.2320172508630206e-15, 2.077894978192297e-15, 1.8674396123315694e-15, 1.5782745338105974e-15, 1.1526087521386856e-15, 0.0]], \"z\": [[-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0], [-10.0, -8.823529411764705, -7.647058823529411, -6.470588235294118, -5.294117647058823, -4.11764705882353, -2.941176470588236, -1.7647058823529418, -0.588235294117647, 0.5882352941176482, 1.764705882352943, 2.9411764705882373, 4.117647058823529, 5.294117647058823, 6.470588235294117, 7.647058823529411, 8.823529411764707, 10.0]]}], {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}}, {\"responsive\": true} ).then(function(){ var gd = document.getElementById('ef403284-6a59-48e2-b0f4-de24074c0eb6'); var x = new MutationObserver(function (mutations, observer) {{ var display = window.getComputedStyle(gd).display; if (!display || display === 'none') {{ console.log([gd, 'removed!']); Plotly.purge(gd); observer.disconnect(); }} }}); // Listen for the removal of the full notebook cells var notebookContainer = gd.closest('#notebook-container'); if (notebookContainer) {{ x.observe(notebookContainer, {childList: true}); }} // Listen for the clearing of the current output cell var outputEl = gd.closest('.output'); if (outputEl) {{ x.observe(outputEl, {childList: true}); }} }) }; });","title":"Plotting (interactive)"},{"location":"problems/problems/","text":"Problems Optimization Newton's Method Write a function called newton which takes input parameters f f , x_0 x_0 , h h (with default value 0.001), tolerance (with default value 0.001) and max_iter (with default value 100). The function implements Newton's method to approximate a solution of f(x) = 0 f(x) = 0 . In other words, compute the values of the recursive sequence starting at x_0 x_0 and defined by x_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)} x_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)} Use the central difference formula with step size h h to approximate the derivative f'(x_n) f'(x_n) . The desired result is that the method converges to an approximate root of f(x) f(x) however there are several possibilities: The sequence reaches the desired tolerance |f(x_n)| \\leq \\mathtt{tolerance} |f(x_n)| \\leq \\mathtt{tolerance} and newton returns the value x_n x_n . The number of iterations exceeds the maximum number of iterations max_iter , the function prints the statement \"Maximum iterations exceeded\" and returns None . A zero derivative is computed f'(x_n) = 0 f'(x_n) = 0 , the function prints the statement \"Zero derivative\" and returns None . Numerical Differentiation Central Difference Formula Write a function called derivatives which takes input parameters f f , a a , n n and h h (with default value h = 0.001 ) and returns approximations of the derivatives f'(a) f'(a) , f''(a) f''(a) , \\dots \\dots , f^{(n)}(a) f^{(n)}(a) (as a NumPy array) using the formula f^{(n)}(a) \\approx \\frac{1}{2^n h^n} \\sum_{k=0}^n (-1)^k {n \\choose k} f \\left( a + ( n - 2k ) h \\right) f^{(n)}(a) \\approx \\frac{1}{2^n h^n} \\sum_{k=0}^n (-1)^k {n \\choose k} f \\left( a + ( n - 2k ) h \\right) Use either scipy.misc.factorial or scipy.misc.comb to compute n n choose k k : {n \\choose k} = \\frac{n!}{k!(n-k)!} {n \\choose k} = \\frac{n!}{k!(n-k)!} Taylor Polynomials Write a function called taylor which takes input parameters f f , a a , n n and L L and plots both f(x) f(x) and the Taylor polynomial T_n(x) T_n(x) of f(x) f(x) at x=a x=a of degree n n T_n(x) = \\sum_{k=0}^n \\frac{f^{(k)}(a)}{k!}(x - a)^k T_n(x) = \\sum_{k=0}^n \\frac{f^{(k)}(a)}{k!}(x - a)^k on the interval [a-L,a+L] [a-L,a+L] (in the same figure). Numerical Integration Trapezoid Rule Find f''(x) f''(x) for f(x) = \\ln( \\ln x) f(x) = \\ln( \\ln x) . Prove |f''(x)| \\leq \\displaystyle \\frac{2}{e^2} |f''(x)| \\leq \\displaystyle \\frac{2}{e^2} for x \\geq e x \\geq e . Write a function called log_log which takes input parameters u and abs_tolerance such that u \\geq e u \\geq e and abs_tolerance is a positive number (with default value 0.0001). The function uses the trapezoid rule to compute and return an approximation of the integral $$ \\int_e^u \\ln( \\ln x) dx $$ The number N N of subintervals used in the trapezoid rule must be large enough to guarantee that the approximation is within abs_tolerance of the true value. You may use the function scipy.integrate.trapz . Simpson's Rule Find f''''(x) f''''(x) for f(x) = e^{-x^2} f(x) = e^{-x^2} . Plot f''''(x) f''''(x) for x \\in [0,5] x \\in [0,5] . Determine a bound M M such that |f''''(x)| \\leq M |f''''(x)| \\leq M for x \\geq 0 x \\geq 0 . Write a function called erf which takes input parameters u and abs_tolerance (with default value 0.0001) such that both are positive numbers. The function uses Simpson's rule to compute and return an approximation of the integral $$ \\int_0^u e^{-x^2} dx $$ The number N N of subintervals used in Simpson's rule must be large enough to guarantee that the approximation is within abs_tolerance of the true value. You may use the function scipy.integrate.simps . Differential Equations Lorenz Equations The Lorenz equations are the system of nonlinear differential equations \\begin{align} \\frac{dx}{dt} &= \\sigma(y - x) \\\\\\ \\frac{dy}{dt} &= x(\\rho - z) - y \\\\\\ \\frac{dz}{dt} &= xy - \\beta z \\end{align} \\begin{align} \\frac{dx}{dt} &= \\sigma(y - x) \\\\\\ \\frac{dy}{dt} &= x(\\rho - z) - y \\\\\\ \\frac{dz}{dt} &= xy - \\beta z \\end{align} where \\sigma \\sigma , \\rho \\rho and \\beta \\beta are positive numbers. Write a function called lorenz which takes input parameters sigma , rho , beta , u0 , t0 , tf , N and plot_vars (with default value [0,1] ). The function computes and plots a numerical approximation of the corresponding solution of the Lorenz equations using the function scipy.integrate.odeint . The input parameters are: sigma , rho and beta define the parameters \\sigma \\sigma , \\rho \\rho and \\beta \\beta u0 is a list of numbers of length 3 defining the initial conditions [x(t_0),y(t_0),z(t_0)] [x(t_0),y(t_0),z(t_0)] t0 is the start of the interval of integration [t_0,t_f] [t_0,t_f] tf is the end of the interval of integration [t_0,t_f] [t_0,t_f] N is an integer specifying the number of evenly spaced points from t_0 t_0 to t_f t_f (inclusively) over which to compute the solution of the system plot_vars is a list of length 2 specifying which 2 components to plot where x=0 x=0 , y=1 y=1 and z=2 z=2 . For example, if plot_vars is [0,1] [0,1] then plot the solution x x versus y y . If plot_vars is [1,2] [1,2] then plot the solution y y versus z z . Note x x versus y y means x x is the horizontal axis and y y is the vertical. Default value is [0,1] which plots x x versus y y . The function lorenz returns a 2D NumPy array with 4 columns: column at index 0 is the array of N N evenly spaced t t values from t_0 t_0 to t_f t_f (inclusively) column at index 1 is the array of x x values of the solution column at index 2 is the array of y y values of the solution column at index 3 is the array of z z values of the solution Damped Oscillator Write a function called damping which takes input parameters m , b , k , F , u0 , t0 , tf and N . The function uses scipy.integrate.odeint to compute a numerical approximation of the corresponding solution of the nonlinear damping equation: m y'' + b |y'| y' + ky = F(t) m y'' + b |y'| y' + ky = F(t) The input parameters are: m , b and k are positive numbers in the nonlinear damping equation F is a function of one variable F(t) F(t) in the nonlinear damping equation u0 is a list of numbers of length 2 defining the initial conditions [y(t_0),y'(t_0)] [y(t_0),y'(t_0)] t0 is the start of the interval of integration [t_0,t_f] [t_0,t_f] tf is the end of the interval of integration [t_0,t_f] [t_0,t_f] N is an integer specifying the number of evenly spaced points from t_0 t_0 to t_f t_f (inclusively) over which to compute the solution The function damping plots the approximation of the solution y(t) y(t) and returns a 2D Numpy array with 2 columns: column at index 0 is the array of N N evenly spaced t t values from t_0 t_0 to t_f t_f (inclusively) column at index 1 is the array of y y values of the solution","title":"Problems"},{"location":"problems/problems/#problems","text":"","title":"Problems"},{"location":"problems/problems/#optimization","text":"","title":"Optimization"},{"location":"problems/problems/#newtons-method","text":"Write a function called newton which takes input parameters f f , x_0 x_0 , h h (with default value 0.001), tolerance (with default value 0.001) and max_iter (with default value 100). The function implements Newton's method to approximate a solution of f(x) = 0 f(x) = 0 . In other words, compute the values of the recursive sequence starting at x_0 x_0 and defined by x_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)} x_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)} Use the central difference formula with step size h h to approximate the derivative f'(x_n) f'(x_n) . The desired result is that the method converges to an approximate root of f(x) f(x) however there are several possibilities: The sequence reaches the desired tolerance |f(x_n)| \\leq \\mathtt{tolerance} |f(x_n)| \\leq \\mathtt{tolerance} and newton returns the value x_n x_n . The number of iterations exceeds the maximum number of iterations max_iter , the function prints the statement \"Maximum iterations exceeded\" and returns None . A zero derivative is computed f'(x_n) = 0 f'(x_n) = 0 , the function prints the statement \"Zero derivative\" and returns None .","title":"Newton's Method"},{"location":"problems/problems/#numerical-differentiation","text":"","title":"Numerical Differentiation"},{"location":"problems/problems/#central-difference-formula","text":"Write a function called derivatives which takes input parameters f f , a a , n n and h h (with default value h = 0.001 ) and returns approximations of the derivatives f'(a) f'(a) , f''(a) f''(a) , \\dots \\dots , f^{(n)}(a) f^{(n)}(a) (as a NumPy array) using the formula f^{(n)}(a) \\approx \\frac{1}{2^n h^n} \\sum_{k=0}^n (-1)^k {n \\choose k} f \\left( a + ( n - 2k ) h \\right) f^{(n)}(a) \\approx \\frac{1}{2^n h^n} \\sum_{k=0}^n (-1)^k {n \\choose k} f \\left( a + ( n - 2k ) h \\right) Use either scipy.misc.factorial or scipy.misc.comb to compute n n choose k k : {n \\choose k} = \\frac{n!}{k!(n-k)!} {n \\choose k} = \\frac{n!}{k!(n-k)!}","title":"Central Difference Formula"},{"location":"problems/problems/#taylor-polynomials","text":"Write a function called taylor which takes input parameters f f , a a , n n and L L and plots both f(x) f(x) and the Taylor polynomial T_n(x) T_n(x) of f(x) f(x) at x=a x=a of degree n n T_n(x) = \\sum_{k=0}^n \\frac{f^{(k)}(a)}{k!}(x - a)^k T_n(x) = \\sum_{k=0}^n \\frac{f^{(k)}(a)}{k!}(x - a)^k on the interval [a-L,a+L] [a-L,a+L] (in the same figure).","title":"Taylor Polynomials"},{"location":"problems/problems/#numerical-integration","text":"","title":"Numerical Integration"},{"location":"problems/problems/#trapezoid-rule","text":"Find f''(x) f''(x) for f(x) = \\ln( \\ln x) f(x) = \\ln( \\ln x) . Prove |f''(x)| \\leq \\displaystyle \\frac{2}{e^2} |f''(x)| \\leq \\displaystyle \\frac{2}{e^2} for x \\geq e x \\geq e . Write a function called log_log which takes input parameters u and abs_tolerance such that u \\geq e u \\geq e and abs_tolerance is a positive number (with default value 0.0001). The function uses the trapezoid rule to compute and return an approximation of the integral $$ \\int_e^u \\ln( \\ln x) dx $$ The number N N of subintervals used in the trapezoid rule must be large enough to guarantee that the approximation is within abs_tolerance of the true value. You may use the function scipy.integrate.trapz .","title":"Trapezoid Rule"},{"location":"problems/problems/#simpsons-rule","text":"Find f''''(x) f''''(x) for f(x) = e^{-x^2} f(x) = e^{-x^2} . Plot f''''(x) f''''(x) for x \\in [0,5] x \\in [0,5] . Determine a bound M M such that |f''''(x)| \\leq M |f''''(x)| \\leq M for x \\geq 0 x \\geq 0 . Write a function called erf which takes input parameters u and abs_tolerance (with default value 0.0001) such that both are positive numbers. The function uses Simpson's rule to compute and return an approximation of the integral $$ \\int_0^u e^{-x^2} dx $$ The number N N of subintervals used in Simpson's rule must be large enough to guarantee that the approximation is within abs_tolerance of the true value. You may use the function scipy.integrate.simps .","title":"Simpson's Rule"},{"location":"problems/problems/#differential-equations","text":"","title":"Differential Equations"},{"location":"problems/problems/#lorenz-equations","text":"The Lorenz equations are the system of nonlinear differential equations \\begin{align} \\frac{dx}{dt} &= \\sigma(y - x) \\\\\\ \\frac{dy}{dt} &= x(\\rho - z) - y \\\\\\ \\frac{dz}{dt} &= xy - \\beta z \\end{align} \\begin{align} \\frac{dx}{dt} &= \\sigma(y - x) \\\\\\ \\frac{dy}{dt} &= x(\\rho - z) - y \\\\\\ \\frac{dz}{dt} &= xy - \\beta z \\end{align} where \\sigma \\sigma , \\rho \\rho and \\beta \\beta are positive numbers. Write a function called lorenz which takes input parameters sigma , rho , beta , u0 , t0 , tf , N and plot_vars (with default value [0,1] ). The function computes and plots a numerical approximation of the corresponding solution of the Lorenz equations using the function scipy.integrate.odeint . The input parameters are: sigma , rho and beta define the parameters \\sigma \\sigma , \\rho \\rho and \\beta \\beta u0 is a list of numbers of length 3 defining the initial conditions [x(t_0),y(t_0),z(t_0)] [x(t_0),y(t_0),z(t_0)] t0 is the start of the interval of integration [t_0,t_f] [t_0,t_f] tf is the end of the interval of integration [t_0,t_f] [t_0,t_f] N is an integer specifying the number of evenly spaced points from t_0 t_0 to t_f t_f (inclusively) over which to compute the solution of the system plot_vars is a list of length 2 specifying which 2 components to plot where x=0 x=0 , y=1 y=1 and z=2 z=2 . For example, if plot_vars is [0,1] [0,1] then plot the solution x x versus y y . If plot_vars is [1,2] [1,2] then plot the solution y y versus z z . Note x x versus y y means x x is the horizontal axis and y y is the vertical. Default value is [0,1] which plots x x versus y y . The function lorenz returns a 2D NumPy array with 4 columns: column at index 0 is the array of N N evenly spaced t t values from t_0 t_0 to t_f t_f (inclusively) column at index 1 is the array of x x values of the solution column at index 2 is the array of y y values of the solution column at index 3 is the array of z z values of the solution","title":"Lorenz Equations"},{"location":"problems/problems/#damped-oscillator","text":"Write a function called damping which takes input parameters m , b , k , F , u0 , t0 , tf and N . The function uses scipy.integrate.odeint to compute a numerical approximation of the corresponding solution of the nonlinear damping equation: m y'' + b |y'| y' + ky = F(t) m y'' + b |y'| y' + ky = F(t) The input parameters are: m , b and k are positive numbers in the nonlinear damping equation F is a function of one variable F(t) F(t) in the nonlinear damping equation u0 is a list of numbers of length 2 defining the initial conditions [y(t_0),y'(t_0)] [y(t_0),y'(t_0)] t0 is the start of the interval of integration [t_0,t_f] [t_0,t_f] tf is the end of the interval of integration [t_0,t_f] [t_0,t_f] N is an integer specifying the number of evenly spaced points from t_0 t_0 to t_f t_f (inclusively) over which to compute the solution The function damping plots the approximation of the solution y(t) y(t) and returns a 2D Numpy array with 2 columns: column at index 0 is the array of N N evenly spaced t t values from t_0 t_0 to t_f t_f (inclusively) column at index 1 is the array of y y values of the solution","title":"Damped Oscillator"},{"location":"python/functions/","text":"Functions A function takes input parameters, executes a series of computations with those inputs and then returns a final output value. Functions give us an efficient way to save and reuse a block of code over and over again with different input values. In this section, we summarize the built-in functions in the standard Python library and then we discuss how to define our own functions. Built-in Functions The standard Python library has a collection of built-in functions ready for us to use. We have already seen a few of these functions in previous sections such as type() , print() and sum() . The following is a list of built-in functions that we'll use most often: Function Description print(object) print object to output type(object) return the type of object abs(x) return the absolute value of x (or modulus if x is complex) int(x) return the integer constructed from float x by truncating decimal len(sequence) return the length of the sequence sum(sequence) return the sum of the entries of sequence max(sequence) return the maximum value in sequence min(sequence) return the minimum value in sequence range(a,b,step) return the range object of integers from a to b (exclusive) by step list(sequence) return a list constructed from sequence sorted(sequence) return the sorted list from the items in sequence reversed(sequence) return the reversed iterator object from the items in sequence enumerate(sequence) return the enumerate object constructed from sequence zip(a,b) return an iterator that aggregates items from sequences a and b Use the function print() to display values: pi = 3.14159 print(pi) 3.14159 Use the function type() to see the datatype of a value: type(pi) float Use the function abs() to compute the absolute value of a real number: x = -2019 abs(x) 2019 Or compute the magnitude of a complex number: z = 3 - 4j abs(z) 5.0 Use the function int() to truncate a float into an int: pi = 3.14159 int(pi) 3 The function truncates floats always towards 0: c = -1.2345 int(c) -1 Use the function len() to compute the length of a sequence: primes = [2,3,5,7,11,13,17,19,23,29,31,37,41] len(primes) 13 Use the function sum() to compute the sum of a sequence: one_to_hundred = range(1,101) sum(one_to_hundred) 5050 Use the functions max() and min() to compute the maximum and minimum values in a sequence. random = [8,27,3,7,6,14,28,19] print(max(random)) print(min(random)) 28 3 Use the function list() to convert a sequence (such as a range or a tuple) into a list: list(range(0,10,2)) [0, 2, 4, 6, 8] Use the function sorted() to sort a sequence: sorted_random = sorted(random) print(random) print(sorted_random) [8, 27, 3, 7, 6, 14, 28, 19] [3, 6, 7, 8, 14, 19, 27, 28] Use the function reversed() to reverse the order of a sequence: reversed_random = list(reversed(random)) print(random) print(reversed_random) [8, 27, 3, 7, 6, 14, 28, 19] [19, 28, 14, 6, 7, 3, 27, 8] Use the function enumerate() to enumerate a sequence: squares = [n**2 for n in range(0,6)] print(squares) enum_squares = list(enumerate(squares)) print(enum_squares) [0, 1, 4, 9, 16, 25] [(0, 0), (1, 1), (2, 4), (3, 9), (4, 16), (5, 25)] Use the function zip() to combine sequences into a list of pairs: random_1 = [-2,4,0,5] random_2 = [7,-1,9,3] random_zip = list(zip(random_1,random_2)) print(random_zip) [(-2, 7), (4, -1), (0, 9), (5, 3)] Notice in the last three examples reversed() , enumerate() and zip() we use the function list() to create a list from the output of each function. This is because these functions return iterator objects (similar to range objects) which only yield values when explicitly told to do so. Defining Functions Let's begin with a simple example. Define a function which returns the average of a sequence of numbers: def average(x): \"Compute the average of the values in the sequence x.\" sum_x = sum(x) length_x = len(x) return sum_x / length_x The main points to observe are: Start the function definition with the def keyword. Follow def with the name of the function. Follow the function name with the list of input parameters separated by commas and within parentheses. End the def statement with a colon : . Indent the body of the function by 4 spaces. Use the return keyword to specify the output of the function (but it is not always necessary). The second line is a documentation string (enclosed in quotation marks \" ... \") which describes the function. In Python, code blocks are defined using indentation . This means that lines of code indented the same amount are considered one block. In the example above, the four indented lines below the def statement form the body of the function. Notice that there is no output when we execute the cell containing the function definition. This is because we've only defined the function and it's waiting for us to use it! We need to call the function with values for the input parameters and then the function will compute and return the output value. Let's test our function: average([1,2,3,4]) 2.5 The function returns the expected value. Success! Documentation Strings The first line after the def statement in a function definition should be a documentation string (or docstring). A docstring is text (enclosed in double quotes \" ... \" or triple quotes ''' ... ''' ) which describes your function. Use triple quotes for a multiline docstring. See the Python documentation for all the conventions related to documentation strings. A helpful feature of the Jupyter notebook is the question mark operator ? . This will display the docstring of a function. Keep this in mind when writing your docstrings: other people will read your docstring to learn how to use your function. For example, use the question mark ? to view the documentation for the built-in function sum() : sum? I recommend (but it's up to you) a style similar to NumPy's style guide for docstrings: def function_name(param1,param2,param3): '''First line is a one-line general summary. A longer paragraph describing the function and relevant equations or algorithms used in the function. Parameters ---------- param1 : datatype Describe the parameter. param2 : datatype Describe the parameter. param3 : datatype Describe the parameters and continue with more details if necessary on a new set of indented lines. Returns ------- datatype A description of the output of the function and also describe special behaviour. Examples -------- >>> function_name(1,2,3) 1.2345 ''' See these examples and these examples . Keyword Arguments When we define functions, we list the input parameters. These are called positional parameters (or positional arguments) because the position in the def statement determines which parameter is which. def poly(x,y): \"Compute x + y**2.\" return x + y**2 poly(1,2) 5 poly(2,1) 3 A keyword argument allows us to insert default values for some parameters and we call them by name and the order doesn't matter. def greeting(first_name,last_name,salutation='Hello, '): return \"{0}{1} {2}!\".format(salutation, first_name, last_name) greeting('Patrick','Walls') 'Hello, Patrick Walls!' greeting('Walls','Patrick') 'Hello, Walls Patrick!' greeting('LeBron','James',salutation='I love you ') 'I love you LeBron James!' In this function, first_name and last_name are positional arguments and saluation is a keyword argument. For example, the function pandas.read_csv in the pandas package has many keyword arguments: import pandas as pd pd.read_csv? So many keyword arguments! The keyword arguments I use most often are encoding , skiprows and usecols . Comments Comments in a Python program are plain text descriptions of Python code which explain code to the reader. Python will ignore lines which begin with the hash symbol # and so we use the hash symbol to write comments to explain the steps in a program. See the examples below. Examples Area of a Triangle Let's define a function called area_triangle which takes an input parameter vertices which is a list of tuples representing the vertices of a triangle and returns the area of the triangle using Heron's Formula : A = \\sqrt{s(s-a)(s-b)(s-c)} A = \\sqrt{s(s-a)(s-b)(s-c)} where a a , b b and c c are the side lengths and s s is the semiperimeter s = \\frac{a+b+c}{2} s = \\frac{a+b+c}{2} def area_triangle(vertices): '''Compute the area of the triangle with given vertices. Parameters ---------- vertices : list of tuples of numbers The vertices of a triangle [(x1,y1),(x2,y2),(x3,y3)]. Returns ------- float Area of the triangle computed by Heron's formula. Examples -------- >>> area_triangle([(0,0),(3,0),(3,4)]) 6.0 >>> area_triangle([(-1,2),(-3,-1),(4,1)]) 8.499999999999996 ''' # Find the x distance between vertices 0 and 1 a_x = abs(vertices[0][0] - vertices[1][0]) # Find the y distance between vertices 0 and 1 a_y = abs(vertices[0][1] - vertices[1][1]) # Compute length of side a a = (a_x**2 + a_y**2)**0.5 # Find the x distance between vertices 1 and 2 b_x = abs(vertices[1][0] - vertices[2][0]) # Find the y distance between vertices 1 and 2 b_y = abs(vertices[1][1] - vertices[2][1]) # Compute length of side b b = (b_x**2 + b_y**2)**0.5 # Find the x distance between vertices 0 and 2 c_x = abs(vertices[0][0] - vertices[2][0]) # Find the y distance between vertices 0 and 2 c_y = abs(vertices[0][1] - vertices[2][1]) # Compute length of side c c = (c_x**2 + c_y**2)**0.5 # Compute semiperimeter s = (a + b + c)/2 # Compute area area = (s*(s - a)*(s - b)*(s - c))**0.5 return area Let's test our function. We know that the area of a right angle triangle with sides of length 1 and hypotenuse \\sqrt{2} \\sqrt{2} has area 0.5 0.5 . area_triangle([(0,0),(0,1),(1,0)]) 0.49999999999999983 Let's test again on another triangle with base b=3 b=3 and height h=4 h=4 and therefore its area is A=3(4)/2=6 A=3(4)/2=6 . area_triangle([(0,0),(3,0),(1,4)]) 6.000000000000003 The function area_triangle returns the expected values. Success! Riemann Zeta Function The Riemann zeta function is the infinite sum \\zeta(s) = \\sum_{n = 1}^{\\infty} \\frac{1}{n^s} \\zeta(s) = \\sum_{n = 1}^{\\infty} \\frac{1}{n^s} Write a function called zeta which takes 2 input parameters s and N and returns the partial sum: \\sum_{n=1}^N \\frac{1}{n^s} \\sum_{n=1}^N \\frac{1}{n^s} def zeta(s,N): \"Compute the Nth partial sum of the zeta function at s.\" terms = [1/n**s for n in range(1,N+1)] partial_sum = sum(terms) return partial_sum Let's test our function on input values for which we know the result: zeta(1,1) 1.0 zeta(2,2) 1.25 Now let's use our function to approximate special values of the Riemann zeta function : \\zeta(2) = \\frac{\\pi^2}{6} \\hspace{10mm} \\text{and} \\hspace{10mm} \\zeta(4) = \\frac{\\pi^4}{90} \\zeta(2) = \\frac{\\pi^2}{6} \\hspace{10mm} \\text{and} \\hspace{10mm} \\zeta(4) = \\frac{\\pi^4}{90} Compute the partial sum for s=2 s=2 and N=100000 N=100000 : zeta(2,100000) 1.6449240668982423 Compare to an approximation of the special value \\pi^2/6 \\pi^2/6 : 3.14159265**2/6 1.6449340630890041 Compute the partial sum for s=4 s=4 and N=100000 N=100000 : zeta(4,100000) 1.082323233710861 Compare to an approximation of the special value \\pi^4/90 \\pi^4/90 : 3.14159265**4/90 1.0823232287641997 Harmonic Mean Write a function called harmonic_mean which takes an input parameter s , a list of numbers x_1, \\dots, x_n x_1, \\dots, x_n of length n n , and returns the harmonic mean of the sequence: \\frac{n}{\\frac{1}{x_1} + \\frac{1}{x_2} + \\cdots + \\frac{1}{x_n}} \\frac{n}{\\frac{1}{x_1} + \\frac{1}{x_2} + \\cdots + \\frac{1}{x_n}} def harmonic_mean(s): \"Compute the harmonic mean of the numbers in the sequence s.\" n = len(s) terms = [1/s[i] for i in range(0,n)] result = n/sum(terms) return result Let's test our function: harmonic_mean([1,1,1,1]) 1.0 harmonic_mean([1,2,3]) 1.6363636363636365 Riemann Sums Write a function called mn_integral which takes input parameters m , n , a , b and N and returns the (right) Riemann sum : $$ \\int_a^b f(x) \\, dx \\approx \\sum_{k=1}^N f(x_k) \\Delta x \\ \\ , \\ \\ f(x) = \\frac{x^m + 1}{x^n + 1} $$ and \\Delta x = (b-a)/N \\Delta x = (b-a)/N and x_k = a + k \\Delta x x_k = a + k \\Delta x . def mn_integral(m,n,a,b,N): '''Compute the (right) Riemann sum for the function f(x) = (x^m + 1)/(x^n + 1) on interval [a,b] with a partition of N subintervals of equal size. Parameters ---------- m , n : numbers Parameters in function f(x) = (x^m + 1)/(x^n + 1) a , b : numbers Limits of integration. N : integer Size of partition of interval [a,b]. Returns ------- float The (right) Riemann sum of f(x) from a to b using a partition of size N. Examples -------- >>> mn_integral(0,1,0,1,2) 1.1666666666666665 >>> mn_integral(1,2,0,1,100000) 1.1319717536649336 ''' # Compute the width of subintervals delta_x = (b - a)/N # Create N+1 evenly spaced x values from a to b x = [a + k*delta_x for k in range(0,N+1)] # Compute terms of the sum terms = [(x[k]**m + 1)/(x[k]**n + 1)*delta_x for k in range(1,N+1)] # Compute the sum riemann_sum = sum(terms) return riemann_sum Let's test our function on input for which we know the result. Let m=0 m=0 , n=1 n=1 , a=0 a=0 , b=1 b=1 and N=2 N=2 . Then x_0 = 0 x_0 = 0 , x_1 = 1/2 x_1 = 1/2 , x_2 = 1 x_2 = 1 and \\Delta x = 1/2 \\Delta x = 1/2 , and we compute: \\begin{aligned} \\sum_{k=1}^N f(x_k) \\Delta x &= \\sum_{k=1}^2 \\frac{x_k^0 + 1}{x_k^1 + 1} \\Delta x \\\\\\ &= \\frac{2}{(1/2) + 1} \\cdot \\frac{1}{2} + \\frac{2}{1 + 1} \\cdot \\frac{1}{2} \\\\\\ &= \\frac{7}{6} \\end{aligned} \\begin{aligned} \\sum_{k=1}^N f(x_k) \\Delta x &= \\sum_{k=1}^2 \\frac{x_k^0 + 1}{x_k^1 + 1} \\Delta x \\\\\\ &= \\frac{2}{(1/2) + 1} \\cdot \\frac{1}{2} + \\frac{2}{1 + 1} \\cdot \\frac{1}{2} \\\\\\ &= \\frac{7}{6} \\end{aligned} mn_integral(0,1,0,1,2) 1.1666666666666665 7/6 1.1666666666666667 Let's test our function on another example. Let m=1 m=1 , n=2 n=2 , a=0 a=0 , and b=1 b=1 . We can solve this integral exactly: \\begin{aligned} \\int_0^1 \\frac{x + 1}{x^2 + 1} dx &= \\int_0^1 \\frac{x}{x^2 + 1} dx + \\int_0^1 \\frac{1}{x^2 + 1} dx \\\\\\ &= \\left. \\left( \\frac{1}{2} \\ln(x^2 + 1) + \\arctan x \\right) \\right|_0^1 \\\\\\ &= \\frac{1}{2} \\ln(2) + \\frac{\\pi}{4} \\end{aligned} \\begin{aligned} \\int_0^1 \\frac{x + 1}{x^2 + 1} dx &= \\int_0^1 \\frac{x}{x^2 + 1} dx + \\int_0^1 \\frac{1}{x^2 + 1} dx \\\\\\ &= \\left. \\left( \\frac{1}{2} \\ln(x^2 + 1) + \\arctan x \\right) \\right|_0^1 \\\\\\ &= \\frac{1}{2} \\ln(2) + \\frac{\\pi}{4} \\end{aligned} Approximate this integral with a Riemann sum for N=100000 N=100000 : mn_integral(1,2,0,1,100000) 1.1319717536649336 Since \\pi \\approx 3.14159265 \\pi \\approx 3.14159265 and \\ln(2) \\approx 0.69314718 \\ln(2) \\approx 0.69314718 , we compare to the approximation: 0.5*0.69314718 + 3.14159265/4 1.1319717525000002 Our function computes the expected values! Exercises Write a function called power_mean which takes input parameters sequence and p where sequence is a list of positive real numbers x_1, \\dots, x_n x_1, \\dots, x_n and p is a nonzero number. The function returns the power mean with exponent p : \\left( \\frac{1}{n} \\sum_{i=1}^n x_i^p \\right)^{1/p} \\left( \\frac{1}{n} \\sum_{i=1}^n x_i^p \\right)^{1/p} Plug in large positive values of p p and various lists of numbers to verify \\lim_{p \\to \\infty} \\left( \\frac{1}{n} \\sum_{i=1}^n x_i^p \\right)^{1/p} = \\max \\{x_1, \\dots, x_n \\} \\lim_{p \\to \\infty} \\left( \\frac{1}{n} \\sum_{i=1}^n x_i^p \\right)^{1/p} = \\max \\{x_1, \\dots, x_n \\} Plug in large negative values of p p and various lists of numbers to verify \\lim_{p \\to -\\infty} \\left( \\frac{1}{n} \\sum_{i=1}^n x_i^p \\right)^{1/p} = \\min \\{x_1, \\dots, x_n \\} \\lim_{p \\to -\\infty} \\left( \\frac{1}{n} \\sum_{i=1}^n x_i^p \\right)^{1/p} = \\min \\{x_1, \\dots, x_n \\} Write a function called arctan_taylor which takes input parameters x and N and return the Taylor polynomial of degree N N of the function \\arctan x \\arctan x evaluated at x : \\sum_{k=0}^N (-1)^k \\frac{x^{2k + 1}}{2k + 1} \\sum_{k=0}^N (-1)^k \\frac{x^{2k + 1}}{2k + 1} Write a function called zips which takes input parameters a and b , where a and b are lists of the equal length, and returns the list of tuples which aggregates the sequence. (In other words, write your own version of the built-in function zip() ... without using zip() of course.) For example zips([-1,3,4,0],[5,7,1,-9]) returns the list [(-1, 5), (3, 7), (4, 1), (0, -9)] . Write a function called sqrt_integral which takes input parameters u , p and N and returns the Riemann sum (using the midpoints x_k^\\* x_k^\\* of a partition of size N N ): \\int_0^u \\frac{1}{\\sqrt{1 + x^p}} dx \\approx \\sum_{k=1}^N \\frac{1}{\\sqrt{1 + (x_k^*)^p}} \\Delta x \\int_0^u \\frac{1}{\\sqrt{1 + x^p}} dx \\approx \\sum_{k=1}^N \\frac{1}{\\sqrt{1 + (x_k^*)^p}} \\Delta x where \\Delta x = u/N \\Delta x = u/N and x_k^* = (x_k + x_{k-1})/2 x_k^* = (x_k + x_{k-1})/2 for endpoints x_k = k \\Delta x x_k = k \\Delta x .","title":"Functions"},{"location":"python/functions/#functions","text":"A function takes input parameters, executes a series of computations with those inputs and then returns a final output value. Functions give us an efficient way to save and reuse a block of code over and over again with different input values. In this section, we summarize the built-in functions in the standard Python library and then we discuss how to define our own functions.","title":"Functions"},{"location":"python/functions/#built-in-functions","text":"The standard Python library has a collection of built-in functions ready for us to use. We have already seen a few of these functions in previous sections such as type() , print() and sum() . The following is a list of built-in functions that we'll use most often: Function Description print(object) print object to output type(object) return the type of object abs(x) return the absolute value of x (or modulus if x is complex) int(x) return the integer constructed from float x by truncating decimal len(sequence) return the length of the sequence sum(sequence) return the sum of the entries of sequence max(sequence) return the maximum value in sequence min(sequence) return the minimum value in sequence range(a,b,step) return the range object of integers from a to b (exclusive) by step list(sequence) return a list constructed from sequence sorted(sequence) return the sorted list from the items in sequence reversed(sequence) return the reversed iterator object from the items in sequence enumerate(sequence) return the enumerate object constructed from sequence zip(a,b) return an iterator that aggregates items from sequences a and b Use the function print() to display values: pi = 3.14159 print(pi) 3.14159 Use the function type() to see the datatype of a value: type(pi) float Use the function abs() to compute the absolute value of a real number: x = -2019 abs(x) 2019 Or compute the magnitude of a complex number: z = 3 - 4j abs(z) 5.0 Use the function int() to truncate a float into an int: pi = 3.14159 int(pi) 3 The function truncates floats always towards 0: c = -1.2345 int(c) -1 Use the function len() to compute the length of a sequence: primes = [2,3,5,7,11,13,17,19,23,29,31,37,41] len(primes) 13 Use the function sum() to compute the sum of a sequence: one_to_hundred = range(1,101) sum(one_to_hundred) 5050 Use the functions max() and min() to compute the maximum and minimum values in a sequence. random = [8,27,3,7,6,14,28,19] print(max(random)) print(min(random)) 28 3 Use the function list() to convert a sequence (such as a range or a tuple) into a list: list(range(0,10,2)) [0, 2, 4, 6, 8] Use the function sorted() to sort a sequence: sorted_random = sorted(random) print(random) print(sorted_random) [8, 27, 3, 7, 6, 14, 28, 19] [3, 6, 7, 8, 14, 19, 27, 28] Use the function reversed() to reverse the order of a sequence: reversed_random = list(reversed(random)) print(random) print(reversed_random) [8, 27, 3, 7, 6, 14, 28, 19] [19, 28, 14, 6, 7, 3, 27, 8] Use the function enumerate() to enumerate a sequence: squares = [n**2 for n in range(0,6)] print(squares) enum_squares = list(enumerate(squares)) print(enum_squares) [0, 1, 4, 9, 16, 25] [(0, 0), (1, 1), (2, 4), (3, 9), (4, 16), (5, 25)] Use the function zip() to combine sequences into a list of pairs: random_1 = [-2,4,0,5] random_2 = [7,-1,9,3] random_zip = list(zip(random_1,random_2)) print(random_zip) [(-2, 7), (4, -1), (0, 9), (5, 3)] Notice in the last three examples reversed() , enumerate() and zip() we use the function list() to create a list from the output of each function. This is because these functions return iterator objects (similar to range objects) which only yield values when explicitly told to do so.","title":"Built-in Functions"},{"location":"python/functions/#defining-functions","text":"Let's begin with a simple example. Define a function which returns the average of a sequence of numbers: def average(x): \"Compute the average of the values in the sequence x.\" sum_x = sum(x) length_x = len(x) return sum_x / length_x The main points to observe are: Start the function definition with the def keyword. Follow def with the name of the function. Follow the function name with the list of input parameters separated by commas and within parentheses. End the def statement with a colon : . Indent the body of the function by 4 spaces. Use the return keyword to specify the output of the function (but it is not always necessary). The second line is a documentation string (enclosed in quotation marks \" ... \") which describes the function. In Python, code blocks are defined using indentation . This means that lines of code indented the same amount are considered one block. In the example above, the four indented lines below the def statement form the body of the function. Notice that there is no output when we execute the cell containing the function definition. This is because we've only defined the function and it's waiting for us to use it! We need to call the function with values for the input parameters and then the function will compute and return the output value. Let's test our function: average([1,2,3,4]) 2.5 The function returns the expected value. Success!","title":"Defining Functions"},{"location":"python/functions/#documentation-strings","text":"The first line after the def statement in a function definition should be a documentation string (or docstring). A docstring is text (enclosed in double quotes \" ... \" or triple quotes ''' ... ''' ) which describes your function. Use triple quotes for a multiline docstring. See the Python documentation for all the conventions related to documentation strings. A helpful feature of the Jupyter notebook is the question mark operator ? . This will display the docstring of a function. Keep this in mind when writing your docstrings: other people will read your docstring to learn how to use your function. For example, use the question mark ? to view the documentation for the built-in function sum() : sum? I recommend (but it's up to you) a style similar to NumPy's style guide for docstrings: def function_name(param1,param2,param3): '''First line is a one-line general summary. A longer paragraph describing the function and relevant equations or algorithms used in the function. Parameters ---------- param1 : datatype Describe the parameter. param2 : datatype Describe the parameter. param3 : datatype Describe the parameters and continue with more details if necessary on a new set of indented lines. Returns ------- datatype A description of the output of the function and also describe special behaviour. Examples -------- >>> function_name(1,2,3) 1.2345 ''' See these examples and these examples .","title":"Documentation Strings"},{"location":"python/functions/#keyword-arguments","text":"When we define functions, we list the input parameters. These are called positional parameters (or positional arguments) because the position in the def statement determines which parameter is which. def poly(x,y): \"Compute x + y**2.\" return x + y**2 poly(1,2) 5 poly(2,1) 3 A keyword argument allows us to insert default values for some parameters and we call them by name and the order doesn't matter. def greeting(first_name,last_name,salutation='Hello, '): return \"{0}{1} {2}!\".format(salutation, first_name, last_name) greeting('Patrick','Walls') 'Hello, Patrick Walls!' greeting('Walls','Patrick') 'Hello, Walls Patrick!' greeting('LeBron','James',salutation='I love you ') 'I love you LeBron James!' In this function, first_name and last_name are positional arguments and saluation is a keyword argument. For example, the function pandas.read_csv in the pandas package has many keyword arguments: import pandas as pd pd.read_csv? So many keyword arguments! The keyword arguments I use most often are encoding , skiprows and usecols .","title":"Keyword Arguments"},{"location":"python/functions/#comments","text":"Comments in a Python program are plain text descriptions of Python code which explain code to the reader. Python will ignore lines which begin with the hash symbol # and so we use the hash symbol to write comments to explain the steps in a program. See the examples below.","title":"Comments"},{"location":"python/functions/#examples","text":"","title":"Examples"},{"location":"python/functions/#area-of-a-triangle","text":"Let's define a function called area_triangle which takes an input parameter vertices which is a list of tuples representing the vertices of a triangle and returns the area of the triangle using Heron's Formula : A = \\sqrt{s(s-a)(s-b)(s-c)} A = \\sqrt{s(s-a)(s-b)(s-c)} where a a , b b and c c are the side lengths and s s is the semiperimeter s = \\frac{a+b+c}{2} s = \\frac{a+b+c}{2} def area_triangle(vertices): '''Compute the area of the triangle with given vertices. Parameters ---------- vertices : list of tuples of numbers The vertices of a triangle [(x1,y1),(x2,y2),(x3,y3)]. Returns ------- float Area of the triangle computed by Heron's formula. Examples -------- >>> area_triangle([(0,0),(3,0),(3,4)]) 6.0 >>> area_triangle([(-1,2),(-3,-1),(4,1)]) 8.499999999999996 ''' # Find the x distance between vertices 0 and 1 a_x = abs(vertices[0][0] - vertices[1][0]) # Find the y distance between vertices 0 and 1 a_y = abs(vertices[0][1] - vertices[1][1]) # Compute length of side a a = (a_x**2 + a_y**2)**0.5 # Find the x distance between vertices 1 and 2 b_x = abs(vertices[1][0] - vertices[2][0]) # Find the y distance between vertices 1 and 2 b_y = abs(vertices[1][1] - vertices[2][1]) # Compute length of side b b = (b_x**2 + b_y**2)**0.5 # Find the x distance between vertices 0 and 2 c_x = abs(vertices[0][0] - vertices[2][0]) # Find the y distance between vertices 0 and 2 c_y = abs(vertices[0][1] - vertices[2][1]) # Compute length of side c c = (c_x**2 + c_y**2)**0.5 # Compute semiperimeter s = (a + b + c)/2 # Compute area area = (s*(s - a)*(s - b)*(s - c))**0.5 return area Let's test our function. We know that the area of a right angle triangle with sides of length 1 and hypotenuse \\sqrt{2} \\sqrt{2} has area 0.5 0.5 . area_triangle([(0,0),(0,1),(1,0)]) 0.49999999999999983 Let's test again on another triangle with base b=3 b=3 and height h=4 h=4 and therefore its area is A=3(4)/2=6 A=3(4)/2=6 . area_triangle([(0,0),(3,0),(1,4)]) 6.000000000000003 The function area_triangle returns the expected values. Success!","title":"Area of a Triangle"},{"location":"python/functions/#riemann-zeta-function","text":"The Riemann zeta function is the infinite sum \\zeta(s) = \\sum_{n = 1}^{\\infty} \\frac{1}{n^s} \\zeta(s) = \\sum_{n = 1}^{\\infty} \\frac{1}{n^s} Write a function called zeta which takes 2 input parameters s and N and returns the partial sum: \\sum_{n=1}^N \\frac{1}{n^s} \\sum_{n=1}^N \\frac{1}{n^s} def zeta(s,N): \"Compute the Nth partial sum of the zeta function at s.\" terms = [1/n**s for n in range(1,N+1)] partial_sum = sum(terms) return partial_sum Let's test our function on input values for which we know the result: zeta(1,1) 1.0 zeta(2,2) 1.25 Now let's use our function to approximate special values of the Riemann zeta function : \\zeta(2) = \\frac{\\pi^2}{6} \\hspace{10mm} \\text{and} \\hspace{10mm} \\zeta(4) = \\frac{\\pi^4}{90} \\zeta(2) = \\frac{\\pi^2}{6} \\hspace{10mm} \\text{and} \\hspace{10mm} \\zeta(4) = \\frac{\\pi^4}{90} Compute the partial sum for s=2 s=2 and N=100000 N=100000 : zeta(2,100000) 1.6449240668982423 Compare to an approximation of the special value \\pi^2/6 \\pi^2/6 : 3.14159265**2/6 1.6449340630890041 Compute the partial sum for s=4 s=4 and N=100000 N=100000 : zeta(4,100000) 1.082323233710861 Compare to an approximation of the special value \\pi^4/90 \\pi^4/90 : 3.14159265**4/90 1.0823232287641997","title":"Riemann Zeta Function"},{"location":"python/functions/#harmonic-mean","text":"Write a function called harmonic_mean which takes an input parameter s , a list of numbers x_1, \\dots, x_n x_1, \\dots, x_n of length n n , and returns the harmonic mean of the sequence: \\frac{n}{\\frac{1}{x_1} + \\frac{1}{x_2} + \\cdots + \\frac{1}{x_n}} \\frac{n}{\\frac{1}{x_1} + \\frac{1}{x_2} + \\cdots + \\frac{1}{x_n}} def harmonic_mean(s): \"Compute the harmonic mean of the numbers in the sequence s.\" n = len(s) terms = [1/s[i] for i in range(0,n)] result = n/sum(terms) return result Let's test our function: harmonic_mean([1,1,1,1]) 1.0 harmonic_mean([1,2,3]) 1.6363636363636365","title":"Harmonic Mean"},{"location":"python/functions/#riemann-sums","text":"Write a function called mn_integral which takes input parameters m , n , a , b and N and returns the (right) Riemann sum : $$ \\int_a^b f(x) \\, dx \\approx \\sum_{k=1}^N f(x_k) \\Delta x \\ \\ , \\ \\ f(x) = \\frac{x^m + 1}{x^n + 1} $$ and \\Delta x = (b-a)/N \\Delta x = (b-a)/N and x_k = a + k \\Delta x x_k = a + k \\Delta x . def mn_integral(m,n,a,b,N): '''Compute the (right) Riemann sum for the function f(x) = (x^m + 1)/(x^n + 1) on interval [a,b] with a partition of N subintervals of equal size. Parameters ---------- m , n : numbers Parameters in function f(x) = (x^m + 1)/(x^n + 1) a , b : numbers Limits of integration. N : integer Size of partition of interval [a,b]. Returns ------- float The (right) Riemann sum of f(x) from a to b using a partition of size N. Examples -------- >>> mn_integral(0,1,0,1,2) 1.1666666666666665 >>> mn_integral(1,2,0,1,100000) 1.1319717536649336 ''' # Compute the width of subintervals delta_x = (b - a)/N # Create N+1 evenly spaced x values from a to b x = [a + k*delta_x for k in range(0,N+1)] # Compute terms of the sum terms = [(x[k]**m + 1)/(x[k]**n + 1)*delta_x for k in range(1,N+1)] # Compute the sum riemann_sum = sum(terms) return riemann_sum Let's test our function on input for which we know the result. Let m=0 m=0 , n=1 n=1 , a=0 a=0 , b=1 b=1 and N=2 N=2 . Then x_0 = 0 x_0 = 0 , x_1 = 1/2 x_1 = 1/2 , x_2 = 1 x_2 = 1 and \\Delta x = 1/2 \\Delta x = 1/2 , and we compute: \\begin{aligned} \\sum_{k=1}^N f(x_k) \\Delta x &= \\sum_{k=1}^2 \\frac{x_k^0 + 1}{x_k^1 + 1} \\Delta x \\\\\\ &= \\frac{2}{(1/2) + 1} \\cdot \\frac{1}{2} + \\frac{2}{1 + 1} \\cdot \\frac{1}{2} \\\\\\ &= \\frac{7}{6} \\end{aligned} \\begin{aligned} \\sum_{k=1}^N f(x_k) \\Delta x &= \\sum_{k=1}^2 \\frac{x_k^0 + 1}{x_k^1 + 1} \\Delta x \\\\\\ &= \\frac{2}{(1/2) + 1} \\cdot \\frac{1}{2} + \\frac{2}{1 + 1} \\cdot \\frac{1}{2} \\\\\\ &= \\frac{7}{6} \\end{aligned} mn_integral(0,1,0,1,2) 1.1666666666666665 7/6 1.1666666666666667 Let's test our function on another example. Let m=1 m=1 , n=2 n=2 , a=0 a=0 , and b=1 b=1 . We can solve this integral exactly: \\begin{aligned} \\int_0^1 \\frac{x + 1}{x^2 + 1} dx &= \\int_0^1 \\frac{x}{x^2 + 1} dx + \\int_0^1 \\frac{1}{x^2 + 1} dx \\\\\\ &= \\left. \\left( \\frac{1}{2} \\ln(x^2 + 1) + \\arctan x \\right) \\right|_0^1 \\\\\\ &= \\frac{1}{2} \\ln(2) + \\frac{\\pi}{4} \\end{aligned} \\begin{aligned} \\int_0^1 \\frac{x + 1}{x^2 + 1} dx &= \\int_0^1 \\frac{x}{x^2 + 1} dx + \\int_0^1 \\frac{1}{x^2 + 1} dx \\\\\\ &= \\left. \\left( \\frac{1}{2} \\ln(x^2 + 1) + \\arctan x \\right) \\right|_0^1 \\\\\\ &= \\frac{1}{2} \\ln(2) + \\frac{\\pi}{4} \\end{aligned} Approximate this integral with a Riemann sum for N=100000 N=100000 : mn_integral(1,2,0,1,100000) 1.1319717536649336 Since \\pi \\approx 3.14159265 \\pi \\approx 3.14159265 and \\ln(2) \\approx 0.69314718 \\ln(2) \\approx 0.69314718 , we compare to the approximation: 0.5*0.69314718 + 3.14159265/4 1.1319717525000002 Our function computes the expected values!","title":"Riemann Sums"},{"location":"python/functions/#exercises","text":"Write a function called power_mean which takes input parameters sequence and p where sequence is a list of positive real numbers x_1, \\dots, x_n x_1, \\dots, x_n and p is a nonzero number. The function returns the power mean with exponent p : \\left( \\frac{1}{n} \\sum_{i=1}^n x_i^p \\right)^{1/p} \\left( \\frac{1}{n} \\sum_{i=1}^n x_i^p \\right)^{1/p} Plug in large positive values of p p and various lists of numbers to verify \\lim_{p \\to \\infty} \\left( \\frac{1}{n} \\sum_{i=1}^n x_i^p \\right)^{1/p} = \\max \\{x_1, \\dots, x_n \\} \\lim_{p \\to \\infty} \\left( \\frac{1}{n} \\sum_{i=1}^n x_i^p \\right)^{1/p} = \\max \\{x_1, \\dots, x_n \\} Plug in large negative values of p p and various lists of numbers to verify \\lim_{p \\to -\\infty} \\left( \\frac{1}{n} \\sum_{i=1}^n x_i^p \\right)^{1/p} = \\min \\{x_1, \\dots, x_n \\} \\lim_{p \\to -\\infty} \\left( \\frac{1}{n} \\sum_{i=1}^n x_i^p \\right)^{1/p} = \\min \\{x_1, \\dots, x_n \\} Write a function called arctan_taylor which takes input parameters x and N and return the Taylor polynomial of degree N N of the function \\arctan x \\arctan x evaluated at x : \\sum_{k=0}^N (-1)^k \\frac{x^{2k + 1}}{2k + 1} \\sum_{k=0}^N (-1)^k \\frac{x^{2k + 1}}{2k + 1} Write a function called zips which takes input parameters a and b , where a and b are lists of the equal length, and returns the list of tuples which aggregates the sequence. (In other words, write your own version of the built-in function zip() ... without using zip() of course.) For example zips([-1,3,4,0],[5,7,1,-9]) returns the list [(-1, 5), (3, 7), (4, 1), (0, -9)] . Write a function called sqrt_integral which takes input parameters u , p and N and returns the Riemann sum (using the midpoints x_k^\\* x_k^\\* of a partition of size N N ): \\int_0^u \\frac{1}{\\sqrt{1 + x^p}} dx \\approx \\sum_{k=1}^N \\frac{1}{\\sqrt{1 + (x_k^*)^p}} \\Delta x \\int_0^u \\frac{1}{\\sqrt{1 + x^p}} dx \\approx \\sum_{k=1}^N \\frac{1}{\\sqrt{1 + (x_k^*)^p}} \\Delta x where \\Delta x = u/N \\Delta x = u/N and x_k^* = (x_k + x_{k-1})/2 x_k^* = (x_k + x_{k-1})/2 for endpoints x_k = k \\Delta x x_k = k \\Delta x .","title":"Exercises"},{"location":"python/logic/","text":"Logic Boolean Values The boolean type has only two values: True and False . Let's assign a boolean value to a variable and verify the type using the built-in function type() : python_is_fun = True print(python_is_fun) True type(python_is_fun) bool Let's assign the value False to a variable and again verify the type: math_is_scary = False print(math_is_scary) False type(math_is_scary) bool Comparison Operators Comparison operators produce Boolean values as output. For example, if we have variables x and y with numeric values, we can evaluate the expression x < y and the result is a boolean value either True or False . Comparison Operator Description < strictly less than <= less than or equal > strictly greater than >= greater than or equal == equal != not equal For example: 1 == 2 False 1 < 2 True 2 == 2 True 3 != 3.14159 True 20.00000001 >= 20 True Boolean Operators We combine logical expressions using boolean operators and , or and not . Boolean Operator Description A and B returns True if both A and B are True A or B returns True if either A or B is True not A returns True if A is False For example: (1 < 2) and (3 != 5) True (1 < 2) and (3 < 1) False (1 < 2) or (3 < 1) True not (1000 <= 999) True if statements An if statement consists of one or more blocks of code such that only one block is executed depending on logical expressions. Let's do an example: # Determine if roots of polynomial ax^2 + bx + c = 0 # are real, repeated or complex using the # quadratic formula x = (-b \\pm \\sqrt{b^2 - 4ac})/2a a = 10 b = -234 c = 1984 discriminant = b**2 - 4*a*c if discriminant > 0: print(\"Discriminant =\", discriminant) print(\"Roots are real and distinct.\") elif discriminant < 0: print(\"Discriminant =\", discriminant) print(\"Roots are complex.\") else: print(\"Discriminant =\", discriminant) print(\"Roots are real and repeated.\") Discriminant = -24604 Roots are complex. The main points to observe are: Start with the if keyword. Write a logical expression (returning True or False ). End line with a colon : . Indent block 4 spaces after if statement. Include elif and else statements if needed. Only one of the blocks if , elif and else is executed. The block following an else statement will execute only if all other logical expressions before it are False . Examples Invertible Matrix Represent a 2 by 2 square matrix as a list of lists. For example, represent the matrix \\begin{bmatrix} 2 & -1 \\\\\\ 5 & 7 \\end{bmatrix} \\begin{bmatrix} 2 & -1 \\\\\\ 5 & 7 \\end{bmatrix} as the list of lists [[2,-1],[5,7]] . Write a function called invertible which takes an input parameter M , a list of lists representing a 2 by 2 matrix, and returns True if the matrix M is invertible and False if not. def invertible(M): '''Determine if M is invertible. Parameters ---------- M : list of lists Representation of a 2 by 2 matrix M = [[a,b],[c,d]]. Returns ------- bool True if M is invertible and False if not. Examples -------- >>> invertible([[1,2],[3,4]]) True ''' # A matrix M is invertible if and only if # the determinant is not zero where # det(M) = ad - bc for M = [[a,b],[c,d]] determinant = M[0][0] * M[1][1] - M[0][1] * M[1][0] if determinant != 0: return True else: return False Let's test our function: invertible([[1,2],[3,4]]) True invertible([[1,1],[3,3]]) False Concavity of a Polynomial Write a function called concave_up which takes input parameters p and a where p is a list representing a polynomial p(x) p(x) and a is a number, and returns True if the function p(x) p(x) is concave up at x=a x=a (ie. its second derivative is positive at x=a x=a , p''(a) > 0 p''(a) > 0 ). We'll use the second derivative test for polynomials. In particular, if we have a polynomial of degree n n p(x) = c_0 + c_1 x + c_2 x^2 + \\cdots + c_n x^n p(x) = c_0 + c_1 x + c_2 x^2 + \\cdots + c_n x^n then the second derivative of p(x) p(x) at x=a x=a is the sum p''(a) = 2(1) c_2 + 3(2)c_3 a + 4(3)c_4 a^2 + \\cdots + n(n-1)c_n a^{n-2} p''(a) = 2(1) c_2 + 3(2)c_3 a + 4(3)c_4 a^2 + \\cdots + n(n-1)c_n a^{n-2} def concave_up(p,a): '''Determine if the polynomial p(x) is concave up at x=a. Parameters ---------- p : list of numbers List [a_0,a_1,a_2,...,a_n] represents the polynomial p(x) = a_0 + a_1*x + a_2*x**2 + ... + a_n*x**n Returns ------- bool True if p(x) is concave up at x=a (ie. p''(a) > 0) and False otherwise. Examples -------- >>> concave_up([1,0,-2],0) False >>> concave_up([1,0,2],0) True ''' # Degree of the polynomial p(x) degree = len(p) - 1 # p''(a) == 0 if degree of p(x) is less than 2 if degree < 2: return False else: # Compute the second derivative p''(a) DDp_a = sum([k*(k-1)*p[k]*a**(k-2) for k in range(2,degree + 1)]) if DDp_a > 0: return True else: return False Let's test our function on p(x) = 1 + x - x^3 p(x) = 1 + x - x^3 at x=2 x=2 . Since p''(x) = -6x p''(x) = -6x and p''(2) = -12 < 0 p''(2) = -12 < 0 , the polynomial is concave down at x=2 x=2 . p = [1,1,0,-1] a = 2 concavity = concave_up(p,a) print(concavity) False Exercises The discriminant of a cubic polynomial p(x) = ax^3 + bx^2 + cx + d p(x) = ax^3 + bx^2 + cx + d is \\Delta = b^2c^2 - 4ac^3 - 4b^3d - 27a^2d^2 + 18abcd \\Delta = b^2c^2 - 4ac^3 - 4b^3d - 27a^2d^2 + 18abcd The discriminant gives us information about the roots of the polynomial p(x) p(x) : if \\Delta > 0 \\Delta > 0 , then p(x) p(x) has 3 distinct real roots if \\Delta < 0 \\Delta < 0 , then p(x) p(x) has 2 distinct complex roots and 1 real root if \\Delta = 0 \\Delta = 0 , then p(x) p(x) has at least 2 (real or complex) roots which are the same Represent a cubic polynomial p(x) = ax^3 + bx^2 + cx + d p(x) = ax^3 + bx^2 + cx + d as a list [d,c,b,a] of numbers. (Note the order of the coefficients is increasing degree.) For example, the polynomial p(x) = x^3 - x + 1 p(x) = x^3 - x + 1 is [1,-1,0,1] . Write a function called cubic_roots which takes an input parameter p , a list of length 4 representing a cubic polynomial, and returns True if p(x) p(x) has 3 real distinct roots and False otherwise. Represent a 2 by 2 square matrix as a list of lists. For example, represent the matrix \\begin{bmatrix} 2 & -1 \\\\\\ 5 & 7 \\end{bmatrix} \\begin{bmatrix} 2 & -1 \\\\\\ 5 & 7 \\end{bmatrix} as the list of lists [[2,-1],[5,7]] . Write a function called inverse_a which takes an input parameter a and returns a list of lists representing the inverse of the matrix \\begin{bmatrix} 1 & a \\\\\\ a & -1 \\end{bmatrix} \\begin{bmatrix} 1 & a \\\\\\ a & -1 \\end{bmatrix} Write a function called real_eigenvalues which takes an input parameter M , a list of lists representing a 2 by 2 matrix (as in the previous exercise), and returns True if the eigenvalues of the matrix M are real numebrs and False if not.","title":"Logic"},{"location":"python/logic/#logic","text":"","title":"Logic"},{"location":"python/logic/#boolean-values","text":"The boolean type has only two values: True and False . Let's assign a boolean value to a variable and verify the type using the built-in function type() : python_is_fun = True print(python_is_fun) True type(python_is_fun) bool Let's assign the value False to a variable and again verify the type: math_is_scary = False print(math_is_scary) False type(math_is_scary) bool","title":"Boolean Values"},{"location":"python/logic/#comparison-operators","text":"Comparison operators produce Boolean values as output. For example, if we have variables x and y with numeric values, we can evaluate the expression x < y and the result is a boolean value either True or False . Comparison Operator Description < strictly less than <= less than or equal > strictly greater than >= greater than or equal == equal != not equal For example: 1 == 2 False 1 < 2 True 2 == 2 True 3 != 3.14159 True 20.00000001 >= 20 True","title":"Comparison Operators"},{"location":"python/logic/#boolean-operators","text":"We combine logical expressions using boolean operators and , or and not . Boolean Operator Description A and B returns True if both A and B are True A or B returns True if either A or B is True not A returns True if A is False For example: (1 < 2) and (3 != 5) True (1 < 2) and (3 < 1) False (1 < 2) or (3 < 1) True not (1000 <= 999) True","title":"Boolean Operators"},{"location":"python/logic/#if-statements","text":"An if statement consists of one or more blocks of code such that only one block is executed depending on logical expressions. Let's do an example: # Determine if roots of polynomial ax^2 + bx + c = 0 # are real, repeated or complex using the # quadratic formula x = (-b \\pm \\sqrt{b^2 - 4ac})/2a a = 10 b = -234 c = 1984 discriminant = b**2 - 4*a*c if discriminant > 0: print(\"Discriminant =\", discriminant) print(\"Roots are real and distinct.\") elif discriminant < 0: print(\"Discriminant =\", discriminant) print(\"Roots are complex.\") else: print(\"Discriminant =\", discriminant) print(\"Roots are real and repeated.\") Discriminant = -24604 Roots are complex. The main points to observe are: Start with the if keyword. Write a logical expression (returning True or False ). End line with a colon : . Indent block 4 spaces after if statement. Include elif and else statements if needed. Only one of the blocks if , elif and else is executed. The block following an else statement will execute only if all other logical expressions before it are False .","title":"if statements"},{"location":"python/logic/#examples","text":"","title":"Examples"},{"location":"python/logic/#invertible-matrix","text":"Represent a 2 by 2 square matrix as a list of lists. For example, represent the matrix \\begin{bmatrix} 2 & -1 \\\\\\ 5 & 7 \\end{bmatrix} \\begin{bmatrix} 2 & -1 \\\\\\ 5 & 7 \\end{bmatrix} as the list of lists [[2,-1],[5,7]] . Write a function called invertible which takes an input parameter M , a list of lists representing a 2 by 2 matrix, and returns True if the matrix M is invertible and False if not. def invertible(M): '''Determine if M is invertible. Parameters ---------- M : list of lists Representation of a 2 by 2 matrix M = [[a,b],[c,d]]. Returns ------- bool True if M is invertible and False if not. Examples -------- >>> invertible([[1,2],[3,4]]) True ''' # A matrix M is invertible if and only if # the determinant is not zero where # det(M) = ad - bc for M = [[a,b],[c,d]] determinant = M[0][0] * M[1][1] - M[0][1] * M[1][0] if determinant != 0: return True else: return False Let's test our function: invertible([[1,2],[3,4]]) True invertible([[1,1],[3,3]]) False","title":"Invertible Matrix"},{"location":"python/logic/#concavity-of-a-polynomial","text":"Write a function called concave_up which takes input parameters p and a where p is a list representing a polynomial p(x) p(x) and a is a number, and returns True if the function p(x) p(x) is concave up at x=a x=a (ie. its second derivative is positive at x=a x=a , p''(a) > 0 p''(a) > 0 ). We'll use the second derivative test for polynomials. In particular, if we have a polynomial of degree n n p(x) = c_0 + c_1 x + c_2 x^2 + \\cdots + c_n x^n p(x) = c_0 + c_1 x + c_2 x^2 + \\cdots + c_n x^n then the second derivative of p(x) p(x) at x=a x=a is the sum p''(a) = 2(1) c_2 + 3(2)c_3 a + 4(3)c_4 a^2 + \\cdots + n(n-1)c_n a^{n-2} p''(a) = 2(1) c_2 + 3(2)c_3 a + 4(3)c_4 a^2 + \\cdots + n(n-1)c_n a^{n-2} def concave_up(p,a): '''Determine if the polynomial p(x) is concave up at x=a. Parameters ---------- p : list of numbers List [a_0,a_1,a_2,...,a_n] represents the polynomial p(x) = a_0 + a_1*x + a_2*x**2 + ... + a_n*x**n Returns ------- bool True if p(x) is concave up at x=a (ie. p''(a) > 0) and False otherwise. Examples -------- >>> concave_up([1,0,-2],0) False >>> concave_up([1,0,2],0) True ''' # Degree of the polynomial p(x) degree = len(p) - 1 # p''(a) == 0 if degree of p(x) is less than 2 if degree < 2: return False else: # Compute the second derivative p''(a) DDp_a = sum([k*(k-1)*p[k]*a**(k-2) for k in range(2,degree + 1)]) if DDp_a > 0: return True else: return False Let's test our function on p(x) = 1 + x - x^3 p(x) = 1 + x - x^3 at x=2 x=2 . Since p''(x) = -6x p''(x) = -6x and p''(2) = -12 < 0 p''(2) = -12 < 0 , the polynomial is concave down at x=2 x=2 . p = [1,1,0,-1] a = 2 concavity = concave_up(p,a) print(concavity) False","title":"Concavity of a Polynomial"},{"location":"python/logic/#exercises","text":"The discriminant of a cubic polynomial p(x) = ax^3 + bx^2 + cx + d p(x) = ax^3 + bx^2 + cx + d is \\Delta = b^2c^2 - 4ac^3 - 4b^3d - 27a^2d^2 + 18abcd \\Delta = b^2c^2 - 4ac^3 - 4b^3d - 27a^2d^2 + 18abcd The discriminant gives us information about the roots of the polynomial p(x) p(x) : if \\Delta > 0 \\Delta > 0 , then p(x) p(x) has 3 distinct real roots if \\Delta < 0 \\Delta < 0 , then p(x) p(x) has 2 distinct complex roots and 1 real root if \\Delta = 0 \\Delta = 0 , then p(x) p(x) has at least 2 (real or complex) roots which are the same Represent a cubic polynomial p(x) = ax^3 + bx^2 + cx + d p(x) = ax^3 + bx^2 + cx + d as a list [d,c,b,a] of numbers. (Note the order of the coefficients is increasing degree.) For example, the polynomial p(x) = x^3 - x + 1 p(x) = x^3 - x + 1 is [1,-1,0,1] . Write a function called cubic_roots which takes an input parameter p , a list of length 4 representing a cubic polynomial, and returns True if p(x) p(x) has 3 real distinct roots and False otherwise. Represent a 2 by 2 square matrix as a list of lists. For example, represent the matrix \\begin{bmatrix} 2 & -1 \\\\\\ 5 & 7 \\end{bmatrix} \\begin{bmatrix} 2 & -1 \\\\\\ 5 & 7 \\end{bmatrix} as the list of lists [[2,-1],[5,7]] . Write a function called inverse_a which takes an input parameter a and returns a list of lists representing the inverse of the matrix \\begin{bmatrix} 1 & a \\\\\\ a & -1 \\end{bmatrix} \\begin{bmatrix} 1 & a \\\\\\ a & -1 \\end{bmatrix} Write a function called real_eigenvalues which takes an input parameter M , a list of lists representing a 2 by 2 matrix (as in the previous exercise), and returns True if the eigenvalues of the matrix M are real numebrs and False if not.","title":"Exercises"},{"location":"python/loops/","text":"Loops for Loops A for loop allows us to execute a block of code multiple times with some parameters updated each time through the loop. A for loop begins with the for statement: iterable = [1,2,3] for item in iterable: # code block indented 4 spaces print(item) 1 2 3 The main points to observe are: for and in keywords iterable is a sequence object such as a list, tuple or range item is a variable which takes each value in iterable end for statement with a colon : code block indented 4 spaces which executes once for each value in iterable For example, let's print n^2 n^2 for n n from 0 to 5: for n in [0,1,2,3,4,5]: square = n**2 print(n,'squared is',square) print('The for loop is complete!') 0 squared is 0 1 squared is 1 2 squared is 4 3 squared is 9 4 squared is 16 5 squared is 25 The for loop is complete! Copy and paste this code and any of the examples below into the Python visualizer to see each step in a for loop! while Loops What if we want to execute a block of code multiple times but we don't know exactly how many times? We can't write a for loop because this requires us to set the length of the loop in advance. This is a situation when a while loop is useful. The following example illustrates a while loop : n = 5 while n > 0: print(n) n = n - 1 5 4 3 2 1 The main points to observe are: while keyword a logical expression followed by a colon : loop executes its code block if the logical expression evaluates to True update the variable in the logical expression each time through the loop BEWARE! If the logical expression always evaluates to True , then you get an infinite loop ! We prefer for loops over while loops because of the last point. A for loop will never result in an infinite loop. If a loop can be constructed with for or while , we'll always choose for . Constructing Sequences There are several ways to construct a sequence of values and to save them as a Python list. We have already seen Python's list comprehension syntax. There is also the append list method described below. Sequences by a Formula If a sequence is given by a formula then we can use a list comprehension to construct it. For example, the sequence of squares from 1 to 100 can be constructed using a list comprehension: squares = [d**2 for d in range(1,11)] print(squares) [1, 4, 9, 16, 25, 36, 49, 64, 81, 100] However, we can achieve the same result with a for loop and the append method for lists: # Intialize an empty list squares = [] for d in range(1,11): # Append the next square to the list squares.append(d**2) print(squares) [1, 4, 9, 16, 25, 36, 49, 64, 81, 100] In fact, the two examples above are equivalent. The purpose of list comprehensions is to simplify and compress the syntax into a one-line construction. Recursive Sequences We can only use a list comprehension to construct a sequence when the sequence values are defined by a formula. But what if we want to construct a sequence where the next value depends on previous values? This is called a recursive sequence . For example, consider the Fibonacci sequence : x_1 = 1, x_2 = 1, x_3 = 2, x_4 = 3, x_5 = 5, ... x_1 = 1, x_2 = 1, x_3 = 2, x_4 = 3, x_5 = 5, ... where x_{n} = x_{n-1} + x_{n-2} x_{n} = x_{n-1} + x_{n-2} We can't use a list comprehension to build the list of Fibonacci numbers, and so we must use a for loop with the append method instead. For example, the first 15 Fibonacci numbers are: fibonacci_numbers = [1,1] for n in range(2,15): fibonacci_n = fibonacci_numbers[n-1] + fibonacci_numbers[n-2] fibonacci_numbers.append(fibonacci_n) print(fibonacci_numbers) [1, 1, 2] [1, 1, 2, 3] [1, 1, 2, 3, 5] [1, 1, 2, 3, 5, 8] [1, 1, 2, 3, 5, 8, 13] [1, 1, 2, 3, 5, 8, 13, 21] [1, 1, 2, 3, 5, 8, 13, 21, 34] [1, 1, 2, 3, 5, 8, 13, 21, 34, 55] [1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89] [1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144] [1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233] [1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377] [1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610] Computing Sums Suppose we want to compute the sum of a sequence of numbers x_0 x_0 , x_1 x_1 , x_2 x_2 , x_3 x_3 , \\dots \\dots , x_n x_n . There are at least two approaches: Compute the entire sequence, store it as a list [x_0,x_1,x_2,\\dots,x_n] [x_0,x_1,x_2,\\dots,x_n] and then use the built-in function sum . Initialize a variable with value 0 (and name it result for example), create and add each element in the sequence to result one at a time. The advantage of the second approach is that we don't need to store all the values at once. For example, here are two ways to write a function which computes the sum of squares. For the first approach, use a list comprehension: def sum_of_squares_1(N): \"Compute the sum of squares 1**2 + 2**2 + ... + N**2.\" return sum([n**2 for n in range(1,N + 1)]) sum_of_squares_1(4) 30 For the second approach, use a for loop with the initialize-and-update construction: def sum_of_squares_2(N): \"Compute the sum of squares 1**2 + 2**2 + ... + N**2.\" # Initialize the output value to 0 result = 0 for n in range(1,N + 1): # Update the result by adding the next term result = result + n**2 return result sum_of_squares_2(4) 30 Again, both methods yield the same result however the second uses less memory! Computing Products There is no built-in function to compute products of sequences therefore we'll use an initialize-and-update construction similar to the example above for computing sums. Write a function called factorial which takes a positive integer N N and return the factorial N! N! . def factorial(N): \"Compute N! = N(N-1) ... (2)(1) for N >= 1.\" # Initialize the output variable to 1 product = 1 for n in range(2,N + 1): # Update the output variable product = product * n return product Let's test our function for input values for which we know the result: factorial(2) 2 factorial(5) 120 We can use our function to approximate e e using the Taylor series for e^x e^x : e^x = \\sum_{k=0}^{\\infty} \\frac{x^k}{k!} e^x = \\sum_{k=0}^{\\infty} \\frac{x^k}{k!} For example, let's compute the 100th partial sum of the series with x=1 x=1 : sum([1/factorial(k) for k in range(0,101)]) 2.7182818284590455 Searching for Solutions We can use for loops to search for integer solutions of equations. For example, suppose we would like to find all representations of a positive integer N N as a sum of two squares . In other words, we want to find all integer solutions (x,y) (x,y) of the equation: x^2 + y^2 = N x^2 + y^2 = N Write a function called reps_sum_squares which takes an integer N N and finds all representations of N N as a sum of squares x^2 + y^2 = N x^2 + y^2 = N for 0 \\leq x \\leq y 0 \\leq x \\leq y . The function returns the representations as a list of tuples. For example, if N = 50 N = 50 then 1^2 + 7^2 = 50 1^2 + 7^2 = 50 and 5^2 + 5^2 = 50 5^2 + 5^2 = 50 and the function returns the list [(1, 7),(5, 5)] . Let's outline our approach before we write any code: Given x \\leq y x \\leq y , the largest possible value for x x is \\sqrt{\\frac{N}{2}} \\sqrt{\\frac{N}{2}} For x \\leq \\sqrt{\\frac{N}{2}} x \\leq \\sqrt{\\frac{N}{2}} , the pair (x,y) (x,y) is a solution if N - x^2 N - x^2 is a square Define a helper function called is_square to test if an integer is square def is_square(n): \"Determine if the integer n is a square.\" if round(n**0.5)**2 == n: return True else: return False def reps_sum_squares(N): '''Find all representations of N as a sum of squares x**2 + y**2 = N. Parameters ---------- N : integer Returns ------- reps : list of tuples of integers List of tuples (x,y) of positive integers such that x**2 + y**2 = N. Examples -------- >>> reps_sum_squares(1105) [(4, 33), (9, 32), (12, 31), (23, 24)] ''' reps = [] if is_square(N/2): # If N/2 is a square, search up to x = (N/2)**0.5 max_x = round((N/2)**0.5) else: # If N/2 is not a square, search up to x = floor((N/2)**0.5) max_x = int((N/2)**0.5) for x in range(0,max_x + 1): y_squared = N - x**2 if is_square(y_squared): y = round(y_squared**0.5) # Append solution (x,y) to list of solutions reps.append((x,y)) return reps reps_sum_squares(1105) [(4, 33), (9, 32), (12, 31), (23, 24)] What is the smallest integer which can be expressed as the sum of squares in 5 different ways? N = 1105 num_reps = 4 while num_reps < 5: N = N + 1 reps = reps_sum_squares(N) num_reps = len(reps) print(N,':',reps_sum_squares(N)) 4225 : [(0, 65), (16, 63), (25, 60), (33, 56), (39, 52)] Examples Prime Numbers A positive integer is prime if it is divisible only by 1 and itself. Write a function called is_prime which takes an input parameter n and returns True or False depending on whether n is prime or not. Let's outline our approach before we write any code: An integer d d divides n n if there is no remainder of n n divided by d d . Use the modulus operator % to compute the remainder. If d d divides n n then n = d q n = d q for some integer q q and either d \\leq \\sqrt{n} d \\leq \\sqrt{n} or q \\leq \\sqrt{n} q \\leq \\sqrt{n} (and not both), therefore we need only test if d d divides n n for integers d \\leq \\sqrt{n} d \\leq \\sqrt{n} def is_prime(n): \"Determine whether or not n is a prime number.\" if n <= 1: return False # Test if d divides n for d <= n**0.5 for d in range(2,round(n**0.5) + 1): if n % d == 0: # n is divisible by d and so n is not prime return False # If we exit the for loop, then n is not divisible by any d # and therefore n is prime return True Let's test our function on the first 30 numbers: for n in range(0,31): if is_prime(n): print(n,'is prime!') 2 is prime! 3 is prime! 5 is prime! 7 is prime! 11 is prime! 13 is prime! 17 is prime! 19 is prime! 23 is prime! 29 is prime! Our function works! Let's find all the primes between 20,000 and 20,100. for n in range(20000,20100): if is_prime(n): print(n,'is prime!') 20011 is prime! 20021 is prime! 20023 is prime! 20029 is prime! 20047 is prime! 20051 is prime! 20063 is prime! 20071 is prime! 20089 is prime! Divisors Let's write a function called divisors which takes a positive integer N N and returns the list of positive integers which divide N N . def divisors(N): \"Return the list of divisors of N.\" # Initialize the list of divisors (which always includes 1) divisor_list = [1] # Check division by d for d <= N/2 for d in range(2,N // 2 + 1): if N % d == 0: divisor_list.append(d) # N divides itself and so we append N to the list of divisors divisor_list.append(N) return divisor_list Let's test our function: divisors(10) [1, 2, 5, 10] divisors(100) [1, 2, 4, 5, 10, 20, 25, 50, 100] divisors(59) [1, 59] Collatz Conjecture Let a a be a positive integer and consider the recursive sequence where x_0 = a x_0 = a and x_{n+1} = \\left\\\\{ \\begin{array}{cl} x_n/2 & \\text{if } x_n \\text{ is even} \\\\\\\\ 3x_n+1 & \\text{if } x_n \\text{ is odd} \\end{array} \\\\right. x_{n+1} = \\left\\\\{ \\begin{array}{cl} x_n/2 & \\text{if } x_n \\text{ is even} \\\\\\\\ 3x_n+1 & \\text{if } x_n \\text{ is odd} \\end{array} \\\\right. The Collatz conjecture states that this sequence will always reach 1. For example, if a = 10 a = 10 then x_0 = 10 x_0 = 10 , x_1 = 5 x_1 = 5 , x_2 = 16 x_2 = 16 , x_3 = 8 x_3 = 8 , x_4 = 4 x_4 = 4 , x_5 = 2 x_5 = 2 and x_6 = 1 x_6 = 1 . Write a function called collatz which takes one input parameter a and returns the sequence of integers defined above and ending with the first occurrence x_n=1 x_n=1 . def collatz(a): \"Compute the Collatz sequence starting at a and ending at 1.\" # Initialize list with first value a sequence = [a] # Compute values until we reach 1 while sequence[-1] > 1: # Check if the last element in the list is even if sequence[-1] % 2 == 0: # Compute and append the new value sequence.append(sequence[-1] // 2) else: # Compute and append the new value sequence.append(3*sequence[-1] + 1) return sequence Let's test our function: print(collatz(10)) [10, 5, 16, 8, 4, 2, 1] collatz(22) [22, 11, 34, 17, 52, 26, 13, 40, 20, 10, 5, 16, 8, 4, 2, 1] The Collatz conjecture is quite amazing. No matter where we start, the sequence always terminates at 1! a = 123456789 seq = collatz(a) print(\"Collatz sequence for a =\",a) print(\"begins with\",seq[:5]) print(\"ends with\",seq[-5:]) print(\"and has\",len(seq),\"terms.\") Collatz sequence for a = 123456789 begins with [123456789, 370370368, 185185184, 92592592, 46296296] ends with [16, 8, 4, 2, 1] and has 178 terms. Which a < 1000 a < 1000 produces the longest sequence? max_length = 1 a_max = 1 for a in range(1,1001): seq_length = len(collatz(a)) if seq_length > max_length: max_length = seq_length a_max = a print('Longest sequence begins with a =',a_max,'and has length',max_length) Longest sequence begins with a = 871 and has length 179 Exercises Fermat's theorem on the sum of two squares states that every prime number p p of the form 4k+1 4k+1 can be expressed as the sum of two squares. For example, 5 = 2^2 + 1^2 5 = 2^2 + 1^2 and 13 = 3^2 + 2^2 13 = 3^2 + 2^2 . Find the smallest prime greater than 2019 2019 of the form 4k+1 4k+1 and write it as a sum of squares. (Hint: Use the functions is_prime and reps_sum_squares from this section.) What is the smallest prime number which can be represented as a sum of squares in 2 different ways? What is the smallest integer which can be represented as a sum of squares in 3 different ways? Write a function called primes_between which takes two integer inputs a a and b b and returns the list of primes in the closed interval [a,b] [a,b] . Write a function called primes_d_mod_N which takes four integer inputs a a , b b , d d and N N and returns the list of primes in the closed interval [a,b] [a,b] which are congruent to d d mod N N (this means that the prime has remainder d d after division by N N ). This kind of list is called primes in an arithmetic progression . Write a function called reciprocal_recursion which takes three positive integers x_0 x_0 , x_1 x_1 and N N and returns the sequence [x_0,x_1,x_2,\\dots,x_N] [x_0,x_1,x_2,\\dots,x_N] where x_n = \\frac{1}{x_{n-1}} + \\frac{1}{x_{n-2}} x_n = \\frac{1}{x_{n-1}} + \\frac{1}{x_{n-2}} Write a function called root_sequence which takes input parameters a a and N N , both positive integers, and returns the N N th term x_N x_N in the sequence: \\begin{align} x_0 &= a \\\\\\ x_n &= 1 + \\sqrt{x_{n-1}} \\end{align} \\begin{align} x_0 &= a \\\\\\ x_n &= 1 + \\sqrt{x_{n-1}} \\end{align} Does the sequence converge to different values for different starting values a a ? Write a function called fib_less_than which takes one input N N and returns the list of Fibonacci numbers less than N N . Write a function called fibonacci_primes which takes an input parameter N N and returns the list of Fibonacci numbers less than N N which are also prime numbers. Let w(N) w(N) be the number of ways N N can be expressed as a sum of two squares x^2 + y^2 = N x^2 + y^2 = N with 1 \\leq x \\leq y 1 \\leq x \\leq y . Then \\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n=1}^{N} w(n) = \\frac{\\pi}{8} \\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n=1}^{N} w(n) = \\frac{\\pi}{8} Compute the left side of the formula for N=100 N=100 and compare the result to \\pi / 8 \\pi / 8 . A list of positive integers [a,b,c] [a,b,c] (with 1 \\leq a < b 1 \\leq a < b ) are a Pythagorean triple if a^2 + b^2 = c^2 a^2 + b^2 = c^2 . Write a function called py_triples which takes an input parameter N N and returns the list of Pythagorean triples [a,b,c] with c \\leq N c \\leq N .","title":"Loops"},{"location":"python/loops/#loops","text":"","title":"Loops"},{"location":"python/loops/#for-loops","text":"A for loop allows us to execute a block of code multiple times with some parameters updated each time through the loop. A for loop begins with the for statement: iterable = [1,2,3] for item in iterable: # code block indented 4 spaces print(item) 1 2 3 The main points to observe are: for and in keywords iterable is a sequence object such as a list, tuple or range item is a variable which takes each value in iterable end for statement with a colon : code block indented 4 spaces which executes once for each value in iterable For example, let's print n^2 n^2 for n n from 0 to 5: for n in [0,1,2,3,4,5]: square = n**2 print(n,'squared is',square) print('The for loop is complete!') 0 squared is 0 1 squared is 1 2 squared is 4 3 squared is 9 4 squared is 16 5 squared is 25 The for loop is complete! Copy and paste this code and any of the examples below into the Python visualizer to see each step in a for loop!","title":"for Loops"},{"location":"python/loops/#while-loops","text":"What if we want to execute a block of code multiple times but we don't know exactly how many times? We can't write a for loop because this requires us to set the length of the loop in advance. This is a situation when a while loop is useful. The following example illustrates a while loop : n = 5 while n > 0: print(n) n = n - 1 5 4 3 2 1 The main points to observe are: while keyword a logical expression followed by a colon : loop executes its code block if the logical expression evaluates to True update the variable in the logical expression each time through the loop BEWARE! If the logical expression always evaluates to True , then you get an infinite loop ! We prefer for loops over while loops because of the last point. A for loop will never result in an infinite loop. If a loop can be constructed with for or while , we'll always choose for .","title":"while Loops"},{"location":"python/loops/#constructing-sequences","text":"There are several ways to construct a sequence of values and to save them as a Python list. We have already seen Python's list comprehension syntax. There is also the append list method described below.","title":"Constructing Sequences"},{"location":"python/loops/#sequences-by-a-formula","text":"If a sequence is given by a formula then we can use a list comprehension to construct it. For example, the sequence of squares from 1 to 100 can be constructed using a list comprehension: squares = [d**2 for d in range(1,11)] print(squares) [1, 4, 9, 16, 25, 36, 49, 64, 81, 100] However, we can achieve the same result with a for loop and the append method for lists: # Intialize an empty list squares = [] for d in range(1,11): # Append the next square to the list squares.append(d**2) print(squares) [1, 4, 9, 16, 25, 36, 49, 64, 81, 100] In fact, the two examples above are equivalent. The purpose of list comprehensions is to simplify and compress the syntax into a one-line construction.","title":"Sequences by a Formula"},{"location":"python/loops/#recursive-sequences","text":"We can only use a list comprehension to construct a sequence when the sequence values are defined by a formula. But what if we want to construct a sequence where the next value depends on previous values? This is called a recursive sequence . For example, consider the Fibonacci sequence : x_1 = 1, x_2 = 1, x_3 = 2, x_4 = 3, x_5 = 5, ... x_1 = 1, x_2 = 1, x_3 = 2, x_4 = 3, x_5 = 5, ... where x_{n} = x_{n-1} + x_{n-2} x_{n} = x_{n-1} + x_{n-2} We can't use a list comprehension to build the list of Fibonacci numbers, and so we must use a for loop with the append method instead. For example, the first 15 Fibonacci numbers are: fibonacci_numbers = [1,1] for n in range(2,15): fibonacci_n = fibonacci_numbers[n-1] + fibonacci_numbers[n-2] fibonacci_numbers.append(fibonacci_n) print(fibonacci_numbers) [1, 1, 2] [1, 1, 2, 3] [1, 1, 2, 3, 5] [1, 1, 2, 3, 5, 8] [1, 1, 2, 3, 5, 8, 13] [1, 1, 2, 3, 5, 8, 13, 21] [1, 1, 2, 3, 5, 8, 13, 21, 34] [1, 1, 2, 3, 5, 8, 13, 21, 34, 55] [1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89] [1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144] [1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233] [1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377] [1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610]","title":"Recursive Sequences"},{"location":"python/loops/#computing-sums","text":"Suppose we want to compute the sum of a sequence of numbers x_0 x_0 , x_1 x_1 , x_2 x_2 , x_3 x_3 , \\dots \\dots , x_n x_n . There are at least two approaches: Compute the entire sequence, store it as a list [x_0,x_1,x_2,\\dots,x_n] [x_0,x_1,x_2,\\dots,x_n] and then use the built-in function sum . Initialize a variable with value 0 (and name it result for example), create and add each element in the sequence to result one at a time. The advantage of the second approach is that we don't need to store all the values at once. For example, here are two ways to write a function which computes the sum of squares. For the first approach, use a list comprehension: def sum_of_squares_1(N): \"Compute the sum of squares 1**2 + 2**2 + ... + N**2.\" return sum([n**2 for n in range(1,N + 1)]) sum_of_squares_1(4) 30 For the second approach, use a for loop with the initialize-and-update construction: def sum_of_squares_2(N): \"Compute the sum of squares 1**2 + 2**2 + ... + N**2.\" # Initialize the output value to 0 result = 0 for n in range(1,N + 1): # Update the result by adding the next term result = result + n**2 return result sum_of_squares_2(4) 30 Again, both methods yield the same result however the second uses less memory!","title":"Computing Sums"},{"location":"python/loops/#computing-products","text":"There is no built-in function to compute products of sequences therefore we'll use an initialize-and-update construction similar to the example above for computing sums. Write a function called factorial which takes a positive integer N N and return the factorial N! N! . def factorial(N): \"Compute N! = N(N-1) ... (2)(1) for N >= 1.\" # Initialize the output variable to 1 product = 1 for n in range(2,N + 1): # Update the output variable product = product * n return product Let's test our function for input values for which we know the result: factorial(2) 2 factorial(5) 120 We can use our function to approximate e e using the Taylor series for e^x e^x : e^x = \\sum_{k=0}^{\\infty} \\frac{x^k}{k!} e^x = \\sum_{k=0}^{\\infty} \\frac{x^k}{k!} For example, let's compute the 100th partial sum of the series with x=1 x=1 : sum([1/factorial(k) for k in range(0,101)]) 2.7182818284590455","title":"Computing Products"},{"location":"python/loops/#searching-for-solutions","text":"We can use for loops to search for integer solutions of equations. For example, suppose we would like to find all representations of a positive integer N N as a sum of two squares . In other words, we want to find all integer solutions (x,y) (x,y) of the equation: x^2 + y^2 = N x^2 + y^2 = N Write a function called reps_sum_squares which takes an integer N N and finds all representations of N N as a sum of squares x^2 + y^2 = N x^2 + y^2 = N for 0 \\leq x \\leq y 0 \\leq x \\leq y . The function returns the representations as a list of tuples. For example, if N = 50 N = 50 then 1^2 + 7^2 = 50 1^2 + 7^2 = 50 and 5^2 + 5^2 = 50 5^2 + 5^2 = 50 and the function returns the list [(1, 7),(5, 5)] . Let's outline our approach before we write any code: Given x \\leq y x \\leq y , the largest possible value for x x is \\sqrt{\\frac{N}{2}} \\sqrt{\\frac{N}{2}} For x \\leq \\sqrt{\\frac{N}{2}} x \\leq \\sqrt{\\frac{N}{2}} , the pair (x,y) (x,y) is a solution if N - x^2 N - x^2 is a square Define a helper function called is_square to test if an integer is square def is_square(n): \"Determine if the integer n is a square.\" if round(n**0.5)**2 == n: return True else: return False def reps_sum_squares(N): '''Find all representations of N as a sum of squares x**2 + y**2 = N. Parameters ---------- N : integer Returns ------- reps : list of tuples of integers List of tuples (x,y) of positive integers such that x**2 + y**2 = N. Examples -------- >>> reps_sum_squares(1105) [(4, 33), (9, 32), (12, 31), (23, 24)] ''' reps = [] if is_square(N/2): # If N/2 is a square, search up to x = (N/2)**0.5 max_x = round((N/2)**0.5) else: # If N/2 is not a square, search up to x = floor((N/2)**0.5) max_x = int((N/2)**0.5) for x in range(0,max_x + 1): y_squared = N - x**2 if is_square(y_squared): y = round(y_squared**0.5) # Append solution (x,y) to list of solutions reps.append((x,y)) return reps reps_sum_squares(1105) [(4, 33), (9, 32), (12, 31), (23, 24)] What is the smallest integer which can be expressed as the sum of squares in 5 different ways? N = 1105 num_reps = 4 while num_reps < 5: N = N + 1 reps = reps_sum_squares(N) num_reps = len(reps) print(N,':',reps_sum_squares(N)) 4225 : [(0, 65), (16, 63), (25, 60), (33, 56), (39, 52)]","title":"Searching for Solutions"},{"location":"python/loops/#examples","text":"","title":"Examples"},{"location":"python/loops/#prime-numbers","text":"A positive integer is prime if it is divisible only by 1 and itself. Write a function called is_prime which takes an input parameter n and returns True or False depending on whether n is prime or not. Let's outline our approach before we write any code: An integer d d divides n n if there is no remainder of n n divided by d d . Use the modulus operator % to compute the remainder. If d d divides n n then n = d q n = d q for some integer q q and either d \\leq \\sqrt{n} d \\leq \\sqrt{n} or q \\leq \\sqrt{n} q \\leq \\sqrt{n} (and not both), therefore we need only test if d d divides n n for integers d \\leq \\sqrt{n} d \\leq \\sqrt{n} def is_prime(n): \"Determine whether or not n is a prime number.\" if n <= 1: return False # Test if d divides n for d <= n**0.5 for d in range(2,round(n**0.5) + 1): if n % d == 0: # n is divisible by d and so n is not prime return False # If we exit the for loop, then n is not divisible by any d # and therefore n is prime return True Let's test our function on the first 30 numbers: for n in range(0,31): if is_prime(n): print(n,'is prime!') 2 is prime! 3 is prime! 5 is prime! 7 is prime! 11 is prime! 13 is prime! 17 is prime! 19 is prime! 23 is prime! 29 is prime! Our function works! Let's find all the primes between 20,000 and 20,100. for n in range(20000,20100): if is_prime(n): print(n,'is prime!') 20011 is prime! 20021 is prime! 20023 is prime! 20029 is prime! 20047 is prime! 20051 is prime! 20063 is prime! 20071 is prime! 20089 is prime!","title":"Prime Numbers"},{"location":"python/loops/#divisors","text":"Let's write a function called divisors which takes a positive integer N N and returns the list of positive integers which divide N N . def divisors(N): \"Return the list of divisors of N.\" # Initialize the list of divisors (which always includes 1) divisor_list = [1] # Check division by d for d <= N/2 for d in range(2,N // 2 + 1): if N % d == 0: divisor_list.append(d) # N divides itself and so we append N to the list of divisors divisor_list.append(N) return divisor_list Let's test our function: divisors(10) [1, 2, 5, 10] divisors(100) [1, 2, 4, 5, 10, 20, 25, 50, 100] divisors(59) [1, 59]","title":"Divisors"},{"location":"python/loops/#collatz-conjecture","text":"Let a a be a positive integer and consider the recursive sequence where x_0 = a x_0 = a and x_{n+1} = \\left\\\\{ \\begin{array}{cl} x_n/2 & \\text{if } x_n \\text{ is even} \\\\\\\\ 3x_n+1 & \\text{if } x_n \\text{ is odd} \\end{array} \\\\right. x_{n+1} = \\left\\\\{ \\begin{array}{cl} x_n/2 & \\text{if } x_n \\text{ is even} \\\\\\\\ 3x_n+1 & \\text{if } x_n \\text{ is odd} \\end{array} \\\\right. The Collatz conjecture states that this sequence will always reach 1. For example, if a = 10 a = 10 then x_0 = 10 x_0 = 10 , x_1 = 5 x_1 = 5 , x_2 = 16 x_2 = 16 , x_3 = 8 x_3 = 8 , x_4 = 4 x_4 = 4 , x_5 = 2 x_5 = 2 and x_6 = 1 x_6 = 1 . Write a function called collatz which takes one input parameter a and returns the sequence of integers defined above and ending with the first occurrence x_n=1 x_n=1 . def collatz(a): \"Compute the Collatz sequence starting at a and ending at 1.\" # Initialize list with first value a sequence = [a] # Compute values until we reach 1 while sequence[-1] > 1: # Check if the last element in the list is even if sequence[-1] % 2 == 0: # Compute and append the new value sequence.append(sequence[-1] // 2) else: # Compute and append the new value sequence.append(3*sequence[-1] + 1) return sequence Let's test our function: print(collatz(10)) [10, 5, 16, 8, 4, 2, 1] collatz(22) [22, 11, 34, 17, 52, 26, 13, 40, 20, 10, 5, 16, 8, 4, 2, 1] The Collatz conjecture is quite amazing. No matter where we start, the sequence always terminates at 1! a = 123456789 seq = collatz(a) print(\"Collatz sequence for a =\",a) print(\"begins with\",seq[:5]) print(\"ends with\",seq[-5:]) print(\"and has\",len(seq),\"terms.\") Collatz sequence for a = 123456789 begins with [123456789, 370370368, 185185184, 92592592, 46296296] ends with [16, 8, 4, 2, 1] and has 178 terms. Which a < 1000 a < 1000 produces the longest sequence? max_length = 1 a_max = 1 for a in range(1,1001): seq_length = len(collatz(a)) if seq_length > max_length: max_length = seq_length a_max = a print('Longest sequence begins with a =',a_max,'and has length',max_length) Longest sequence begins with a = 871 and has length 179","title":"Collatz Conjecture"},{"location":"python/loops/#exercises","text":"Fermat's theorem on the sum of two squares states that every prime number p p of the form 4k+1 4k+1 can be expressed as the sum of two squares. For example, 5 = 2^2 + 1^2 5 = 2^2 + 1^2 and 13 = 3^2 + 2^2 13 = 3^2 + 2^2 . Find the smallest prime greater than 2019 2019 of the form 4k+1 4k+1 and write it as a sum of squares. (Hint: Use the functions is_prime and reps_sum_squares from this section.) What is the smallest prime number which can be represented as a sum of squares in 2 different ways? What is the smallest integer which can be represented as a sum of squares in 3 different ways? Write a function called primes_between which takes two integer inputs a a and b b and returns the list of primes in the closed interval [a,b] [a,b] . Write a function called primes_d_mod_N which takes four integer inputs a a , b b , d d and N N and returns the list of primes in the closed interval [a,b] [a,b] which are congruent to d d mod N N (this means that the prime has remainder d d after division by N N ). This kind of list is called primes in an arithmetic progression . Write a function called reciprocal_recursion which takes three positive integers x_0 x_0 , x_1 x_1 and N N and returns the sequence [x_0,x_1,x_2,\\dots,x_N] [x_0,x_1,x_2,\\dots,x_N] where x_n = \\frac{1}{x_{n-1}} + \\frac{1}{x_{n-2}} x_n = \\frac{1}{x_{n-1}} + \\frac{1}{x_{n-2}} Write a function called root_sequence which takes input parameters a a and N N , both positive integers, and returns the N N th term x_N x_N in the sequence: \\begin{align} x_0 &= a \\\\\\ x_n &= 1 + \\sqrt{x_{n-1}} \\end{align} \\begin{align} x_0 &= a \\\\\\ x_n &= 1 + \\sqrt{x_{n-1}} \\end{align} Does the sequence converge to different values for different starting values a a ? Write a function called fib_less_than which takes one input N N and returns the list of Fibonacci numbers less than N N . Write a function called fibonacci_primes which takes an input parameter N N and returns the list of Fibonacci numbers less than N N which are also prime numbers. Let w(N) w(N) be the number of ways N N can be expressed as a sum of two squares x^2 + y^2 = N x^2 + y^2 = N with 1 \\leq x \\leq y 1 \\leq x \\leq y . Then \\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n=1}^{N} w(n) = \\frac{\\pi}{8} \\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n=1}^{N} w(n) = \\frac{\\pi}{8} Compute the left side of the formula for N=100 N=100 and compare the result to \\pi / 8 \\pi / 8 . A list of positive integers [a,b,c] [a,b,c] (with 1 \\leq a < b 1 \\leq a < b ) are a Pythagorean triple if a^2 + b^2 = c^2 a^2 + b^2 = c^2 . Write a function called py_triples which takes an input parameter N N and returns the list of Pythagorean triples [a,b,c] with c \\leq N c \\leq N .","title":"Exercises"},{"location":"python/modules-packages/","text":"Modules and Packages Under construction","title":"Modules and Packages"},{"location":"python/modules-packages/#modules-and-packages","text":"Under construction","title":"Modules and Packages"},{"location":"python/numbers/","text":"Numbers The main numeric types in Python are integers, floating point numbers and complex numbers. The syntax for arithmetic operators are: addition + , subtraction - , multiplication * , division / and exponentiation ** . Integers Add integers: 8 + 12 20 Subtract integers: 2019 - 21 1998 Multiply integers: 45 * 11 495 Divide integers (and notice that division of integers always returns a float): 100 / 4 25.0 Compute powers of integers: 2**10 1024 Use the built-in function type() to verify the type of a Python object: type(42) int Floating Point Numbers A floating point number (or float) is a real number written in decimal form. Python stores floats and integers in different ways and if we combine integers and floats using arithmetic operations the result is always a float. Approximate \\sqrt{2} \\, \\sqrt{2} \\, : 2**0.5 1.4142135623730951 Approximate 2 \\pi 2 \\pi : 2 * 3.14159 6.28318 Use scientific notation to create 0.00001 0.00001 : 1e-5 1e-05 Again, use the type() function to verify the type of a number: type(42) int type(42.0) float Complex Numbers Use the built-in function complex() to create a complex number in Python or use the letter j for j = \\sqrt{-1} j = \\sqrt{-1} . The built-in function complex() takes 2 parameters defining the real and imaginary part of the complex number. Create the complex number 1 + j 1 + j : complex(1,1) (1+1j) Add complex numbers: (1 + 2j) + (2 - 3j) (3-1j) Multiply complex numbers: (2 - 1j) * (5 + 2j) (12-1j) Use the type() function to verify the type of a number: type(2 - 7j) complex Arithmetic Operators The syntax for arithmetic operators in Python are: Operator Description + addition - subtraction * multiplication / division ** exponentiation % remainder (or modulo) // integer division Notice that division of integers always returns a float: 4 / 3 1.3333333333333333 Even if the mathematical result is an integer: 4 / 2 2.0 Use parentheses to group combinations of arithmetic operations: 5 * (4 + 3) - 2 33 An integer power of an integer is again an integer: 2**4 16 An exponent involving a float is a float: 9**0.5 3.0 The remainder operator computes the remainder of division of integers: 11 % 4 3 Integer division is: 11 // 4 2 Examples Taylor Approximation The Taylor series of the exponential function e^x e^x is given by e^x = \\sum_{k=0}^{\\infty} \\frac{x^k}{k!} e^x = \\sum_{k=0}^{\\infty} \\frac{x^k}{k!} Compute the Taylor polynomial of degree 5 evaluated at x = 1 x = 1 to find an approximation of e e e \\approx \\frac{1}{0!} + \\frac{1}{1!} + \\frac{1}{2!} + \\frac{1}{3!} + \\frac{1}{4!} + \\frac{1}{5!} e \\approx \\frac{1}{0!} + \\frac{1}{1!} + \\frac{1}{2!} + \\frac{1}{3!} + \\frac{1}{4!} + \\frac{1}{5!} 1 + 1 + 1/2 + 1/(3*2) + 1/(4*3*2) + 1/(5*4*3*2) 2.7166666666666663 Ramanujan's \\pi \\pi Formula Srinivasa Ramanujan discovered the following beautiful (and very rapidly converging) series representation of \\pi \\pi \\frac{1}{\\pi} = \\frac{2 \\sqrt{2}}{99^2} \\sum_{k = 0}^{\\infty} \\frac{(4k)!}{k!^4} \\frac{1103 + 26390k}{396^{4k}} \\frac{1}{\\pi} = \\frac{2 \\sqrt{2}}{99^2} \\sum_{k = 0}^{\\infty} \\frac{(4k)!}{k!^4} \\frac{1103 + 26390k}{396^{4k}} Let's find an approximation of \\pi \\pi by computing the reciprocal of the sum of the first 3 terms of the series: \\pi \\approx \\frac{99^2}{2 \\sqrt{2}} \\frac{1}{\\left( 1103 + 4! \\frac{1103 + 26390}{396^{4}} + \\frac{8!}{2^4} \\frac{1103 + 26390(2)}{396^{8}} \\right)} \\pi \\approx \\frac{99^2}{2 \\sqrt{2}} \\frac{1}{\\left( 1103 + 4! \\frac{1103 + 26390}{396^{4}} + \\frac{8!}{2^4} \\frac{1103 + 26390(2)}{396^{8}} \\right)} 99**2 / (2 * 2**0.5) / (1103 + 4*3*2 * (26390 + 1103) / 396**4 + 8*7*6*5*4*3*2 / 2**4 * (26390*2 + 1103) / 396**8) 3.141592653589793 These are exactly the first 16 digits of \\pi \\pi . Exercises The Taylor series of \\cos x \\cos x is given by \\cos x = \\sum_{k=0}^{\\infty} (-1)^k \\frac{x^{2k}}{(2k)!} \\cos x = \\sum_{k=0}^{\\infty} (-1)^k \\frac{x^{2k}}{(2k)!} Compute the Taylor polynomial of degree 6 evaluated at x=2 x=2 : \\cos(2) \\approx 1 - \\frac{2^2}{2!} + \\frac{2^4}{4!} - \\frac{2^6}{6!} \\cos(2) \\approx 1 - \\frac{2^2}{2!} + \\frac{2^4}{4!} - \\frac{2^6}{6!} The Riemann zeta function is the infinite series \\zeta(s) = \\sum_{n=1}^{\\infty} \\frac{1}{n^s} \\zeta(s) = \\sum_{n=1}^{\\infty} \\frac{1}{n^s} and is intimately related to prime numbers by the Euler product formula \\sum_{n=1}^{\\infty} \\frac{1}{n^s} = \\prod_p \\left( \\frac{1}{1 - p^{-s}} \\right) \\sum_{n=1}^{\\infty} \\frac{1}{n^s} = \\prod_p \\left( \\frac{1}{1 - p^{-s}} \\right) where the product is over all primes p = 2,3,5,7,11,13,\\dots p = 2,3,5,7,11,13,\\dots Compute the 5th partial sum for s=2 s=2 1 + \\frac{1}{2^2} + \\frac{1}{3^2} + \\frac{1}{4^2} + \\frac{1}{5^2} 1 + \\frac{1}{2^2} + \\frac{1}{3^2} + \\frac{1}{4^2} + \\frac{1}{5^2} Compute the 5th partial product for s=2 s=2 \\left( \\frac{1}{1 - 2^{-2}} \\right) \\left( \\frac{1}{1 - 3^{-2}} \\right) \\left( \\frac{1}{1 - 5^{-2}} \\right) \\left( \\frac{1}{1 - 7^{-2}} \\right) \\left( \\frac{1}{1 - 11^{-2}} \\right) \\left( \\frac{1}{1 - 2^{-2}} \\right) \\left( \\frac{1}{1 - 3^{-2}} \\right) \\left( \\frac{1}{1 - 5^{-2}} \\right) \\left( \\frac{1}{1 - 7^{-2}} \\right) \\left( \\frac{1}{1 - 11^{-2}} \\right) Given Euler's special value formula \\zeta(2) = \\frac{\\pi^2}{6} \\zeta(2) = \\frac{\\pi^2}{6} which converges more quickly: the infinite series or product? The continued fraction for \\sqrt{2} \\sqrt{2} is given by \\sqrt{2} = 1 + \\frac{1}{2 + \\frac{1}{2 + \\frac{1}{2 + \\frac{1}{2 + \\ddots}}}} \\sqrt{2} = 1 + \\frac{1}{2 + \\frac{1}{2 + \\frac{1}{2 + \\frac{1}{2 + \\ddots}}}} Compute the following (partial) continued fraction to approximate \\sqrt{2} \\sqrt{2} \\sqrt{2} \\approx 1 + \\frac{1}{2 + \\frac{1}{2 + \\frac{1}{2 + \\frac{1}{2}}}} \\sqrt{2} \\approx 1 + \\frac{1}{2 + \\frac{1}{2 + \\frac{1}{2 + \\frac{1}{2}}}}","title":"Numbers"},{"location":"python/numbers/#numbers","text":"The main numeric types in Python are integers, floating point numbers and complex numbers. The syntax for arithmetic operators are: addition + , subtraction - , multiplication * , division / and exponentiation ** .","title":"Numbers"},{"location":"python/numbers/#integers","text":"Add integers: 8 + 12 20 Subtract integers: 2019 - 21 1998 Multiply integers: 45 * 11 495 Divide integers (and notice that division of integers always returns a float): 100 / 4 25.0 Compute powers of integers: 2**10 1024 Use the built-in function type() to verify the type of a Python object: type(42) int","title":"Integers"},{"location":"python/numbers/#floating-point-numbers","text":"A floating point number (or float) is a real number written in decimal form. Python stores floats and integers in different ways and if we combine integers and floats using arithmetic operations the result is always a float. Approximate \\sqrt{2} \\, \\sqrt{2} \\, : 2**0.5 1.4142135623730951 Approximate 2 \\pi 2 \\pi : 2 * 3.14159 6.28318 Use scientific notation to create 0.00001 0.00001 : 1e-5 1e-05 Again, use the type() function to verify the type of a number: type(42) int type(42.0) float","title":"Floating Point Numbers"},{"location":"python/numbers/#complex-numbers","text":"Use the built-in function complex() to create a complex number in Python or use the letter j for j = \\sqrt{-1} j = \\sqrt{-1} . The built-in function complex() takes 2 parameters defining the real and imaginary part of the complex number. Create the complex number 1 + j 1 + j : complex(1,1) (1+1j) Add complex numbers: (1 + 2j) + (2 - 3j) (3-1j) Multiply complex numbers: (2 - 1j) * (5 + 2j) (12-1j) Use the type() function to verify the type of a number: type(2 - 7j) complex","title":"Complex Numbers"},{"location":"python/numbers/#arithmetic-operators","text":"The syntax for arithmetic operators in Python are: Operator Description + addition - subtraction * multiplication / division ** exponentiation % remainder (or modulo) // integer division Notice that division of integers always returns a float: 4 / 3 1.3333333333333333 Even if the mathematical result is an integer: 4 / 2 2.0 Use parentheses to group combinations of arithmetic operations: 5 * (4 + 3) - 2 33 An integer power of an integer is again an integer: 2**4 16 An exponent involving a float is a float: 9**0.5 3.0 The remainder operator computes the remainder of division of integers: 11 % 4 3 Integer division is: 11 // 4 2","title":"Arithmetic Operators"},{"location":"python/numbers/#examples","text":"","title":"Examples"},{"location":"python/numbers/#taylor-approximation","text":"The Taylor series of the exponential function e^x e^x is given by e^x = \\sum_{k=0}^{\\infty} \\frac{x^k}{k!} e^x = \\sum_{k=0}^{\\infty} \\frac{x^k}{k!} Compute the Taylor polynomial of degree 5 evaluated at x = 1 x = 1 to find an approximation of e e e \\approx \\frac{1}{0!} + \\frac{1}{1!} + \\frac{1}{2!} + \\frac{1}{3!} + \\frac{1}{4!} + \\frac{1}{5!} e \\approx \\frac{1}{0!} + \\frac{1}{1!} + \\frac{1}{2!} + \\frac{1}{3!} + \\frac{1}{4!} + \\frac{1}{5!} 1 + 1 + 1/2 + 1/(3*2) + 1/(4*3*2) + 1/(5*4*3*2) 2.7166666666666663","title":"Taylor Approximation"},{"location":"python/numbers/#ramanujans-pipi-formula","text":"Srinivasa Ramanujan discovered the following beautiful (and very rapidly converging) series representation of \\pi \\pi \\frac{1}{\\pi} = \\frac{2 \\sqrt{2}}{99^2} \\sum_{k = 0}^{\\infty} \\frac{(4k)!}{k!^4} \\frac{1103 + 26390k}{396^{4k}} \\frac{1}{\\pi} = \\frac{2 \\sqrt{2}}{99^2} \\sum_{k = 0}^{\\infty} \\frac{(4k)!}{k!^4} \\frac{1103 + 26390k}{396^{4k}} Let's find an approximation of \\pi \\pi by computing the reciprocal of the sum of the first 3 terms of the series: \\pi \\approx \\frac{99^2}{2 \\sqrt{2}} \\frac{1}{\\left( 1103 + 4! \\frac{1103 + 26390}{396^{4}} + \\frac{8!}{2^4} \\frac{1103 + 26390(2)}{396^{8}} \\right)} \\pi \\approx \\frac{99^2}{2 \\sqrt{2}} \\frac{1}{\\left( 1103 + 4! \\frac{1103 + 26390}{396^{4}} + \\frac{8!}{2^4} \\frac{1103 + 26390(2)}{396^{8}} \\right)} 99**2 / (2 * 2**0.5) / (1103 + 4*3*2 * (26390 + 1103) / 396**4 + 8*7*6*5*4*3*2 / 2**4 * (26390*2 + 1103) / 396**8) 3.141592653589793 These are exactly the first 16 digits of \\pi \\pi .","title":"Ramanujan's \\pi\\pi Formula"},{"location":"python/numbers/#exercises","text":"The Taylor series of \\cos x \\cos x is given by \\cos x = \\sum_{k=0}^{\\infty} (-1)^k \\frac{x^{2k}}{(2k)!} \\cos x = \\sum_{k=0}^{\\infty} (-1)^k \\frac{x^{2k}}{(2k)!} Compute the Taylor polynomial of degree 6 evaluated at x=2 x=2 : \\cos(2) \\approx 1 - \\frac{2^2}{2!} + \\frac{2^4}{4!} - \\frac{2^6}{6!} \\cos(2) \\approx 1 - \\frac{2^2}{2!} + \\frac{2^4}{4!} - \\frac{2^6}{6!} The Riemann zeta function is the infinite series \\zeta(s) = \\sum_{n=1}^{\\infty} \\frac{1}{n^s} \\zeta(s) = \\sum_{n=1}^{\\infty} \\frac{1}{n^s} and is intimately related to prime numbers by the Euler product formula \\sum_{n=1}^{\\infty} \\frac{1}{n^s} = \\prod_p \\left( \\frac{1}{1 - p^{-s}} \\right) \\sum_{n=1}^{\\infty} \\frac{1}{n^s} = \\prod_p \\left( \\frac{1}{1 - p^{-s}} \\right) where the product is over all primes p = 2,3,5,7,11,13,\\dots p = 2,3,5,7,11,13,\\dots Compute the 5th partial sum for s=2 s=2 1 + \\frac{1}{2^2} + \\frac{1}{3^2} + \\frac{1}{4^2} + \\frac{1}{5^2} 1 + \\frac{1}{2^2} + \\frac{1}{3^2} + \\frac{1}{4^2} + \\frac{1}{5^2} Compute the 5th partial product for s=2 s=2 \\left( \\frac{1}{1 - 2^{-2}} \\right) \\left( \\frac{1}{1 - 3^{-2}} \\right) \\left( \\frac{1}{1 - 5^{-2}} \\right) \\left( \\frac{1}{1 - 7^{-2}} \\right) \\left( \\frac{1}{1 - 11^{-2}} \\right) \\left( \\frac{1}{1 - 2^{-2}} \\right) \\left( \\frac{1}{1 - 3^{-2}} \\right) \\left( \\frac{1}{1 - 5^{-2}} \\right) \\left( \\frac{1}{1 - 7^{-2}} \\right) \\left( \\frac{1}{1 - 11^{-2}} \\right) Given Euler's special value formula \\zeta(2) = \\frac{\\pi^2}{6} \\zeta(2) = \\frac{\\pi^2}{6} which converges more quickly: the infinite series or product? The continued fraction for \\sqrt{2} \\sqrt{2} is given by \\sqrt{2} = 1 + \\frac{1}{2 + \\frac{1}{2 + \\frac{1}{2 + \\frac{1}{2 + \\ddots}}}} \\sqrt{2} = 1 + \\frac{1}{2 + \\frac{1}{2 + \\frac{1}{2 + \\frac{1}{2 + \\ddots}}}} Compute the following (partial) continued fraction to approximate \\sqrt{2} \\sqrt{2} \\sqrt{2} \\approx 1 + \\frac{1}{2 + \\frac{1}{2 + \\frac{1}{2 + \\frac{1}{2}}}} \\sqrt{2} \\approx 1 + \\frac{1}{2 + \\frac{1}{2 + \\frac{1}{2 + \\frac{1}{2}}}}","title":"Exercises"},{"location":"python/sequences/","text":"Sequences The main sequence types in Python are lists, tuples and range objects. The main differences between these sequence objects are: Lists are mutable and their elements are usually homogeneous (things of the same type making a list of similar objects) Tuples are immutable and their elements are usually heterogeneous (things of different types making a tuple describing a single structure) Range objects are efficient sequences of integers (commonly used in for loops), use a small amount of memory and yield items only when needed Lists Create a list using square brackets [ ... ] with items separated by commas. For example, create a list of square integers, assign it to a variable and use the built-in function print() to display the list: squares = [1,4,9,16,25] print(squares) [1, 4, 9, 16, 25] Lists may contain data of any type including other lists: points = [[0,0],[0,1],[1,1],[0,1]] print(points) [[0, 0], [0, 1], [1, 1], [0, 1]] Index Access the elements of a list by their index: primes = [2,3,5,7,11,13,17,19,23,29] print(primes[0]) 2 Notice that lists are indexed starting at 0: print(primes[1]) print(primes[2]) print(primes[6]) 3 5 17 Use negative indices to access elements starting from the end of the list: print(primes[-1]) print(primes[-2]) 29 23 Since lists are mutable, we may assign new values to entries in a list: primes[0] = -1 print(primes) [-1, 3, 5, 7, 11, 13, 17, 19, 23, 29] Use multiple indices to access entries in a list of lists: pairs = [[0,1],[2,3],[4,5],[6,7]] print(pairs[2][1]) 5 Slice Create a new list from a sublist (called a slice): fibonacci = [1,1,2,3,5,8,13,21,34,55,89,144] print(fibonacci[4:7]) print(fibonacci[6:]) print(fibonacci[:-2]) [5, 8, 13] [13, 21, 34, 55, 89, 144] [1, 1, 2, 3, 5, 8, 13, 21, 34, 55] Notice in the example fibonacci[4:7] the slice begins at index 4 and goes up to but not including index 7. This makes sense since the length of the slice is then 7 - 4 = 3. A slice can skip over entries in a list. For example, create a slice from every third entry from index 0 to 11: print(fibonacci[0:11:3]) [1, 3, 13, 55] Concatenate The addition operator + concatenates lists: one = [1] two = [2,2] three = [3,3,3] numbers = one + two + three print(numbers) [1, 2, 2, 3, 3, 3] Append Add a value to the end of a list using the append() list method: squares = [1,4,9,16,25] squares.append(36) print(squares) [1, 4, 9, 16, 25, 36] What is an object method? First, an object in Python (such as a list) contains data as well as functions (called methods) to manipulate that data. Everything in Python is an object! The list squares in the cell above contains the integer entries (the data) but it also has methods like append() to manipulate the data. We'll see more about objects and methods later on. For now, see the documentation for a complete list of list methods . Tuples Create a tuple with parentheses ( ... ) : today = (2019,7,11) print(today) (2019, 7, 11) Indexing, slicing and concatenating work for tuples in the exact same way as for lists: print(today[0]) print(today[-1]) print(today[1:3]) 2019 11 (7, 11) Range Objects Create a range object with the built-in function range() . The parameters a , b and step in range(a,b,step) are integers and the function creates an object which represents the sequence of integers from a to b (exclusively) incremented by step . (The parameter step may be omitted and is equal to 1 by default.) digits_range = range(0,10) print(digits_range) range(0, 10) Notice that a range object does not display the values of its entries when printed. This is because a range object is an efficient sequence which yields values only when needed. Use the built-in function list() to convert a range object to a list: digits_range = range(0,10) digits_list = list(digits_range) print(digits_list) [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] Create a range of even integers and convert it to a list: even_list = list(range(0,10,2)) print(even_list) [0, 2, 4, 6, 8] Unpacking a Sequence One of the features of a Python sequence is unpacking where we assign all the entries of a sequence to variables in a single operation. For example, create a tuple representing a date and unpack the data as year , month and and day : today = (2019,7,11) year, month, day = today print(year) print(month) print(day) 2019 7 11 List Comprehensions The built-in function range() is an efficient tool for creating sequences of integers but what about an arbitrary sequence? It is very inefficient to create a sequence by manually typing the numbers. For example, simply typing out the numbers from 1 to 20 takes a long time! numbers = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20] print(numbers) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20] Python has a beautiful syntax for creating lists called list comprehensions . The syntax is: [expression for item in iterable] where: iterable is a range, list, tuple, or any kind of sequence object item is a variable name which takes each value in the iterable expression is a Python expression which is calculated for each value of item Use a list comprehension to create the list from 1 to 20: numbers = [n for n in range(1,21)] print(numbers) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20] Create the list of square integers from 1 1 to 100 100 : squares = [n**2 for n in range(1,11)] print(squares) [1, 4, 9, 16, 25, 36, 49, 64, 81, 100] Create the periodic sequence 0,1,2,0,1,2,0,1,2,\\dots 0,1,2,0,1,2,0,1,2,\\dots of length 21 (using the remainder operator % ): zero_one_two = [n%3 for n in range(0,21)] print(zero_one_two) [0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2] Built-in Functions for Sequences Python has several built-in functions for computing with sequences. For example, compute the length of a list: len([1,2,3]) 3 Compute the sum, maximum and minimum of a list of numbers: random = [3,-5,7,8,-1] print(sum(random)) print(max(random)) print(min(random)) 12 8 -5 Sort the list: sorted(random) [-5, -1, 3, 7, 8] Sum the numbers from 1 to 100: one_to_hundred = range(1,101) print(sum(one_to_hundred)) 5050 Examples Triangular Numbers The formula for the sum of integers from 1 to N N (also known as triangular numbers ) is given by: \\sum_{k=1}^N k = \\frac{N(N+1)}{2} \\sum_{k=1}^N k = \\frac{N(N+1)}{2} Let's verify the formula for N=1000 N=1000 : N = 1000 left_side = sum([k for k in range(1,N+1)]) right_side = N*(N+1)/2 print(left_side) print(right_side) 500500 500500.0 Notice the results agree (although the right side is a float since we used division). Sum of Squares The sum of squares (a special case of a geometric series ) is given by the formula: \\sum_{k=1}^N k^2 = \\frac{N(N+1)(2N+1)}{6} \\sum_{k=1}^N k^2 = \\frac{N(N+1)(2N+1)}{6} Let's verify the formula for N=2000 N=2000 : N = 2000 left_side = sum([k**2 for k in range(1,N+1)]) right_side = N*(N+1)*(2*N+1)/6 print(left_side) print(right_side) 2668667000 2668667000.0 Riemann Zeta Function The Riemann zeta function is the infinite series \\zeta(s) = \\sum_{n=1}^{\\infty} \\frac{1}{n^s} \\zeta(s) = \\sum_{n=1}^{\\infty} \\frac{1}{n^s} Its values are very mysterious! Let's verify the special value formula \\zeta(4) = \\sum_{n=1}^{\\infty} \\frac{1}{n^4} = \\frac{\\pi^4}{90} \\zeta(4) = \\sum_{n=1}^{\\infty} \\frac{1}{n^4} = \\frac{\\pi^4}{90} Compute the 1000th partial sum of the series: terms = [1/n**4 for n in range(1,1001)] sum(terms) 1.082323233378306 Compare to an approximation of \\frac{\\pi^4}{90} \\frac{\\pi^4}{90} : 3.14159**4/90 1.082319576918468 Exercises The Maclaurin series of \\arctan(x) \\arctan(x) is \\arctan(x) = \\sum_{n = 0}^{\\infty} \\frac{(-1)^nx^{2n + 1}}{2n+1} \\arctan(x) = \\sum_{n = 0}^{\\infty} \\frac{(-1)^nx^{2n + 1}}{2n+1} Substituting x = 1 x = 1 gives a series representation of \\pi/4 \\pi/4 . Compute the 5000th partial sum of the series to approximate \\pi/4 \\pi/4 . Compute the 2000th partial sum of the alternating harmonic series : \\sum_{n=1}^{\\infty}\\frac{(-1)^n}{n} \\sum_{n=1}^{\\infty}\\frac{(-1)^n}{n} Write a list comprehension to create the list of lists: [[0, 0], [1, 1], [2, 4], [3, 9], [4, 16], [5, 25], [6, 36], [7, 49]] [[0, 0], [1, 1], [2, 4], [3, 9], [4, 16], [5, 25], [6, 36], [7, 49]]","title":"Sequences"},{"location":"python/sequences/#sequences","text":"The main sequence types in Python are lists, tuples and range objects. The main differences between these sequence objects are: Lists are mutable and their elements are usually homogeneous (things of the same type making a list of similar objects) Tuples are immutable and their elements are usually heterogeneous (things of different types making a tuple describing a single structure) Range objects are efficient sequences of integers (commonly used in for loops), use a small amount of memory and yield items only when needed","title":"Sequences"},{"location":"python/sequences/#lists","text":"Create a list using square brackets [ ... ] with items separated by commas. For example, create a list of square integers, assign it to a variable and use the built-in function print() to display the list: squares = [1,4,9,16,25] print(squares) [1, 4, 9, 16, 25] Lists may contain data of any type including other lists: points = [[0,0],[0,1],[1,1],[0,1]] print(points) [[0, 0], [0, 1], [1, 1], [0, 1]]","title":"Lists"},{"location":"python/sequences/#index","text":"Access the elements of a list by their index: primes = [2,3,5,7,11,13,17,19,23,29] print(primes[0]) 2 Notice that lists are indexed starting at 0: print(primes[1]) print(primes[2]) print(primes[6]) 3 5 17 Use negative indices to access elements starting from the end of the list: print(primes[-1]) print(primes[-2]) 29 23 Since lists are mutable, we may assign new values to entries in a list: primes[0] = -1 print(primes) [-1, 3, 5, 7, 11, 13, 17, 19, 23, 29] Use multiple indices to access entries in a list of lists: pairs = [[0,1],[2,3],[4,5],[6,7]] print(pairs[2][1]) 5","title":"Index"},{"location":"python/sequences/#slice","text":"Create a new list from a sublist (called a slice): fibonacci = [1,1,2,3,5,8,13,21,34,55,89,144] print(fibonacci[4:7]) print(fibonacci[6:]) print(fibonacci[:-2]) [5, 8, 13] [13, 21, 34, 55, 89, 144] [1, 1, 2, 3, 5, 8, 13, 21, 34, 55] Notice in the example fibonacci[4:7] the slice begins at index 4 and goes up to but not including index 7. This makes sense since the length of the slice is then 7 - 4 = 3. A slice can skip over entries in a list. For example, create a slice from every third entry from index 0 to 11: print(fibonacci[0:11:3]) [1, 3, 13, 55]","title":"Slice"},{"location":"python/sequences/#concatenate","text":"The addition operator + concatenates lists: one = [1] two = [2,2] three = [3,3,3] numbers = one + two + three print(numbers) [1, 2, 2, 3, 3, 3]","title":"Concatenate"},{"location":"python/sequences/#append","text":"Add a value to the end of a list using the append() list method: squares = [1,4,9,16,25] squares.append(36) print(squares) [1, 4, 9, 16, 25, 36] What is an object method? First, an object in Python (such as a list) contains data as well as functions (called methods) to manipulate that data. Everything in Python is an object! The list squares in the cell above contains the integer entries (the data) but it also has methods like append() to manipulate the data. We'll see more about objects and methods later on. For now, see the documentation for a complete list of list methods .","title":"Append"},{"location":"python/sequences/#tuples","text":"Create a tuple with parentheses ( ... ) : today = (2019,7,11) print(today) (2019, 7, 11) Indexing, slicing and concatenating work for tuples in the exact same way as for lists: print(today[0]) print(today[-1]) print(today[1:3]) 2019 11 (7, 11)","title":"Tuples"},{"location":"python/sequences/#range-objects","text":"Create a range object with the built-in function range() . The parameters a , b and step in range(a,b,step) are integers and the function creates an object which represents the sequence of integers from a to b (exclusively) incremented by step . (The parameter step may be omitted and is equal to 1 by default.) digits_range = range(0,10) print(digits_range) range(0, 10) Notice that a range object does not display the values of its entries when printed. This is because a range object is an efficient sequence which yields values only when needed. Use the built-in function list() to convert a range object to a list: digits_range = range(0,10) digits_list = list(digits_range) print(digits_list) [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] Create a range of even integers and convert it to a list: even_list = list(range(0,10,2)) print(even_list) [0, 2, 4, 6, 8]","title":"Range Objects"},{"location":"python/sequences/#unpacking-a-sequence","text":"One of the features of a Python sequence is unpacking where we assign all the entries of a sequence to variables in a single operation. For example, create a tuple representing a date and unpack the data as year , month and and day : today = (2019,7,11) year, month, day = today print(year) print(month) print(day) 2019 7 11","title":"Unpacking a Sequence"},{"location":"python/sequences/#list-comprehensions","text":"The built-in function range() is an efficient tool for creating sequences of integers but what about an arbitrary sequence? It is very inefficient to create a sequence by manually typing the numbers. For example, simply typing out the numbers from 1 to 20 takes a long time! numbers = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20] print(numbers) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20] Python has a beautiful syntax for creating lists called list comprehensions . The syntax is: [expression for item in iterable] where: iterable is a range, list, tuple, or any kind of sequence object item is a variable name which takes each value in the iterable expression is a Python expression which is calculated for each value of item Use a list comprehension to create the list from 1 to 20: numbers = [n for n in range(1,21)] print(numbers) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20] Create the list of square integers from 1 1 to 100 100 : squares = [n**2 for n in range(1,11)] print(squares) [1, 4, 9, 16, 25, 36, 49, 64, 81, 100] Create the periodic sequence 0,1,2,0,1,2,0,1,2,\\dots 0,1,2,0,1,2,0,1,2,\\dots of length 21 (using the remainder operator % ): zero_one_two = [n%3 for n in range(0,21)] print(zero_one_two) [0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2]","title":"List Comprehensions"},{"location":"python/sequences/#built-in-functions-for-sequences","text":"Python has several built-in functions for computing with sequences. For example, compute the length of a list: len([1,2,3]) 3 Compute the sum, maximum and minimum of a list of numbers: random = [3,-5,7,8,-1] print(sum(random)) print(max(random)) print(min(random)) 12 8 -5 Sort the list: sorted(random) [-5, -1, 3, 7, 8] Sum the numbers from 1 to 100: one_to_hundred = range(1,101) print(sum(one_to_hundred)) 5050","title":"Built-in Functions for Sequences"},{"location":"python/sequences/#examples","text":"","title":"Examples"},{"location":"python/sequences/#triangular-numbers","text":"The formula for the sum of integers from 1 to N N (also known as triangular numbers ) is given by: \\sum_{k=1}^N k = \\frac{N(N+1)}{2} \\sum_{k=1}^N k = \\frac{N(N+1)}{2} Let's verify the formula for N=1000 N=1000 : N = 1000 left_side = sum([k for k in range(1,N+1)]) right_side = N*(N+1)/2 print(left_side) print(right_side) 500500 500500.0 Notice the results agree (although the right side is a float since we used division).","title":"Triangular Numbers"},{"location":"python/sequences/#sum-of-squares","text":"The sum of squares (a special case of a geometric series ) is given by the formula: \\sum_{k=1}^N k^2 = \\frac{N(N+1)(2N+1)}{6} \\sum_{k=1}^N k^2 = \\frac{N(N+1)(2N+1)}{6} Let's verify the formula for N=2000 N=2000 : N = 2000 left_side = sum([k**2 for k in range(1,N+1)]) right_side = N*(N+1)*(2*N+1)/6 print(left_side) print(right_side) 2668667000 2668667000.0","title":"Sum of Squares"},{"location":"python/sequences/#riemann-zeta-function","text":"The Riemann zeta function is the infinite series \\zeta(s) = \\sum_{n=1}^{\\infty} \\frac{1}{n^s} \\zeta(s) = \\sum_{n=1}^{\\infty} \\frac{1}{n^s} Its values are very mysterious! Let's verify the special value formula \\zeta(4) = \\sum_{n=1}^{\\infty} \\frac{1}{n^4} = \\frac{\\pi^4}{90} \\zeta(4) = \\sum_{n=1}^{\\infty} \\frac{1}{n^4} = \\frac{\\pi^4}{90} Compute the 1000th partial sum of the series: terms = [1/n**4 for n in range(1,1001)] sum(terms) 1.082323233378306 Compare to an approximation of \\frac{\\pi^4}{90} \\frac{\\pi^4}{90} : 3.14159**4/90 1.082319576918468","title":"Riemann Zeta Function"},{"location":"python/sequences/#exercises","text":"The Maclaurin series of \\arctan(x) \\arctan(x) is \\arctan(x) = \\sum_{n = 0}^{\\infty} \\frac{(-1)^nx^{2n + 1}}{2n+1} \\arctan(x) = \\sum_{n = 0}^{\\infty} \\frac{(-1)^nx^{2n + 1}}{2n+1} Substituting x = 1 x = 1 gives a series representation of \\pi/4 \\pi/4 . Compute the 5000th partial sum of the series to approximate \\pi/4 \\pi/4 . Compute the 2000th partial sum of the alternating harmonic series : \\sum_{n=1}^{\\infty}\\frac{(-1)^n}{n} \\sum_{n=1}^{\\infty}\\frac{(-1)^n}{n} Write a list comprehension to create the list of lists: [[0, 0], [1, 1], [2, 4], [3, 9], [4, 16], [5, 25], [6, 36], [7, 49]] [[0, 0], [1, 1], [2, 4], [3, 9], [4, 16], [5, 25], [6, 36], [7, 49]]","title":"Exercises"},{"location":"python/text/","text":"Text Under construction","title":"Text"},{"location":"python/text/#text","text":"Under construction","title":"Text"},{"location":"python/variables/","text":"Variables Just like the familiar variables x x and y y in mathematics, we use variables in programming to easily manipulate values. In this section, we introduce the assignment operator = , namespaces and naming conventions for variables. Assign Values to Variables We assign a value to a variable using the assignment operator = . For example, assign the integer 2 to the variable x : x = 2 The assignment operator does not produce any output and so the cell above does not produce any output in a Jupyter notebook. Use the built-in function print to display the value assigned to a variable: print(x) 2 Compute new values using variables and operators: 1 + x + x**2 + x**3 15 Use the built-in function type to verify the datatype of the value assigned to a variable: pi = 3.14159 type(pi) float Naming Conventions We can use any set of letters, numbers and underscores to make variable names however a variable name cannot begin with a number. There are many different kinds of naming conventions and we refer to the Style Guide for Python Code (PEP8) for a summary. In this book we use lower_case_with_underscores variable names and single lowercase letter variable names such as x . It is good practice to use descriptive variable names to make your code more readable for other people. For example, the distance from Vancouver to Halifax along the Trans-Canada Highway is approximately 5799 kilometres. We write the following code to convert this value to miles: distance_km = 5799 miles_per_km = 0.6214 distance_miles = distance_km * miles_per_km print(distance_miles) 3603.4986 Names to Avoid It is good practice to use variable names which describe the value assigned to it. However there are words that we should not use as variable names because these words already have special meaning in Python. Reserved Words Summarized below are the reserved words in Python 3 . Python will raise an error if you try to assign a value to any of these keywords and so you must avoid these as variable names. False class finally is return None continue for lambda try True def from nonlocal while and del global not with as elif if or yield assert else import pass break except in raise Built-in Function Names There are several functions which are included in the standard Python library. Do not use the names of these functions as variable names otherwise the reference to the built-in function will be lost. For example, do not use sum , min , max , list or sorted as a variable name. See the full list of builtin functions . Jupyter Magic: whos The Jupyer magic command whos lists all variables in the current Jupyter notebook and their types: x = 2 pi = 3.14159 distance_km = 5799 miles_per_km = 0.6214 distance_miles = distance_km * miles_per_km whos Variable Type Data/Info ----------------------------------- distance_km int 5799 distance_miles float 3603.4986 miles_per_km float 0.6214 pi float 3.14159 x int 2","title":"Variables"},{"location":"python/variables/#variables","text":"Just like the familiar variables x x and y y in mathematics, we use variables in programming to easily manipulate values. In this section, we introduce the assignment operator = , namespaces and naming conventions for variables.","title":"Variables"},{"location":"python/variables/#assign-values-to-variables","text":"We assign a value to a variable using the assignment operator = . For example, assign the integer 2 to the variable x : x = 2 The assignment operator does not produce any output and so the cell above does not produce any output in a Jupyter notebook. Use the built-in function print to display the value assigned to a variable: print(x) 2 Compute new values using variables and operators: 1 + x + x**2 + x**3 15 Use the built-in function type to verify the datatype of the value assigned to a variable: pi = 3.14159 type(pi) float","title":"Assign Values to Variables"},{"location":"python/variables/#naming-conventions","text":"We can use any set of letters, numbers and underscores to make variable names however a variable name cannot begin with a number. There are many different kinds of naming conventions and we refer to the Style Guide for Python Code (PEP8) for a summary. In this book we use lower_case_with_underscores variable names and single lowercase letter variable names such as x . It is good practice to use descriptive variable names to make your code more readable for other people. For example, the distance from Vancouver to Halifax along the Trans-Canada Highway is approximately 5799 kilometres. We write the following code to convert this value to miles: distance_km = 5799 miles_per_km = 0.6214 distance_miles = distance_km * miles_per_km print(distance_miles) 3603.4986","title":"Naming Conventions"},{"location":"python/variables/#names-to-avoid","text":"It is good practice to use variable names which describe the value assigned to it. However there are words that we should not use as variable names because these words already have special meaning in Python.","title":"Names to Avoid"},{"location":"python/variables/#reserved-words","text":"Summarized below are the reserved words in Python 3 . Python will raise an error if you try to assign a value to any of these keywords and so you must avoid these as variable names. False class finally is return None continue for lambda try True def from nonlocal while and del global not with as elif if or yield assert else import pass break except in raise","title":"Reserved Words"},{"location":"python/variables/#built-in-function-names","text":"There are several functions which are included in the standard Python library. Do not use the names of these functions as variable names otherwise the reference to the built-in function will be lost. For example, do not use sum , min , max , list or sorted as a variable name. See the full list of builtin functions .","title":"Built-in Function Names"},{"location":"python/variables/#jupyter-magic-whos","text":"The Jupyer magic command whos lists all variables in the current Jupyter notebook and their types: x = 2 pi = 3.14159 distance_km = 5799 miles_per_km = 0.6214 distance_miles = distance_km * miles_per_km whos Variable Type Data/Info ----------------------------------- distance_km int 5799 distance_miles float 3603.4986 miles_per_km float 0.6214 pi float 3.14159 x int 2","title":"Jupyter Magic: whos"},{"location":"roots-optimization/bisection/","text":"Bisection Method The simplest root finding algorithm is the bisection method . The algorithm applies to any continuous function f(x) f(x) on an interval [a,b] [a,b] where the value of the function f(x) f(x) changes sign from a a to b b . The idea is simple: divide the interval in two, a solution must exist within one subinterval, select the subinterval where the sign of f(x) f(x) changes and repeat. Algorithm The bisection method procedure is: Choose a starting interval [a_0,b_0] [a_0,b_0] such that f(a_0)f(b_0) < 0 f(a_0)f(b_0) < 0 . Compute f(m_0) f(m_0) where m_0 = (a_0+b_0)/2 m_0 = (a_0+b_0)/2 is the midpoint. Determine the next subinterval [a_1,b_1] [a_1,b_1] : If f(a_0)f(m_0) < 0 f(a_0)f(m_0) < 0 , then let [a_1,b_1] [a_1,b_1] be the next interval with a_1=a_0 a_1=a_0 and b_1=m_0 b_1=m_0 . If f(b_0)f(m_0) < 0 f(b_0)f(m_0) < 0 , then let [a_1,b_1] [a_1,b_1] be the next interval with a_1=m_0 a_1=m_0 and b_1=b_0 b_1=b_0 . Repeat (2) and (3) until the interval [a_N,b_N] [a_N,b_N] reaches some predetermined length. Return the midpoint value m_N=(a_N+b_N)/2 m_N=(a_N+b_N)/2 . A solution of the equation f(x)=0 f(x)=0 in the interval [a,b] [a,b] is guaranteed by the Intermediate Value Theorem provided f(x) f(x) is continuous on [a,b] [a,b] and f(a)f(b) < 0 f(a)f(b) < 0 . In other words, the function changes sign over the interval and therefore must equal 0 at some point in the interval [a,b] [a,b] . Absolute Error The bisection method does not (in general) produce an exact solution of an equation f(x)=0 f(x)=0 . However, we can give an estimate of the absolute error in the approxiation. Theorem . Let f(x) f(x) be a continuous function on [a,b] [a,b] such that f(a)f(b) < 0 f(a)f(b) < 0 . After N N iterations of the biection method, let x_N x_N be the midpoint in the N N th subinterval [a_N,b_N] [a_N,b_N] x_N = \\frac{a_N + b_N}{2} x_N = \\frac{a_N + b_N}{2} There exists an exact solution x_{\\mathrm{true}} x_{\\mathrm{true}} of the equation f(x)=0 f(x)=0 in the subinterval [a_N,b_N] [a_N,b_N] and the absolute error is \\left| \\ x_{\\text{true}} - x_N \\, \\right| \\leq \\frac{b-a}{2^{N+1}} \\left| \\ x_{\\text{true}} - x_N \\, \\right| \\leq \\frac{b-a}{2^{N+1}} Note that we can rearrange the error bound to see the minimum number of iterations required to guarantee absolute error less than a prescribed \\epsilon \\epsilon : \\begin{align} \\frac{b-a}{2^{N+1}} & < \\epsilon \\\\\\ \\frac{b-a}{\\epsilon} & < 2^{N+1} \\\\\\ \\ln \\left( \\frac{b-a}{\\epsilon} \\right) & < (N+1)\\ln(2) \\\\\\ \\frac{\\ln \\left( \\frac{b-a}{\\epsilon} \\right)}{\\ln(2)} - 1 & < N \\end{align} \\begin{align} \\frac{b-a}{2^{N+1}} & < \\epsilon \\\\\\ \\frac{b-a}{\\epsilon} & < 2^{N+1} \\\\\\ \\ln \\left( \\frac{b-a}{\\epsilon} \\right) & < (N+1)\\ln(2) \\\\\\ \\frac{\\ln \\left( \\frac{b-a}{\\epsilon} \\right)}{\\ln(2)} - 1 & < N \\end{align} Implementation Write a function called bisection which takes 4 input parameters f , a , b and N and returns the approximation of a solution of f(x)=0 f(x)=0 given by N N iterations of the bisection method. If f(a_n)f(b_n) \\geq 0 f(a_n)f(b_n) \\geq 0 at any point in the iteration (caused either by a bad initial interval or rounding error in computations), then print \"Bisection method fails.\" and return None . def bisection(f,a,b,N): '''Approximate solution of f(x)=0 on interval [a,b] by bisection method. Parameters ---------- f : function The function for which we are trying to approximate a solution f(x)=0. a,b : numbers The interval in which to search for a solution. The function returns None if f(a)*f(b) >= 0 since a solution is not guaranteed. N : (positive) integer The number of iterations to implement. Returns ------- x_N : number The midpoint of the Nth interval computed by the bisection method. The initial interval [a_0,b_0] is given by [a,b]. If f(m_n) == 0 for some midpoint m_n = (a_n + b_n)/2, then the function returns this solution. If all signs of values f(a_n), f(b_n) and f(m_n) are the same at any iteration, the bisection method fails and return None. Examples -------- >>> f = lambda x: x**2 - x - 1 >>> bisection(f,1,2,25) 1.618033990263939 >>> f = lambda x: (2*x - 1)*(x - 3) >>> bisection(f,0,1,10) 0.5 ''' if f(a)*f(b) >= 0: print(\"Bisection method fails.\") return None a_n = a b_n = b for n in range(1,N+1): m_n = (a_n + b_n)/2 f_m_n = f(m_n) if f(a_n)*f_m_n < 0: a_n = a_n b_n = m_n elif f(b_n)*f_m_n < 0: a_n = m_n b_n = b_n elif f_m_n == 0: print(\"Found exact solution.\") return m_n else: print(\"Bisection method fails.\") return None return (a_n + b_n)/2 Examples Golden Ratio Let's use our function with input parameters f(x)=x^2 - x - 1 f(x)=x^2 - x - 1 and N=25 N=25 iterations on [1,2] [1,2] to approximate the golden ratio \\phi = \\frac{1 + \\sqrt{5}}{2} \\phi = \\frac{1 + \\sqrt{5}}{2} The golden ratio \\phi \\phi is a root of the quadratic polynomial x^2 - x - 1 = 0 x^2 - x - 1 = 0 . f = lambda x: x**2 - x - 1 approx_phi = bisection(f,1,2,25) print(approx_phi) 1.618033990263939 The absolute error is guaranteed to be less than (2 - 1)/(2^{26}) (2 - 1)/(2^{26}) which is: error_bound = 2**(-26) print(error_bound) 1.4901161193847656e-08 Let's verify the absolute error is then than this error bound: abs( (1 + 5**0.5)/2 - approx_phi) < error_bound True Exercises Under construction","title":"Bisection Method"},{"location":"roots-optimization/bisection/#bisection-method","text":"The simplest root finding algorithm is the bisection method . The algorithm applies to any continuous function f(x) f(x) on an interval [a,b] [a,b] where the value of the function f(x) f(x) changes sign from a a to b b . The idea is simple: divide the interval in two, a solution must exist within one subinterval, select the subinterval where the sign of f(x) f(x) changes and repeat.","title":"Bisection Method"},{"location":"roots-optimization/bisection/#algorithm","text":"The bisection method procedure is: Choose a starting interval [a_0,b_0] [a_0,b_0] such that f(a_0)f(b_0) < 0 f(a_0)f(b_0) < 0 . Compute f(m_0) f(m_0) where m_0 = (a_0+b_0)/2 m_0 = (a_0+b_0)/2 is the midpoint. Determine the next subinterval [a_1,b_1] [a_1,b_1] : If f(a_0)f(m_0) < 0 f(a_0)f(m_0) < 0 , then let [a_1,b_1] [a_1,b_1] be the next interval with a_1=a_0 a_1=a_0 and b_1=m_0 b_1=m_0 . If f(b_0)f(m_0) < 0 f(b_0)f(m_0) < 0 , then let [a_1,b_1] [a_1,b_1] be the next interval with a_1=m_0 a_1=m_0 and b_1=b_0 b_1=b_0 . Repeat (2) and (3) until the interval [a_N,b_N] [a_N,b_N] reaches some predetermined length. Return the midpoint value m_N=(a_N+b_N)/2 m_N=(a_N+b_N)/2 . A solution of the equation f(x)=0 f(x)=0 in the interval [a,b] [a,b] is guaranteed by the Intermediate Value Theorem provided f(x) f(x) is continuous on [a,b] [a,b] and f(a)f(b) < 0 f(a)f(b) < 0 . In other words, the function changes sign over the interval and therefore must equal 0 at some point in the interval [a,b] [a,b] .","title":"Algorithm"},{"location":"roots-optimization/bisection/#absolute-error","text":"The bisection method does not (in general) produce an exact solution of an equation f(x)=0 f(x)=0 . However, we can give an estimate of the absolute error in the approxiation. Theorem . Let f(x) f(x) be a continuous function on [a,b] [a,b] such that f(a)f(b) < 0 f(a)f(b) < 0 . After N N iterations of the biection method, let x_N x_N be the midpoint in the N N th subinterval [a_N,b_N] [a_N,b_N] x_N = \\frac{a_N + b_N}{2} x_N = \\frac{a_N + b_N}{2} There exists an exact solution x_{\\mathrm{true}} x_{\\mathrm{true}} of the equation f(x)=0 f(x)=0 in the subinterval [a_N,b_N] [a_N,b_N] and the absolute error is \\left| \\ x_{\\text{true}} - x_N \\, \\right| \\leq \\frac{b-a}{2^{N+1}} \\left| \\ x_{\\text{true}} - x_N \\, \\right| \\leq \\frac{b-a}{2^{N+1}} Note that we can rearrange the error bound to see the minimum number of iterations required to guarantee absolute error less than a prescribed \\epsilon \\epsilon : \\begin{align} \\frac{b-a}{2^{N+1}} & < \\epsilon \\\\\\ \\frac{b-a}{\\epsilon} & < 2^{N+1} \\\\\\ \\ln \\left( \\frac{b-a}{\\epsilon} \\right) & < (N+1)\\ln(2) \\\\\\ \\frac{\\ln \\left( \\frac{b-a}{\\epsilon} \\right)}{\\ln(2)} - 1 & < N \\end{align} \\begin{align} \\frac{b-a}{2^{N+1}} & < \\epsilon \\\\\\ \\frac{b-a}{\\epsilon} & < 2^{N+1} \\\\\\ \\ln \\left( \\frac{b-a}{\\epsilon} \\right) & < (N+1)\\ln(2) \\\\\\ \\frac{\\ln \\left( \\frac{b-a}{\\epsilon} \\right)}{\\ln(2)} - 1 & < N \\end{align}","title":"Absolute Error"},{"location":"roots-optimization/bisection/#implementation","text":"Write a function called bisection which takes 4 input parameters f , a , b and N and returns the approximation of a solution of f(x)=0 f(x)=0 given by N N iterations of the bisection method. If f(a_n)f(b_n) \\geq 0 f(a_n)f(b_n) \\geq 0 at any point in the iteration (caused either by a bad initial interval or rounding error in computations), then print \"Bisection method fails.\" and return None . def bisection(f,a,b,N): '''Approximate solution of f(x)=0 on interval [a,b] by bisection method. Parameters ---------- f : function The function for which we are trying to approximate a solution f(x)=0. a,b : numbers The interval in which to search for a solution. The function returns None if f(a)*f(b) >= 0 since a solution is not guaranteed. N : (positive) integer The number of iterations to implement. Returns ------- x_N : number The midpoint of the Nth interval computed by the bisection method. The initial interval [a_0,b_0] is given by [a,b]. If f(m_n) == 0 for some midpoint m_n = (a_n + b_n)/2, then the function returns this solution. If all signs of values f(a_n), f(b_n) and f(m_n) are the same at any iteration, the bisection method fails and return None. Examples -------- >>> f = lambda x: x**2 - x - 1 >>> bisection(f,1,2,25) 1.618033990263939 >>> f = lambda x: (2*x - 1)*(x - 3) >>> bisection(f,0,1,10) 0.5 ''' if f(a)*f(b) >= 0: print(\"Bisection method fails.\") return None a_n = a b_n = b for n in range(1,N+1): m_n = (a_n + b_n)/2 f_m_n = f(m_n) if f(a_n)*f_m_n < 0: a_n = a_n b_n = m_n elif f(b_n)*f_m_n < 0: a_n = m_n b_n = b_n elif f_m_n == 0: print(\"Found exact solution.\") return m_n else: print(\"Bisection method fails.\") return None return (a_n + b_n)/2","title":"Implementation"},{"location":"roots-optimization/bisection/#examples","text":"","title":"Examples"},{"location":"roots-optimization/bisection/#golden-ratio","text":"Let's use our function with input parameters f(x)=x^2 - x - 1 f(x)=x^2 - x - 1 and N=25 N=25 iterations on [1,2] [1,2] to approximate the golden ratio \\phi = \\frac{1 + \\sqrt{5}}{2} \\phi = \\frac{1 + \\sqrt{5}}{2} The golden ratio \\phi \\phi is a root of the quadratic polynomial x^2 - x - 1 = 0 x^2 - x - 1 = 0 . f = lambda x: x**2 - x - 1 approx_phi = bisection(f,1,2,25) print(approx_phi) 1.618033990263939 The absolute error is guaranteed to be less than (2 - 1)/(2^{26}) (2 - 1)/(2^{26}) which is: error_bound = 2**(-26) print(error_bound) 1.4901161193847656e-08 Let's verify the absolute error is then than this error bound: abs( (1 + 5**0.5)/2 - approx_phi) < error_bound True","title":"Golden Ratio"},{"location":"roots-optimization/bisection/#exercises","text":"Under construction","title":"Exercises"},{"location":"roots-optimization/newton/","text":"Newton's Method Newton's method is a root finding method that uses linear approximation. In particular, we guess a solution x_0 x_0 of the equation f(x)=0 f(x)=0 , compute the linear approximation of f(x) f(x) at x_0 x_0 and then find the x x -intercept of the linear approximation. Formula Let f(x) f(x) be a differentiable function. If x_0 x_0 is near a solution of f(x)=0 f(x)=0 then we can approximate f(x) f(x) by the tangent line at x_0 x_0 and compute the x x -intercept of the tangent line. The equation of the tangent line at x_0 x_0 is y = f'(x_0)(x - x_0) + f(x_0) y = f'(x_0)(x - x_0) + f(x_0) The x x -intercept is the solution x_1 x_1 of the equation 0 = f'(x_0)(x_1 - x_0) + f(x_0) 0 = f'(x_0)(x_1 - x_0) + f(x_0) and we solve for x_1 x_1 x_1 = x_0 - \\frac{f(x_0)}{f'(x_0)} x_1 = x_0 - \\frac{f(x_0)}{f'(x_0)} If we implement this procedure repeatedly, then we obtain a sequence given by the recursive formula x_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)} x_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)} which (potentially) converges to a solution of the equation f(x)=0 f(x)=0 . Advantages/Disadvantages When it converges, Newton's method usually converges very quickly and this is its main advantage. However, Newton's method is not guaranteed to converge and this is obviously a big disadvantage especially compared to the bisection and secant methods which are guaranteed to converge to a solution (provided they start with an interval containing a root). Newton's method also requires computing values of the derivative of the function in question. This is potentially a disadvantage if the derivative is difficult to compute. The stopping criteria for Newton's method differs from the bisection and secant methods. In those methods, we know how close we are to a solution because we are computing intervals which contain a solution. In Newton's method, we don't know how close we are to a solution. All we can compute is the value f(x) f(x) and so we implement a stopping criteria based on f(x) f(x) . Finally, there's no guarantee that the method converges to a solution and we should set a maximum number of iterations so that our implementation ends if we don't find a solution. Implementation Let's write a function called newton which takes 5 input parameters f , Df , x0 , epsilon and max_iter and returns an approximation of a solution of f(x)=0 f(x)=0 by Newton's method. The function may terminate in 3 ways: If abs(f(xn)) < epsilon , the algorithm has found an approximate solution and returns xn . If f'(xn) == 0 , the algorithm stops and returns None . If the number of iterations exceed max_iter , the algorithm stops and returns None . def newton(f,Df,x0,epsilon,max_iter): '''Approximate solution of f(x)=0 by Newton's method. Parameters ---------- f : function Function for which we are searching for a solution f(x)=0. Df : function Derivative of f(x). x0 : number Initial guess for a solution f(x)=0. epsilon : number Stopping criteria is abs(f(x)) < epsilon. max_iter : integer Maximum number of iterations of Newton's method. Returns ------- xn : number Implement Newton's method: compute the linear approximation of f(x) at xn and find x intercept by the formula x = xn - f(xn)/Df(xn) Continue until abs(f(xn)) < epsilon and return xn. If Df(xn) == 0, return None. If the number of iterations exceeds max_iter, then return None. Examples -------- >>> f = lambda x: x**2 - x - 1 >>> Df = lambda x: 2*x - 1 >>> newton(f,Df,1,1e-8,10) Found solution after 5 iterations. 1.618033988749989 ''' xn = x0 for n in range(0,max_iter): fxn = f(xn) if abs(fxn) < epsilon: print('Found solution after',n,'iterations.') return xn Dfxn = Df(xn) if Dfxn == 0: print('Zero derivative. No solution found.') return None xn = xn - fxn/Dfxn print('Exceeded maximum iterations. No solution found.') return None Examples Supergolden Ratio Let's test our function newton on the polynomial p(x) = x^3 - x^2 - 1 p(x) = x^3 - x^2 - 1 to approximate the super golden ratio . p = lambda x: x**3 - x**2 - 1 Dp = lambda x: 3*x**2 - 2*x approx = newton(p,Dp,1,1e-10,10) print(approx) Found solution after 6 iterations. 1.4655712318767877 How many iterations of the bisection method starting with the interval [1,2] [1,2] can achieve the same accuracy? Divergent Example Newton's method diverges in certain cases. For example, if the tangent line at the root is vertical as in f(x)=x^{1/3} f(x)=x^{1/3} . Note that bisection and secant methods would converge in this case. f = lambda x: x**(1/3) Df = lambda x: (1/3)*x**(-2/3) approx = newton(f,Df,0.1,1e-2,100) Exceeded maximum iterations. No solution found. Exercises Let p(x) = x^3 - x - 1 p(x) = x^3 - x - 1 . The only real root of p(x) p(x) is called the plastic number and is given by \\frac{\\sqrt[3]{108 + 12\\sqrt{69}} + \\sqrt[3]{108 - 12\\sqrt{69}}}{6} \\frac{\\sqrt[3]{108 + 12\\sqrt{69}} + \\sqrt[3]{108 - 12\\sqrt{69}}}{6} Choose x_0 = 1 x_0 = 1 and implement 2 iterations of Newton's method to approximate the plastic number. Use the exact value above to compute the absolute error after 2 iterations of Newton's method. Starting with the subinterval [1,2] [1,2] , how many iterations of the bisection method is required to achieve the same accuracy?","title":"Newton's Method"},{"location":"roots-optimization/newton/#newtons-method","text":"Newton's method is a root finding method that uses linear approximation. In particular, we guess a solution x_0 x_0 of the equation f(x)=0 f(x)=0 , compute the linear approximation of f(x) f(x) at x_0 x_0 and then find the x x -intercept of the linear approximation.","title":"Newton's Method"},{"location":"roots-optimization/newton/#formula","text":"Let f(x) f(x) be a differentiable function. If x_0 x_0 is near a solution of f(x)=0 f(x)=0 then we can approximate f(x) f(x) by the tangent line at x_0 x_0 and compute the x x -intercept of the tangent line. The equation of the tangent line at x_0 x_0 is y = f'(x_0)(x - x_0) + f(x_0) y = f'(x_0)(x - x_0) + f(x_0) The x x -intercept is the solution x_1 x_1 of the equation 0 = f'(x_0)(x_1 - x_0) + f(x_0) 0 = f'(x_0)(x_1 - x_0) + f(x_0) and we solve for x_1 x_1 x_1 = x_0 - \\frac{f(x_0)}{f'(x_0)} x_1 = x_0 - \\frac{f(x_0)}{f'(x_0)} If we implement this procedure repeatedly, then we obtain a sequence given by the recursive formula x_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)} x_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)} which (potentially) converges to a solution of the equation f(x)=0 f(x)=0 .","title":"Formula"},{"location":"roots-optimization/newton/#advantagesdisadvantages","text":"When it converges, Newton's method usually converges very quickly and this is its main advantage. However, Newton's method is not guaranteed to converge and this is obviously a big disadvantage especially compared to the bisection and secant methods which are guaranteed to converge to a solution (provided they start with an interval containing a root). Newton's method also requires computing values of the derivative of the function in question. This is potentially a disadvantage if the derivative is difficult to compute. The stopping criteria for Newton's method differs from the bisection and secant methods. In those methods, we know how close we are to a solution because we are computing intervals which contain a solution. In Newton's method, we don't know how close we are to a solution. All we can compute is the value f(x) f(x) and so we implement a stopping criteria based on f(x) f(x) . Finally, there's no guarantee that the method converges to a solution and we should set a maximum number of iterations so that our implementation ends if we don't find a solution.","title":"Advantages/Disadvantages"},{"location":"roots-optimization/newton/#implementation","text":"Let's write a function called newton which takes 5 input parameters f , Df , x0 , epsilon and max_iter and returns an approximation of a solution of f(x)=0 f(x)=0 by Newton's method. The function may terminate in 3 ways: If abs(f(xn)) < epsilon , the algorithm has found an approximate solution and returns xn . If f'(xn) == 0 , the algorithm stops and returns None . If the number of iterations exceed max_iter , the algorithm stops and returns None . def newton(f,Df,x0,epsilon,max_iter): '''Approximate solution of f(x)=0 by Newton's method. Parameters ---------- f : function Function for which we are searching for a solution f(x)=0. Df : function Derivative of f(x). x0 : number Initial guess for a solution f(x)=0. epsilon : number Stopping criteria is abs(f(x)) < epsilon. max_iter : integer Maximum number of iterations of Newton's method. Returns ------- xn : number Implement Newton's method: compute the linear approximation of f(x) at xn and find x intercept by the formula x = xn - f(xn)/Df(xn) Continue until abs(f(xn)) < epsilon and return xn. If Df(xn) == 0, return None. If the number of iterations exceeds max_iter, then return None. Examples -------- >>> f = lambda x: x**2 - x - 1 >>> Df = lambda x: 2*x - 1 >>> newton(f,Df,1,1e-8,10) Found solution after 5 iterations. 1.618033988749989 ''' xn = x0 for n in range(0,max_iter): fxn = f(xn) if abs(fxn) < epsilon: print('Found solution after',n,'iterations.') return xn Dfxn = Df(xn) if Dfxn == 0: print('Zero derivative. No solution found.') return None xn = xn - fxn/Dfxn print('Exceeded maximum iterations. No solution found.') return None","title":"Implementation"},{"location":"roots-optimization/newton/#examples","text":"","title":"Examples"},{"location":"roots-optimization/newton/#supergolden-ratio","text":"Let's test our function newton on the polynomial p(x) = x^3 - x^2 - 1 p(x) = x^3 - x^2 - 1 to approximate the super golden ratio . p = lambda x: x**3 - x**2 - 1 Dp = lambda x: 3*x**2 - 2*x approx = newton(p,Dp,1,1e-10,10) print(approx) Found solution after 6 iterations. 1.4655712318767877 How many iterations of the bisection method starting with the interval [1,2] [1,2] can achieve the same accuracy?","title":"Supergolden Ratio"},{"location":"roots-optimization/newton/#divergent-example","text":"Newton's method diverges in certain cases. For example, if the tangent line at the root is vertical as in f(x)=x^{1/3} f(x)=x^{1/3} . Note that bisection and secant methods would converge in this case. f = lambda x: x**(1/3) Df = lambda x: (1/3)*x**(-2/3) approx = newton(f,Df,0.1,1e-2,100) Exceeded maximum iterations. No solution found.","title":"Divergent Example"},{"location":"roots-optimization/newton/#exercises","text":"Let p(x) = x^3 - x - 1 p(x) = x^3 - x - 1 . The only real root of p(x) p(x) is called the plastic number and is given by \\frac{\\sqrt[3]{108 + 12\\sqrt{69}} + \\sqrt[3]{108 - 12\\sqrt{69}}}{6} \\frac{\\sqrt[3]{108 + 12\\sqrt{69}} + \\sqrt[3]{108 - 12\\sqrt{69}}}{6} Choose x_0 = 1 x_0 = 1 and implement 2 iterations of Newton's method to approximate the plastic number. Use the exact value above to compute the absolute error after 2 iterations of Newton's method. Starting with the subinterval [1,2] [1,2] , how many iterations of the bisection method is required to achieve the same accuracy?","title":"Exercises"},{"location":"roots-optimization/root-finding/","text":"Root Finding Root finding refers to the general problem of searching for a solution of an equation F(x)=0 F(x)=0 for some function F(x) F(x) . This is a very general problem and it comes up a lot in mathematics! For example, if we want to optimize a function f(x) f(x) then we need to find critical points and therefore solve the equation f'(x)=0 f'(x)=0 . There are few examples where there exist exact methods for finding solutions. For example, the quadratic formula x = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a} x = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a} gives us an exact method for finding roots of the equation ax^2 + bx + c = 0 ax^2 + bx + c = 0 There is a general formula to solve a cubic equation and even a quartic (degree 4) equation (but the formula is too complicated to be useful). But there does not exist a formula for a quintic (degree 5) polynomial . And there are many more examples of equations with no known method to solve them exactly. What can we do? Use numerical methods to find approximate solutions.","title":"Root Finding"},{"location":"roots-optimization/root-finding/#root-finding","text":"Root finding refers to the general problem of searching for a solution of an equation F(x)=0 F(x)=0 for some function F(x) F(x) . This is a very general problem and it comes up a lot in mathematics! For example, if we want to optimize a function f(x) f(x) then we need to find critical points and therefore solve the equation f'(x)=0 f'(x)=0 . There are few examples where there exist exact methods for finding solutions. For example, the quadratic formula x = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a} x = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a} gives us an exact method for finding roots of the equation ax^2 + bx + c = 0 ax^2 + bx + c = 0 There is a general formula to solve a cubic equation and even a quartic (degree 4) equation (but the formula is too complicated to be useful). But there does not exist a formula for a quintic (degree 5) polynomial . And there are many more examples of equations with no known method to solve them exactly. What can we do? Use numerical methods to find approximate solutions.","title":"Root Finding"},{"location":"roots-optimization/secant/","text":"Secant Method The secant method is very similar to the bisection method except instead of dividing each interval by choosing the midpoint the secant method divides each interval by the secant line connecting the endpoints. The secant method always converges to a root of f(x)=0 f(x)=0 provided that f(x) f(x) is continuous on [a,b] [a,b] and f(a)f(b)<0 f(a)f(b)<0 . Secant Line Formula Let f(x) f(x) be a continuous function on a closed interval [a,b] [a,b] such that f(a)f(b) < 0 f(a)f(b) < 0 . A solution of the equation f(x) = 0 f(x) = 0 for x \\in [a,b] x \\in [a,b] is guaranteed by the Intermediate Value Theorem . Consider the line connecting the endpoint values (a,f(a)) (a,f(a)) and (b,f(b)) (b,f(b)) . The line connecting these two points is called the secant line and is given by the formula y = \\frac{f(b) - f(a)}{b - a}(x - a) + f(a) y = \\frac{f(b) - f(a)}{b - a}(x - a) + f(a) The point where the secant line crosses the x x -axis is 0 = \\frac{f(b) - f(a)}{b - a}(x - a) + f(a) 0 = \\frac{f(b) - f(a)}{b - a}(x - a) + f(a) which we solve for x x x = a - f(a)\\frac{b - a}{f(b) - f(a)} x = a - f(a)\\frac{b - a}{f(b) - f(a)} Algorithm The secant method procedure is almost identical to the bisection method. The only difference it how we divide each subinterval. Choose a starting interval [a_0,b_0] [a_0,b_0] such that f(a_0)f(b_0) < 0 f(a_0)f(b_0) < 0 . Compute f(x_0) f(x_0) where x_0 x_0 is given by the secant line $$ x_0 = a_0 - f(a_0)\\frac{b_0 - a_0}{f(b_0) - f(a_0)} $$ Determine the next subinterval [a_1,b_1] [a_1,b_1] : If f(a_0)f(x_0) < 0 f(a_0)f(x_0) < 0 , then let [a_1,b_1] [a_1,b_1] be the next interval with a_1=a_0 a_1=a_0 and b_1=x_0 b_1=x_0 . If f(b_0)f(x_0) < 0 f(b_0)f(x_0) < 0 , then let [a_1,b_1] [a_1,b_1] be the next interval with a_1=x_0 a_1=x_0 and b_1=b_0 b_1=b_0 . Repeat (2) and (3) until the interval [a_N,b_N] [a_N,b_N] reaches some predetermined length. Return the value x_N x_N , the x x -intercept of the N N th subinterval. A solution of the equation f(x)=0 f(x)=0 in the interval [a,b] [a,b] is guaranteed by the Intermediate Value Theorem provided f(x) f(x) is continuous on [a,b] [a,b] and f(a)f(b) < 0 f(a)f(b) < 0 . In other words, the function changes sign over the interval and therefore must equal 0 at some point in the interval [a,b] [a,b] . Implementation Write a function called secant which takes 4 input parameters f , a , b and N and returns the approximation of a solution of f(x)=0 f(x)=0 given by N N iterations of the secant method. If f(a_n)f(b_n) \\geq 0 f(a_n)f(b_n) \\geq 0 at any point in the iteration (caused either by a bad initial interval or rounding error in computations), then print \"Secant method fails.\" and return None . def secant(f,a,b,N): '''Approximate solution of f(x)=0 on interval [a,b] by the secant method. Parameters ---------- f : function The function for which we are trying to approximate a solution f(x)=0. a,b : numbers The interval in which to search for a solution. The function returns None if f(a)*f(b) >= 0 since a solution is not guaranteed. N : (positive) integer The number of iterations to implement. Returns ------- m_N : number The x intercept of the secant line on the the Nth interval m_n = a_n - f(a_n)*(b_n - a_n)/(f(b_n) - f(a_n)) The initial interval [a_0,b_0] is given by [a,b]. If f(m_n) == 0 for some intercept m_n then the function returns this solution. If all signs of values f(a_n), f(b_n) and f(m_n) are the same at any iterations, the secant method fails and return None. Examples -------- >>> f = lambda x: x**2 - x - 1 >>> secant(f,1,2,5) 1.6180257510729614 ''' if f(a)*f(b) >= 0: print(\"Secant method fails.\") return None a_n = a b_n = b for n in range(1,N+1): m_n = a_n - f(a_n)*(b_n - a_n)/(f(b_n) - f(a_n)) f_m_n = f(m_n) if f(a_n)*f_m_n < 0: a_n = a_n b_n = m_n elif f(b_n)*f_m_n < 0: a_n = m_n b_n = b_n elif f_m_n == 0: print(\"Found exact solution.\") return m_n else: print(\"Secant method fails.\") return None return a_n - f(a_n)*(b_n - a_n)/(f(b_n) - f(a_n)) Examples Supergolden Ratio Let's test our function with input values for which we know the correct output. Let's find an approximation of the supergolden ratio : the only real root of the polynomial p(x) = x^3 - x^2 - 1 p(x) = x^3 - x^2 - 1 . p = lambda x: x**3 - x**2 - 1 print(p(1)) print(p(2)) -1 3 Since the polynomial changes sign in the interval [1,2] [1,2] , we can apply the secant method with this as the starting interval: approx = secant(p,1,2,20) print(approx) 1.4655712311394433 The exact value of the supergolden ratio is \\frac{1 + \\sqrt[3]{\\frac{29 + 3\\sqrt{93}}{2}} + \\sqrt[3]{\\frac{29 - 3\\sqrt{93}}{2}}}{3} \\frac{1 + \\sqrt[3]{\\frac{29 + 3\\sqrt{93}}{2}} + \\sqrt[3]{\\frac{29 - 3\\sqrt{93}}{2}}}{3} supergolden = (1 + ((29 + 3*93**0.5)/2)**(1/3) + ((29 - 3*93**0.5)/2)**(1/3))/3 print(supergolden) 1.4655712318767682 Let's compare our approximation with the exact solution: error = abs(supergolden - approx) print(error) 7.373248678277378e-10 Exercises Under construction","title":"Secant Method"},{"location":"roots-optimization/secant/#secant-method","text":"The secant method is very similar to the bisection method except instead of dividing each interval by choosing the midpoint the secant method divides each interval by the secant line connecting the endpoints. The secant method always converges to a root of f(x)=0 f(x)=0 provided that f(x) f(x) is continuous on [a,b] [a,b] and f(a)f(b)<0 f(a)f(b)<0 .","title":"Secant Method"},{"location":"roots-optimization/secant/#secant-line-formula","text":"Let f(x) f(x) be a continuous function on a closed interval [a,b] [a,b] such that f(a)f(b) < 0 f(a)f(b) < 0 . A solution of the equation f(x) = 0 f(x) = 0 for x \\in [a,b] x \\in [a,b] is guaranteed by the Intermediate Value Theorem . Consider the line connecting the endpoint values (a,f(a)) (a,f(a)) and (b,f(b)) (b,f(b)) . The line connecting these two points is called the secant line and is given by the formula y = \\frac{f(b) - f(a)}{b - a}(x - a) + f(a) y = \\frac{f(b) - f(a)}{b - a}(x - a) + f(a) The point where the secant line crosses the x x -axis is 0 = \\frac{f(b) - f(a)}{b - a}(x - a) + f(a) 0 = \\frac{f(b) - f(a)}{b - a}(x - a) + f(a) which we solve for x x x = a - f(a)\\frac{b - a}{f(b) - f(a)} x = a - f(a)\\frac{b - a}{f(b) - f(a)}","title":"Secant Line Formula"},{"location":"roots-optimization/secant/#algorithm","text":"The secant method procedure is almost identical to the bisection method. The only difference it how we divide each subinterval. Choose a starting interval [a_0,b_0] [a_0,b_0] such that f(a_0)f(b_0) < 0 f(a_0)f(b_0) < 0 . Compute f(x_0) f(x_0) where x_0 x_0 is given by the secant line $$ x_0 = a_0 - f(a_0)\\frac{b_0 - a_0}{f(b_0) - f(a_0)} $$ Determine the next subinterval [a_1,b_1] [a_1,b_1] : If f(a_0)f(x_0) < 0 f(a_0)f(x_0) < 0 , then let [a_1,b_1] [a_1,b_1] be the next interval with a_1=a_0 a_1=a_0 and b_1=x_0 b_1=x_0 . If f(b_0)f(x_0) < 0 f(b_0)f(x_0) < 0 , then let [a_1,b_1] [a_1,b_1] be the next interval with a_1=x_0 a_1=x_0 and b_1=b_0 b_1=b_0 . Repeat (2) and (3) until the interval [a_N,b_N] [a_N,b_N] reaches some predetermined length. Return the value x_N x_N , the x x -intercept of the N N th subinterval. A solution of the equation f(x)=0 f(x)=0 in the interval [a,b] [a,b] is guaranteed by the Intermediate Value Theorem provided f(x) f(x) is continuous on [a,b] [a,b] and f(a)f(b) < 0 f(a)f(b) < 0 . In other words, the function changes sign over the interval and therefore must equal 0 at some point in the interval [a,b] [a,b] .","title":"Algorithm"},{"location":"roots-optimization/secant/#implementation","text":"Write a function called secant which takes 4 input parameters f , a , b and N and returns the approximation of a solution of f(x)=0 f(x)=0 given by N N iterations of the secant method. If f(a_n)f(b_n) \\geq 0 f(a_n)f(b_n) \\geq 0 at any point in the iteration (caused either by a bad initial interval or rounding error in computations), then print \"Secant method fails.\" and return None . def secant(f,a,b,N): '''Approximate solution of f(x)=0 on interval [a,b] by the secant method. Parameters ---------- f : function The function for which we are trying to approximate a solution f(x)=0. a,b : numbers The interval in which to search for a solution. The function returns None if f(a)*f(b) >= 0 since a solution is not guaranteed. N : (positive) integer The number of iterations to implement. Returns ------- m_N : number The x intercept of the secant line on the the Nth interval m_n = a_n - f(a_n)*(b_n - a_n)/(f(b_n) - f(a_n)) The initial interval [a_0,b_0] is given by [a,b]. If f(m_n) == 0 for some intercept m_n then the function returns this solution. If all signs of values f(a_n), f(b_n) and f(m_n) are the same at any iterations, the secant method fails and return None. Examples -------- >>> f = lambda x: x**2 - x - 1 >>> secant(f,1,2,5) 1.6180257510729614 ''' if f(a)*f(b) >= 0: print(\"Secant method fails.\") return None a_n = a b_n = b for n in range(1,N+1): m_n = a_n - f(a_n)*(b_n - a_n)/(f(b_n) - f(a_n)) f_m_n = f(m_n) if f(a_n)*f_m_n < 0: a_n = a_n b_n = m_n elif f(b_n)*f_m_n < 0: a_n = m_n b_n = b_n elif f_m_n == 0: print(\"Found exact solution.\") return m_n else: print(\"Secant method fails.\") return None return a_n - f(a_n)*(b_n - a_n)/(f(b_n) - f(a_n))","title":"Implementation"},{"location":"roots-optimization/secant/#examples","text":"","title":"Examples"},{"location":"roots-optimization/secant/#supergolden-ratio","text":"Let's test our function with input values for which we know the correct output. Let's find an approximation of the supergolden ratio : the only real root of the polynomial p(x) = x^3 - x^2 - 1 p(x) = x^3 - x^2 - 1 . p = lambda x: x**3 - x**2 - 1 print(p(1)) print(p(2)) -1 3 Since the polynomial changes sign in the interval [1,2] [1,2] , we can apply the secant method with this as the starting interval: approx = secant(p,1,2,20) print(approx) 1.4655712311394433 The exact value of the supergolden ratio is \\frac{1 + \\sqrt[3]{\\frac{29 + 3\\sqrt{93}}{2}} + \\sqrt[3]{\\frac{29 - 3\\sqrt{93}}{2}}}{3} \\frac{1 + \\sqrt[3]{\\frac{29 + 3\\sqrt{93}}{2}} + \\sqrt[3]{\\frac{29 - 3\\sqrt{93}}{2}}}{3} supergolden = (1 + ((29 + 3*93**0.5)/2)**(1/3) + ((29 - 3*93**0.5)/2)**(1/3))/3 print(supergolden) 1.4655712318767682 Let's compare our approximation with the exact solution: error = abs(supergolden - approx) print(error) 7.373248678277378e-10","title":"Supergolden Ratio"},{"location":"roots-optimization/secant/#exercises","text":"Under construction","title":"Exercises"},{"location":"scipy/matplotlib/","text":"Matplotlib Matplotlib is a Python package for 2D plotting and the matplotlib.pyplot sub-module contains many plotting functions to create various kinds of plots. Let's get started by importing matplotlib.pyplot and using %matplotlib Jupyter magic to display plots in the notebook. import numpy as np import matplotlib.pyplot as plt %matplotlib inline Basic Plotting Procedure The general procedure to create a 2D line plot is: Create a sequence of x x values. Create a sequence of y y values. Enter plt.plot(x,y,[fmt],**kwargs) where [fmt] is a (optional) format string and **kwargs are (optional) keyword arguments specifying line properties of the plot. Use pyplot functions to add features to the figure such as a title, legend, grid lines, etc. Enter plt.show() to display the resulting figure. Let's begin with a basic example with a few random points: x = [-5,-2,0,1,3] y = [2,-1,1,-4,3] plt.plot(x,y) plt.show() The main things to notice are: The sequences x and y define the coordinates of the points in the plot. The line in the plot is constructed by connecting the points by straight lines. The second observation implies that if we want to plot a smooth curve then we need to plot lots of points otherwise the plot will not be smooth. For example, we could try plotting the parabola y = x^2 y = x^2 for x \\in [-2,2] x \\in [-2,2] using only 5 points: x = [-2,-1,0,1,2] y = [4,1,0,1,4] plt.plot(x,y) plt.show() This is too few points to plot a smooth curve such as y = x^2 y = x^2 and so we need more points! Let's try again using the NumPy function np.linspace to create 100 points! x = np.linspace(-2,2,100) y = x**2 plt.plot(x,y) plt.show() That's a better representation of the parabola y = x^2 y = x^2 . Note that the number of points we use in a line plot (100 in this case) is completely arbitrary but the goal is to show a smooth graph for a smooth curve and so we just need to pick a big enough number depending on the function. But be careful not to generate too many points since a very large number of points will take a long time to plot! Now that we have the general idea, let's look at adding style and features to our plots! Line Properties A line appearing in a plot has several properties including color, transparency, style, width and markers. We can set these properties when we call plt.plot using the following keyword arguments: Property Description alpha transparency (0.0 transparent through 1.0 opaque) color (or c ) any matplotlib color label text appearing in legend linestyle (or ls ) solid , dashed , dashdot , dotted linewidth (or lw ) set width of the line marker set marker style markeredgecolor (or mec ) any matplotlib color markerfacecolor (or mfc ) any matplotlib color markersize (or ms ) size of the marker Note that we can specify a matplotlib color in several different ways including by name such as blue or red , or by a RGB tuple such as (1,0,1) for purple. For example, let's plot the function y = e^{-x^2}\\cos(2 \\pi x) \\ \\ , \\ \\ x \\in [-2,2] y = e^{-x^2}\\cos(2 \\pi x) \\ \\ , \\ \\ x \\in [-2,2] x = np.linspace(-2,2,41) y = np.exp(-x**2) * np.cos(2*np.pi*x) plt.plot(x,y,alpha=0.4,label='Decaying Cosine', color='red',linestyle='dashed',linewidth=2, marker='o',markersize=5,markerfacecolor='blue', markeredgecolor='blue') plt.ylim([-2,2]) plt.legend() plt.show() Notice that we used the pyplot function plt.legend to display the figure with a legend (showing the line label) and and plt.ylim to set the limits on the vertical axis to [-2,2] . Format Strings A format string gives us a shortcut to add color, markers and line style to a line plot. For example, if we want to plot the function y = \\frac{1}{1 + x^2} \\ , \\ x \\in [-5,5] y = \\frac{1}{1 + x^2} \\ , \\ x \\in [-5,5] with a dashed black line and square markers, we could use keyword arguments: x = np.linspace(-5,5,41) y = 1/(1 + x**2) plt.plot(x,y,color='black',linestyle='dashed',marker='s') plt.show() Or we could use the corresponding format string 'ks--' where k denotes a black line, s a square marker and -- a dashed line: x = np.linspace(-5,5,41) y = 1/(1 + x**2) plt.plot(x,y,'ks--') plt.show() Much easier! See below for a list of colors, markers and linestyles. Colors Character Color b blue g green r red c cyan m magenta y yellow k black w white Markers Character Marker . point o circle v triangle down ^ triangle up s square p pentagon * star + plus x x D diamond Line Styles Character Line Style - solid line style -- dashed line style -. dash-dot line style : dotted line style See the matplotlib.pyplot.plot documentation for more options. Pyplot Functions There are many pyplot functions available for us to customize our figures. For example: Fucntion Description plt.xlim set x x limits plt.ylim set y y limits plt.grid add grid lines plt.title add a title plt.xlabel add label to the horizontal axis plt.ylabel add label to the vertical axis plt.axis set axis properties ( equal , off , scaled , etc.) plt.xticks set tick locations on the horizontal axis plt.yticks set tick locations on the vertical axis plt.legend display legend for several lines in the same figure plt.savefig save figure (as .png, .pdf, etc.) to working directory plt.figure create a new figure and set its properties See the pyplot documentation for a full list of functions. Examples Taylor Polynomials Plot the function y = \\cos(x) y = \\cos(x) along with its Taylor polynomials of degrees 2 and 4. x = np.linspace(-6,6,50) # Plot y = cos(x) y = np.cos(x) plt.plot(x,y,'b',label='cos(x)') # Plot degree 2 Taylor polynomial y2 = 1 - x**2/2 plt.plot(x,y2,'r-.',label='Degree 2') # Plot degree 4 Taylor polynomial y4 = 1 - x**2/2 + x**4/24 plt.plot(x,y4,'g:',label='Degree 4') # Add features to our figure plt.legend() plt.grid(True,linestyle=':') plt.xlim([-6,6]) plt.ylim([-4,4]) plt.title('Taylor Polynomials of cos(x) at x=0') plt.xlabel('x') plt.ylabel('y') plt.show() Heart Curve Plot the heart curve: \\begin{align} x &= 16 \\sin^3(t) \\\\\\ y &= 13 \\cos(t) - 5 \\cos(2t) - 2 \\cos(3t) - \\cos(4t) \\end{align} \\begin{align} x &= 16 \\sin^3(t) \\\\\\ y &= 13 \\cos(t) - 5 \\cos(2t) - 2 \\cos(3t) - \\cos(4t) \\end{align} for t \\in [0,2\\pi] t \\in [0,2\\pi] . t = np.linspace(0,2*np.pi,100) x = 16*np.sin(t)**3 y = 13*np.cos(t) - 5*np.cos(2*t) - 2*np.cos(3*t) - np.cos(4*t) # Plot line with RGB tuple (red=1, green=0.2, blue=0.5) # and 20pt line width plt.plot(x,y,c=(1,0.2,0.5),lw=20) # Add features to our figure plt.title('Heart!') plt.axis('equal') plt.axis('off') plt.show() Subplots The plt.subplot function takes at least 3 inputs n n , m m and i i and creates a figure with a n n by m m grid of subplots and then sets the i i th subplot (counting across the rows) as the current plot (ie. current axes object). For example, consider the sawtooth wave f(t) = \\frac{1}{2} - \\frac{1}{\\pi} \\sum_{k=1}^{\\infty} (-1)^k \\frac{\\sin(2 \\pi k t)}{k} f(t) = \\frac{1}{2} - \\frac{1}{\\pi} \\sum_{k=1}^{\\infty} (-1)^k \\frac{\\sin(2 \\pi k t)}{k} and let f_N(t) f_N(t) denote the N N th partial sum of the sawtooth wave: f_N(t) = \\frac{1}{2} - \\frac{1}{\\pi} \\sum_{k=1}^{N} (-1)^k \\frac{\\sin(2 \\pi k t)}{k} f_N(t) = \\frac{1}{2} - \\frac{1}{\\pi} \\sum_{k=1}^{N} (-1)^k \\frac{\\sin(2 \\pi k t)}{k} Create a 2 by 2 grid of subplots to plot the first 4 partial sums: \\begin{align} f_1(t) &= \\frac{1}{2} + \\frac{\\sin(2 \\pi t)}{\\pi} \\\\\\ f_2(t) &= \\frac{1}{2} + \\frac{\\sin(2 \\pi t)}{\\pi} - \\frac{\\sin(4 \\pi t)}{2\\pi} \\\\\\ f_3(t) &= \\frac{1}{2} + \\frac{\\sin(2 \\pi t)}{\\pi} - \\frac{\\sin(4 \\pi t)}{2\\pi} + \\frac{\\sin(6 \\pi t)}{3\\pi} \\\\\\ f_4(t) &= \\frac{1}{2} + \\frac{\\sin(2 \\pi t)}{\\pi} - \\frac{\\sin(4 \\pi t)}{2\\pi} + \\frac{\\sin(6 \\pi t)}{3\\pi} - \\frac{\\sin(8 \\pi t)}{4\\pi} \\end{align} \\begin{align} f_1(t) &= \\frac{1}{2} + \\frac{\\sin(2 \\pi t)}{\\pi} \\\\\\ f_2(t) &= \\frac{1}{2} + \\frac{\\sin(2 \\pi t)}{\\pi} - \\frac{\\sin(4 \\pi t)}{2\\pi} \\\\\\ f_3(t) &= \\frac{1}{2} + \\frac{\\sin(2 \\pi t)}{\\pi} - \\frac{\\sin(4 \\pi t)}{2\\pi} + \\frac{\\sin(6 \\pi t)}{3\\pi} \\\\\\ f_4(t) &= \\frac{1}{2} + \\frac{\\sin(2 \\pi t)}{\\pi} - \\frac{\\sin(4 \\pi t)}{2\\pi} + \\frac{\\sin(6 \\pi t)}{3\\pi} - \\frac{\\sin(8 \\pi t)}{4\\pi} \\end{align} t = np.linspace(0,4,200) fN = 1/2 for N in [1,2,3,4]: fN = fN - (-1)**N * np.sin(2*N*np.pi*t)/(N*np.pi) plt.subplot(2,2,N) plt.plot(t,fN) plt.title('N = {}'.format(N)) plt.tight_layout() plt.show() See the documentation for more about subplots. Beyond Line Plots Scatter plots A scatter plot has 4 dimensions: x x coordinate, y y coordinate, size and color. Let's make a random scatter plot: # Set the number of dots in the plot N = 2000 # Create random x and y coordinates sampled uniformly from [0,1] x = np.random.rand(N) y = np.random.rand(N) # Create random array sampled uniformly from [20,120] # `size` array is used below to set the size of each dot size = 100*np.random.rand(N) + 20 # Create random 4-tuples sampled uniformly from [0,1] # `colors` array is used below to set the color # (red,green,blue,alpha) of each dot colors = np.random.rand(N,4) # Create a figure of size 12 by 5 and create scatter plot plt.figure(figsize=(12,5)) plt.scatter(x,y,c=colors,s=size) plt.axis('off') plt.show() Histograms Generate an array of 10000 random numbers sampled from the normal distribution and create a histogram . Let's also superimpose the normal distribution: y = \\frac{1}{\\sqrt{2\\pi}} e^{-x^2/2} y = \\frac{1}{\\sqrt{2\\pi}} e^{-x^2/2} samples = np.random.randn(10000) plt.hist(samples,bins=20,density=True,alpha=0.5,color=(0.3,0.8,0.1)) plt.title('Random Samples - Normal Distribution') plt.ylabel('Frequency') x = np.linspace(-4,4,100) y = 1/(2*np.pi)**0.5 * np.exp(-x**2/2) plt.plot(x,y,'b',alpha=0.8) plt.show() Bar plots Plot the total precipitation in Vancouver by month as a bar plot : month = range(1,13) precipitation = [98.8,128.8,206.0,138.5,102.2,46.4,1.8,5.0,29.4,114.8,197.0,170.6] plt.bar(month,precipitation) plt.xticks(month) plt.yticks(range(0,300,50)) plt.grid(True,alpha=0.5,linestyle='--') plt.title('Precipitation in Vancouver, 2017') plt.ylabel('Total Precipitation (mm)') plt.xlabel('Month') plt.show() Figure and Axes Objects Under construction Exercises Plot the following functions: f(x) = \\sqrt{|x|} f(x) = \\sqrt{|x|} , x \\in [-9,9] x \\in [-9,9] f(x) = \\sin(x) + \\sin(2x) f(x) = \\sin(x) + \\sin(2x) , x \\in [0,4\\pi] x \\in [0,4\\pi] f(x) = \\arctan(x) f(x) = \\arctan(x) , x \\in [-5,5] x \\in [-5,5] f(x) = 2x\\ln|x| f(x) = 2x\\ln|x| , x \\not=0 x \\not=0 , f(0)=0 f(0)=0 , x \\in [-1,1] x \\in [-1,1] f(x) = (x+2)(x+1)(x-1)(x-2)(x - 3) f(x) = (x+2)(x+1)(x-1)(x-2)(x - 3) , x \\in [-2,3] x \\in [-2,3] f(x) = e^{-x^2} f(x) = e^{-x^2} , x \\in [-2,2] x \\in [-2,2] Plot the figure eight curve : \\begin{align} x &= \\sin(t) \\\\\\ y &= \\sin(t) \\cos(t) \\end{align} \\begin{align} x &= \\sin(t) \\\\\\ y &= \\sin(t) \\cos(t) \\end{align} for t \\in [0,2\\pi] t \\in [0,2\\pi] . Plot the trefoil knot : \\begin{align} x &= \\sin t + 2 \\sin 2t \\\\\\ y &= \\cos t - 2 \\cos 2t \\end{align} \\begin{align} x &= \\sin t + 2 \\sin 2t \\\\\\ y &= \\cos t - 2 \\cos 2t \\end{align} for t \\in [0,2\\pi] t \\in [0,2\\pi] . Plot the butterfly curve : \\begin{align} x &= \\sin(t) \\left( e^{\\cos t } - 2 \\cos(4t) - \\sin^5(t/12) \\right) \\\\\\ y &= \\cos(t) \\left( e^{\\cos t } - 2 \\cos(4t) - \\sin^5(t/12) \\right) \\end{align} \\begin{align} x &= \\sin(t) \\left( e^{\\cos t } - 2 \\cos(4t) - \\sin^5(t/12) \\right) \\\\\\ y &= \\cos(t) \\left( e^{\\cos t } - 2 \\cos(4t) - \\sin^5(t/12) \\right) \\end{align} for t \\in [0,100] t \\in [0,100] . Write a function called parametric_plots which takes input parameters a and k and plots the parametric equation \\begin{align} x(t) &= 2 k \\cos(t) - a \\cos(k t) \\\\\\ y(t) &= 2 k \\sin(t) - a \\sin(k t) \\end{align} \\begin{align} x(t) &= 2 k \\cos(t) - a \\cos(k t) \\\\\\ y(t) &= 2 k \\sin(t) - a \\sin(k t) \\end{align} for t \\in [0,2\\pi] t \\in [0,2\\pi] . Include a title for each subplot to display the values for a a and k k , and use plt.axis('equal') to display the curve properly.","title":"Matplotlib"},{"location":"scipy/matplotlib/#matplotlib","text":"Matplotlib is a Python package for 2D plotting and the matplotlib.pyplot sub-module contains many plotting functions to create various kinds of plots. Let's get started by importing matplotlib.pyplot and using %matplotlib Jupyter magic to display plots in the notebook. import numpy as np import matplotlib.pyplot as plt %matplotlib inline","title":"Matplotlib"},{"location":"scipy/matplotlib/#basic-plotting","text":"","title":"Basic Plotting"},{"location":"scipy/matplotlib/#procedure","text":"The general procedure to create a 2D line plot is: Create a sequence of x x values. Create a sequence of y y values. Enter plt.plot(x,y,[fmt],**kwargs) where [fmt] is a (optional) format string and **kwargs are (optional) keyword arguments specifying line properties of the plot. Use pyplot functions to add features to the figure such as a title, legend, grid lines, etc. Enter plt.show() to display the resulting figure. Let's begin with a basic example with a few random points: x = [-5,-2,0,1,3] y = [2,-1,1,-4,3] plt.plot(x,y) plt.show() The main things to notice are: The sequences x and y define the coordinates of the points in the plot. The line in the plot is constructed by connecting the points by straight lines. The second observation implies that if we want to plot a smooth curve then we need to plot lots of points otherwise the plot will not be smooth. For example, we could try plotting the parabola y = x^2 y = x^2 for x \\in [-2,2] x \\in [-2,2] using only 5 points: x = [-2,-1,0,1,2] y = [4,1,0,1,4] plt.plot(x,y) plt.show() This is too few points to plot a smooth curve such as y = x^2 y = x^2 and so we need more points! Let's try again using the NumPy function np.linspace to create 100 points! x = np.linspace(-2,2,100) y = x**2 plt.plot(x,y) plt.show() That's a better representation of the parabola y = x^2 y = x^2 . Note that the number of points we use in a line plot (100 in this case) is completely arbitrary but the goal is to show a smooth graph for a smooth curve and so we just need to pick a big enough number depending on the function. But be careful not to generate too many points since a very large number of points will take a long time to plot! Now that we have the general idea, let's look at adding style and features to our plots!","title":"Procedure"},{"location":"scipy/matplotlib/#line-properties","text":"A line appearing in a plot has several properties including color, transparency, style, width and markers. We can set these properties when we call plt.plot using the following keyword arguments: Property Description alpha transparency (0.0 transparent through 1.0 opaque) color (or c ) any matplotlib color label text appearing in legend linestyle (or ls ) solid , dashed , dashdot , dotted linewidth (or lw ) set width of the line marker set marker style markeredgecolor (or mec ) any matplotlib color markerfacecolor (or mfc ) any matplotlib color markersize (or ms ) size of the marker Note that we can specify a matplotlib color in several different ways including by name such as blue or red , or by a RGB tuple such as (1,0,1) for purple. For example, let's plot the function y = e^{-x^2}\\cos(2 \\pi x) \\ \\ , \\ \\ x \\in [-2,2] y = e^{-x^2}\\cos(2 \\pi x) \\ \\ , \\ \\ x \\in [-2,2] x = np.linspace(-2,2,41) y = np.exp(-x**2) * np.cos(2*np.pi*x) plt.plot(x,y,alpha=0.4,label='Decaying Cosine', color='red',linestyle='dashed',linewidth=2, marker='o',markersize=5,markerfacecolor='blue', markeredgecolor='blue') plt.ylim([-2,2]) plt.legend() plt.show() Notice that we used the pyplot function plt.legend to display the figure with a legend (showing the line label) and and plt.ylim to set the limits on the vertical axis to [-2,2] .","title":"Line Properties"},{"location":"scipy/matplotlib/#format-strings","text":"A format string gives us a shortcut to add color, markers and line style to a line plot. For example, if we want to plot the function y = \\frac{1}{1 + x^2} \\ , \\ x \\in [-5,5] y = \\frac{1}{1 + x^2} \\ , \\ x \\in [-5,5] with a dashed black line and square markers, we could use keyword arguments: x = np.linspace(-5,5,41) y = 1/(1 + x**2) plt.plot(x,y,color='black',linestyle='dashed',marker='s') plt.show() Or we could use the corresponding format string 'ks--' where k denotes a black line, s a square marker and -- a dashed line: x = np.linspace(-5,5,41) y = 1/(1 + x**2) plt.plot(x,y,'ks--') plt.show() Much easier! See below for a list of colors, markers and linestyles.","title":"Format Strings"},{"location":"scipy/matplotlib/#colors","text":"Character Color b blue g green r red c cyan m magenta y yellow k black w white","title":"Colors"},{"location":"scipy/matplotlib/#markers","text":"Character Marker . point o circle v triangle down ^ triangle up s square p pentagon * star + plus x x D diamond","title":"Markers"},{"location":"scipy/matplotlib/#line-styles","text":"Character Line Style - solid line style -- dashed line style -. dash-dot line style : dotted line style See the matplotlib.pyplot.plot documentation for more options.","title":"Line Styles"},{"location":"scipy/matplotlib/#pyplot-functions","text":"There are many pyplot functions available for us to customize our figures. For example: Fucntion Description plt.xlim set x x limits plt.ylim set y y limits plt.grid add grid lines plt.title add a title plt.xlabel add label to the horizontal axis plt.ylabel add label to the vertical axis plt.axis set axis properties ( equal , off , scaled , etc.) plt.xticks set tick locations on the horizontal axis plt.yticks set tick locations on the vertical axis plt.legend display legend for several lines in the same figure plt.savefig save figure (as .png, .pdf, etc.) to working directory plt.figure create a new figure and set its properties See the pyplot documentation for a full list of functions.","title":"Pyplot Functions"},{"location":"scipy/matplotlib/#examples","text":"","title":"Examples"},{"location":"scipy/matplotlib/#taylor-polynomials","text":"Plot the function y = \\cos(x) y = \\cos(x) along with its Taylor polynomials of degrees 2 and 4. x = np.linspace(-6,6,50) # Plot y = cos(x) y = np.cos(x) plt.plot(x,y,'b',label='cos(x)') # Plot degree 2 Taylor polynomial y2 = 1 - x**2/2 plt.plot(x,y2,'r-.',label='Degree 2') # Plot degree 4 Taylor polynomial y4 = 1 - x**2/2 + x**4/24 plt.plot(x,y4,'g:',label='Degree 4') # Add features to our figure plt.legend() plt.grid(True,linestyle=':') plt.xlim([-6,6]) plt.ylim([-4,4]) plt.title('Taylor Polynomials of cos(x) at x=0') plt.xlabel('x') plt.ylabel('y') plt.show()","title":"Taylor Polynomials"},{"location":"scipy/matplotlib/#heart-curve","text":"Plot the heart curve: \\begin{align} x &= 16 \\sin^3(t) \\\\\\ y &= 13 \\cos(t) - 5 \\cos(2t) - 2 \\cos(3t) - \\cos(4t) \\end{align} \\begin{align} x &= 16 \\sin^3(t) \\\\\\ y &= 13 \\cos(t) - 5 \\cos(2t) - 2 \\cos(3t) - \\cos(4t) \\end{align} for t \\in [0,2\\pi] t \\in [0,2\\pi] . t = np.linspace(0,2*np.pi,100) x = 16*np.sin(t)**3 y = 13*np.cos(t) - 5*np.cos(2*t) - 2*np.cos(3*t) - np.cos(4*t) # Plot line with RGB tuple (red=1, green=0.2, blue=0.5) # and 20pt line width plt.plot(x,y,c=(1,0.2,0.5),lw=20) # Add features to our figure plt.title('Heart!') plt.axis('equal') plt.axis('off') plt.show()","title":"Heart Curve"},{"location":"scipy/matplotlib/#subplots","text":"The plt.subplot function takes at least 3 inputs n n , m m and i i and creates a figure with a n n by m m grid of subplots and then sets the i i th subplot (counting across the rows) as the current plot (ie. current axes object). For example, consider the sawtooth wave f(t) = \\frac{1}{2} - \\frac{1}{\\pi} \\sum_{k=1}^{\\infty} (-1)^k \\frac{\\sin(2 \\pi k t)}{k} f(t) = \\frac{1}{2} - \\frac{1}{\\pi} \\sum_{k=1}^{\\infty} (-1)^k \\frac{\\sin(2 \\pi k t)}{k} and let f_N(t) f_N(t) denote the N N th partial sum of the sawtooth wave: f_N(t) = \\frac{1}{2} - \\frac{1}{\\pi} \\sum_{k=1}^{N} (-1)^k \\frac{\\sin(2 \\pi k t)}{k} f_N(t) = \\frac{1}{2} - \\frac{1}{\\pi} \\sum_{k=1}^{N} (-1)^k \\frac{\\sin(2 \\pi k t)}{k} Create a 2 by 2 grid of subplots to plot the first 4 partial sums: \\begin{align} f_1(t) &= \\frac{1}{2} + \\frac{\\sin(2 \\pi t)}{\\pi} \\\\\\ f_2(t) &= \\frac{1}{2} + \\frac{\\sin(2 \\pi t)}{\\pi} - \\frac{\\sin(4 \\pi t)}{2\\pi} \\\\\\ f_3(t) &= \\frac{1}{2} + \\frac{\\sin(2 \\pi t)}{\\pi} - \\frac{\\sin(4 \\pi t)}{2\\pi} + \\frac{\\sin(6 \\pi t)}{3\\pi} \\\\\\ f_4(t) &= \\frac{1}{2} + \\frac{\\sin(2 \\pi t)}{\\pi} - \\frac{\\sin(4 \\pi t)}{2\\pi} + \\frac{\\sin(6 \\pi t)}{3\\pi} - \\frac{\\sin(8 \\pi t)}{4\\pi} \\end{align} \\begin{align} f_1(t) &= \\frac{1}{2} + \\frac{\\sin(2 \\pi t)}{\\pi} \\\\\\ f_2(t) &= \\frac{1}{2} + \\frac{\\sin(2 \\pi t)}{\\pi} - \\frac{\\sin(4 \\pi t)}{2\\pi} \\\\\\ f_3(t) &= \\frac{1}{2} + \\frac{\\sin(2 \\pi t)}{\\pi} - \\frac{\\sin(4 \\pi t)}{2\\pi} + \\frac{\\sin(6 \\pi t)}{3\\pi} \\\\\\ f_4(t) &= \\frac{1}{2} + \\frac{\\sin(2 \\pi t)}{\\pi} - \\frac{\\sin(4 \\pi t)}{2\\pi} + \\frac{\\sin(6 \\pi t)}{3\\pi} - \\frac{\\sin(8 \\pi t)}{4\\pi} \\end{align} t = np.linspace(0,4,200) fN = 1/2 for N in [1,2,3,4]: fN = fN - (-1)**N * np.sin(2*N*np.pi*t)/(N*np.pi) plt.subplot(2,2,N) plt.plot(t,fN) plt.title('N = {}'.format(N)) plt.tight_layout() plt.show() See the documentation for more about subplots.","title":"Subplots"},{"location":"scipy/matplotlib/#beyond-line-plots","text":"","title":"Beyond Line Plots"},{"location":"scipy/matplotlib/#scatter-plots","text":"A scatter plot has 4 dimensions: x x coordinate, y y coordinate, size and color. Let's make a random scatter plot: # Set the number of dots in the plot N = 2000 # Create random x and y coordinates sampled uniformly from [0,1] x = np.random.rand(N) y = np.random.rand(N) # Create random array sampled uniformly from [20,120] # `size` array is used below to set the size of each dot size = 100*np.random.rand(N) + 20 # Create random 4-tuples sampled uniformly from [0,1] # `colors` array is used below to set the color # (red,green,blue,alpha) of each dot colors = np.random.rand(N,4) # Create a figure of size 12 by 5 and create scatter plot plt.figure(figsize=(12,5)) plt.scatter(x,y,c=colors,s=size) plt.axis('off') plt.show()","title":"Scatter plots"},{"location":"scipy/matplotlib/#histograms","text":"Generate an array of 10000 random numbers sampled from the normal distribution and create a histogram . Let's also superimpose the normal distribution: y = \\frac{1}{\\sqrt{2\\pi}} e^{-x^2/2} y = \\frac{1}{\\sqrt{2\\pi}} e^{-x^2/2} samples = np.random.randn(10000) plt.hist(samples,bins=20,density=True,alpha=0.5,color=(0.3,0.8,0.1)) plt.title('Random Samples - Normal Distribution') plt.ylabel('Frequency') x = np.linspace(-4,4,100) y = 1/(2*np.pi)**0.5 * np.exp(-x**2/2) plt.plot(x,y,'b',alpha=0.8) plt.show()","title":"Histograms"},{"location":"scipy/matplotlib/#bar-plots","text":"Plot the total precipitation in Vancouver by month as a bar plot : month = range(1,13) precipitation = [98.8,128.8,206.0,138.5,102.2,46.4,1.8,5.0,29.4,114.8,197.0,170.6] plt.bar(month,precipitation) plt.xticks(month) plt.yticks(range(0,300,50)) plt.grid(True,alpha=0.5,linestyle='--') plt.title('Precipitation in Vancouver, 2017') plt.ylabel('Total Precipitation (mm)') plt.xlabel('Month') plt.show()","title":"Bar plots"},{"location":"scipy/matplotlib/#figure-and-axes-objects","text":"Under construction","title":"Figure and Axes Objects"},{"location":"scipy/matplotlib/#exercises","text":"Plot the following functions: f(x) = \\sqrt{|x|} f(x) = \\sqrt{|x|} , x \\in [-9,9] x \\in [-9,9] f(x) = \\sin(x) + \\sin(2x) f(x) = \\sin(x) + \\sin(2x) , x \\in [0,4\\pi] x \\in [0,4\\pi] f(x) = \\arctan(x) f(x) = \\arctan(x) , x \\in [-5,5] x \\in [-5,5] f(x) = 2x\\ln|x| f(x) = 2x\\ln|x| , x \\not=0 x \\not=0 , f(0)=0 f(0)=0 , x \\in [-1,1] x \\in [-1,1] f(x) = (x+2)(x+1)(x-1)(x-2)(x - 3) f(x) = (x+2)(x+1)(x-1)(x-2)(x - 3) , x \\in [-2,3] x \\in [-2,3] f(x) = e^{-x^2} f(x) = e^{-x^2} , x \\in [-2,2] x \\in [-2,2] Plot the figure eight curve : \\begin{align} x &= \\sin(t) \\\\\\ y &= \\sin(t) \\cos(t) \\end{align} \\begin{align} x &= \\sin(t) \\\\\\ y &= \\sin(t) \\cos(t) \\end{align} for t \\in [0,2\\pi] t \\in [0,2\\pi] . Plot the trefoil knot : \\begin{align} x &= \\sin t + 2 \\sin 2t \\\\\\ y &= \\cos t - 2 \\cos 2t \\end{align} \\begin{align} x &= \\sin t + 2 \\sin 2t \\\\\\ y &= \\cos t - 2 \\cos 2t \\end{align} for t \\in [0,2\\pi] t \\in [0,2\\pi] . Plot the butterfly curve : \\begin{align} x &= \\sin(t) \\left( e^{\\cos t } - 2 \\cos(4t) - \\sin^5(t/12) \\right) \\\\\\ y &= \\cos(t) \\left( e^{\\cos t } - 2 \\cos(4t) - \\sin^5(t/12) \\right) \\end{align} \\begin{align} x &= \\sin(t) \\left( e^{\\cos t } - 2 \\cos(4t) - \\sin^5(t/12) \\right) \\\\\\ y &= \\cos(t) \\left( e^{\\cos t } - 2 \\cos(4t) - \\sin^5(t/12) \\right) \\end{align} for t \\in [0,100] t \\in [0,100] . Write a function called parametric_plots which takes input parameters a and k and plots the parametric equation \\begin{align} x(t) &= 2 k \\cos(t) - a \\cos(k t) \\\\\\ y(t) &= 2 k \\sin(t) - a \\sin(k t) \\end{align} \\begin{align} x(t) &= 2 k \\cos(t) - a \\cos(k t) \\\\\\ y(t) &= 2 k \\sin(t) - a \\sin(k t) \\end{align} for t \\in [0,2\\pi] t \\in [0,2\\pi] . Include a title for each subplot to display the values for a a and k k , and use plt.axis('equal') to display the curve properly.","title":"Exercises"},{"location":"scipy/numpy/","text":"NumPy NumPy is the core Python package for numerical computing. The main features of NumPy are: N N -dimensional array object ndarray Vectorized operations and functions which broadcast across arrays for fast computation To get started with NumPy, let's adopt the standard convention and import it using the name np : import numpy as np NumPy Arrays The fundamental object provided by the NumPy package is the ndarray . We can think of a 1D (1-dimensional) ndarray as a list, a 2D (2-dimensional) ndarray as a matrix, a 3D (3-dimensional) ndarray as a 3-tensor (or a \"cube\" of numbers), and so on. See the NumPy tutorial for more about NumPy arrays. Creating Arrays The function numpy.array creates a NumPy array from a Python sequence such as a list, a tuple or a list of lists. For example, create a 1D NumPy array from a Python list: a = np.array([1,2,3,4,5]) print(a) [1 2 3 4 5] Notice that when we print a NumPy array it looks a lot like a Python list except that the entries are separated by spaces whereas entries in a Python list are separated by commas: print([1,2,3,4,5]) [1, 2, 3, 4, 5] Notice also that a NumPy array is displayed slightly differently when output by a cell (as opposed to being explicitly printed to output by the print function): a array([1, 2, 3, 4, 5]) Use the built-in function type to verify the type: type(a) numpy.ndarray Create a 2D NumPy array from a Python list of lists: M = np.array([[1,2,3],[4,5,6]]) print(M) [[1 2 3] [4 5 6]] type(M) numpy.ndarray Create an n n -dimensional NumPy array from nested Python lists. For example, the following is a 3D NumPy array: N = np.array([ [[1,2],[3,4]] , [[5,6],[7,8]] , [[9,10],[11,12]] ]) print(N) [[[ 1 2] [ 3 4]] [[ 5 6] [ 7 8]] [[ 9 10] [11 12]]] There are several NumPy functions for creating arrays : Function Description numpy.array(a) Create n n -dimensional NumPy array from sequence a numpy.linspace(a,b,N) Create 1D NumPy array with N equally spaced values from a to b (inclusively) numpy.arange(a,b,step) Create 1D NumPy array with values from a to b (exclusively) incremented by step numpy.zeros(N) Create 1D NumPy array of zeros of length N N numpy.zeros((n,m)) Create 2D NumPy array of zeros with n n rows and m m columns numpy.ones(N) Create 1D NumPy array of ones of length N N numpy.ones((n,m)) Create 2D NumPy array of ones with n n rows and m m columns numpy.eye(N) Create 2D NumPy array with N N rows and N N columns with ones on the diagonal (ie. the identity matrix of size N N ) Create a 1D NumPy array with 11 equally spaced values from 0 to 1: x = np.linspace(0,1,11) print(x) [0. 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ] Create a 1D NumPy array with values from 0 to 20 (exclusively) incremented by 2.5: y = np.arange(0,20,2.5) print(y) [ 0. 2.5 5. 7.5 10. 12.5 15. 17.5] These are the functions that we'll use most often when creating NumPy arrays. The function numpy.linspace works best when we know the number of points we want in the array, and numpy.arange works best when we know step size between values in the array. Create a 1D NumPy array of zeros of length 5: z = np.zeros(5) print(z) [0. 0. 0. 0. 0.] Create a 2D NumPy array of zeros with 2 rows and 5 columns: M = np.zeros((2,5)) print(M) [[0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]] Create a 1D NumPy array of ones of length 7: w = np.ones(7) print(w) [1. 1. 1. 1. 1. 1. 1.] Create a 2D NumPy array of ones with 3 rows and 2 columns: N = np.ones((3,2)) print(N) [[1. 1.] [1. 1.] [1. 1.]] Create the identity matrix of size 10: I = np.eye(10) print(I) [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]] Array Datatype NumPy arrays are homogeneous : all entries in the array are the same datatype. We will only work with numeric arrays and our arrays will contain either integers, floats, complex numbers or booleans. There are different kinds of datatypes provided by NumPy for different applications but we'll mostly be working with the default integer type numpy.int64 and the default float type numpy.float64 . These are very similar to the built-in Python datatypes int and float but with some differences that we won't go into. Check out the NumPy documentation on numeric datatypes for more information. The most important point for now is to know how to determine if a NumPy array contains integers elements or float elements. We can access the datatype of a NumPy array by its .dtype attribute. For example, create a 2D NumPy array from a list of lists of integers: A = np.array([[1,2,3],[4,5,6]]) print(A) [[1 2 3] [4 5 6]] We expect the datatype of A to be integers and we verify: A.dtype dtype('int64') Most of the other NumPy functions which create arrays use the numpy.float64 datatype by default. For example, using numpy.linspace : u = np.linspace(0,1,5) print(u) [0. 0.25 0.5 0.75 1. ] u.dtype dtype('float64') Notice that numbers are printed with a decimal point when the datatype of the NumPy array is any kind of float. Dimension, Shape and Size We can think of a 1D NumPy array as a list of numbers, a 2D NumPy array as a matrix, a 3D NumPy array as a cube of numbers, and so on. Given a NumPy array, we can find out how many dimensions it has by accessing its .ndim attribute. The result is a number telling us how many dimensions it has. For example, create a 2D NumPy array: A = np.array([[1,2],[3,4],[5,6]]) print(A) [[1 2] [3 4] [5 6]] A.ndim 2 The result tells us that A has 2 dimensions. The first dimension corresponds to the vertical direction counting the rows and the second dimension corresponds to the horizontal direction counting the columns. We can find out how many rows and columns A has by accessing its .shape attribute: A.shape (3, 2) The result is a tuple (3,2) of length 2 which means that A is a 2D array with 3 rows and 2 columns. We can also find out how many entries A has in total by accessing its .size attribute: A.size 6 This is the expected result since we know that A has 3 rows and 2 columns and therefore 2(3) = 6 total entries. Create a 1D NumPy array and inspect its dimension, shape and size: r = np.array([9,3,1,7]) print(r) [9 3 1 7] r.ndim 1 r.shape (4,) r.size 4 The variable r is assigned to a 1D NumPy array of length 4. Notice that r.shape is a tuple with a single entry (4,) . Slicing and Indexing Accessing the entries in an array is called indexing and accessing rows and columns (or subarrays) is called slicing . See the NumPy documentation for more information about indexing and slicing . Create a 1D NumPy array: v = np.linspace(0,5,11) print(v) [0. 0.5 1. 1.5 2. 2.5 3. 3.5 4. 4.5 5. ] Access the entries in a 1D array using the square brackets notation just like a Python list. For example, access the entry at index 3: v[3] 1.5 Notice that NumPy array indices start at 0 just like Python sequences. Create a 2D array of integers: B = np.array([[6, 5, 3, 1, 1],[1, 0, 4, 0, 1],[5, 9, 2, 2, 9]]) print(B) [[6 5 3 1 1] [1 0 4 0 1] [5 9 2 2 9]] Access the entries in a 2D array using the square brackets with 2 indices. In particular, access the entry at row index 1 and column index 2: B[1,2] 4 Access the top left entry in the array: B[0,0] 6 Negative indices work for NumPy arrays as they do for Python sequences. Access the bottom right entry in the array: B[-1,-1] 9 Access the row at index 2 using the colon : syntax: B[2,:] array([5, 9, 2, 2, 9]) Access the column at index 3: B[:,3] array([1, 0, 2]) Select the subarray of rows at index 1 and 2, and columns at index 2, 3 and 4: subB = B[1:3,2:5] print(subB) [[4 0 1] [2 2 9]] Slices of NumPy arrays are again NumPy arrays but possibly of a different dimension: subB.ndim 2 subB.shape (2, 3) type(subB) numpy.ndarray The variable subB is assigned to a 2D NumPy array of shape 2 by 2. Let's do the same for the column at index 2: colB = B[:,2] print(colB) [3 4 2] colB.ndim 1 colB.shape (3,) type(colB) numpy.ndarray The variable colB is assigned to a 1D NumPy array of length 3. Stacking We can build bigger arrays out of smaller arrays by stacking along different dimensions using the functions numpy.hstack and numpy.vstack . Stack 3 different 1D NumPy arrays of length 3 vertically forming a 3 by 3 matrix: x = np.array([1,1,1]) y = np.array([2,2,2]) z = np.array([3,3,3]) vstacked = np.vstack((x,y,z)) print(vstacked) [[1 1 1] [2 2 2] [3 3 3]] Stack 1D NumPy arrays horizontally to create another 1D array: hstacked = np.hstack((x,y,z)) print(hstacked) [1 1 1 2 2 2 3 3 3] Use numpy.hstack and numpy.vstack to build the matrix T T where T = \\begin{bmatrix} 1 & 1 & 2 & 2 \\\\ 1 & 1 & 2 & 2 \\\\ 3 & 3 & 4 & 4 \\\\ 3 & 3 & 4 & 4 \\end{bmatrix} T = \\begin{bmatrix} 1 & 1 & 2 & 2 \\\\ 1 & 1 & 2 & 2 \\\\ 3 & 3 & 4 & 4 \\\\ 3 & 3 & 4 & 4 \\end{bmatrix} A = np.ones((2,2)) B = 2*np.ones((2,2)) C = 3*np.ones((2,2)) D = 4*np.ones((2,2)) A_B = np.hstack((A,B)) print(A_B) [[1. 1. 2. 2.] [1. 1. 2. 2.]] C_D = np.hstack((C,D)) print(C_D) [[3. 3. 4. 4.] [3. 3. 4. 4.]] T = np.vstack((A_B,C_D)) print(T) [[1. 1. 2. 2.] [1. 1. 2. 2.] [3. 3. 4. 4.] [3. 3. 4. 4.]] Copies versus Views Under construction Operations and Functions Array Operations Arithmetic operators including addition + , subtraction - , multiplication * , division / and exponentiation ** are applied to arrays elementwise . For addition and substraction, these are the familiar vector operations we see in linear algebra: v = np.array([1,2,3]) w = np.array([1,0,-1]) v + w array([2, 2, 2]) v - w array([0, 2, 4]) In the same way, array multiplication and division are performed element by element: v * w array([ 1, 0, -3]) w / v array([ 1. , 0. , -0.33333333]) Notice that the datatype of both v and w is numpy.int64 however division w / v returns an array with datatype numpy.float64 . The exponent operator ** also acts element by element in the array: v ** 2 array([1, 4, 9]) Let's see these operations for 2D arrays: A = np.array([[3,1],[2,-1]]) B = np.array([[2,-2],[5,1]]) A + B array([[ 5, -1], [ 7, 0]]) A - B array([[ 1, 3], [-3, -2]]) A / B array([[ 1.5, -0.5], [ 0.4, -1. ]]) A * B array([[ 6, -2], [10, -1]]) A ** 2 array([[9, 1], [4, 1]]) Notice that array multiplication and exponentiation are performed elementwise. In Python 3.5+, the symbol @ computes matrix multiplication for NumPy arrays: A @ B array([[11, -5], [-1, -5]]) Matrix powers are performed by the function numpy.linalg.matrix_power . It's a long function name and so it's convenient to import it with a shorter name: from numpy.linalg import matrix_power as mpow Compute A^3 A^3 : mpow(A,3) array([[37, 9], [18, 1]]) Equivalently, use the @ operator to compute A^3 A^3 : A @ A @ A array([[37, 9], [18, 1]]) Broadcasting We know from linear algebra that we can only add matrices of the same size. Braodcasting is a set of NumPy rules which relaxes this constraint and allows us to combine a smaller array with a bigger when it makes sense. For example, suppose we want to create a 1D NumPy array of y y values for x=0.0,0.25,0.5,0.75,1.0 x=0.0,0.25,0.5,0.75,1.0 for the function y = x^2 + 1 y = x^2 + 1 . From what we've seen so far, it makes sense to create x , then x**2 and then add an array of ones [1. 1. 1. 1. 1.] : x = np.array([0,0.25,0.5,0.75,1.0]) y = x**2 + np.array([1,1,1,1,1]) print(y) [1. 1.0625 1.25 1.5625 2. ] An example of broadcasting in NumPy is the following equivalent operation: x = np.array([0,0.25,0.5,0.75,1.0]) y = x**2 + 1 print(y) [1. 1.0625 1.25 1.5625 2. ] The number 1 is a scalar and we are adding it to a 1D NumPy array of length 5. The broadcasting rule in this case is to broadcast the scalar value 1 across the larger array. The result is a simpler syntax for a very comman operation. Let's try another example. What happens when we try to add a 1D NumPy array of length 4 to a 2D NumPy array of size 3 by 4? u = np.array([1,2,3,4]) print(u) [1 2 3 4] A = np.array([[1,1,1,1],[2,2,2,2],[3,3,3,3]]) print(A) [[1 1 1 1] [2 2 2 2] [3 3 3 3]] result = A + u print(result) [[2 3 4 5] [3 4 5 6] [4 5 6 7]] The 1D NumPy array is broadcast across the 2D array because the length of the first dimension in each array are equal! Array Functions There are many array functions we can use to compute with NumPy arrays. The following is a partial list and we'll look closer at mathematical functions in the next section. numpy.sum numpy.prod numpy.mean numpy.max numpy.min numpy.std numpy.argmax numpy.argmin numpy.var Create a 1D NumPy array with random values and compute: arr = np.array([8,-2,4,7,-3]) print(arr) [ 8 -2 4 7 -3] Compute the mean of the values in the array: np.mean(arr) 2.8 Verify the mean once more: m = np.sum(arr) / arr.size print(m) 2.8 Find the index of the maximum element in the array: max_i = np.argmax(arr) print(max_i) 0 Verify the maximum value in the array: np.max(arr) 8 arr[max_i] 8 Array functions apply to 2D arrays as well (and N N -dimensional arrays in general) with the added feature that we can choose to apply array functions to the entire array, down the columns or across the rows (or any axis). Create a 2D NumPy array with random values and compute the sum of all the entries: M = np.array([[2,4,2],[2,1,1],[3,2,0],[0,6,2]]) print(M) [[2 4 2] [2 1 1] [3 2 0] [0 6 2]] np.sum(M) 25 The function numpy.sum also takes a keyword argument axis which determines along which dimension to compute the sum: np.sum(M,axis=0) # Sum of the columns array([ 7, 13, 5]) np.sum(M,axis=1) # Sum of the rows array([8, 4, 5, 8]) Mathematical Functions Mathematical functions in NumPy are called universal functions and are vectorized . Vectorized functions operate elementwise on arrays producing arrays as output and are built to compute values across arrays very quickly. The following is a partial list of mathematical functions: numpy.sin numpy.cos numpy.tan numpy.exp numpy.log numpy.log10 numpy.arcsin numpy.arccos numpy.arctan Compute the values \\sin(2 \\pi x) \\sin(2 \\pi x) for x = 0,0.25,0.5\\dots,1.75 x = 0,0.25,0.5\\dots,1.75 : x = np.arange(0,1.25,0.25) print(x) [0. 0.25 0.5 0.75 1. ] np.sin(2*np.pi*x) array([ 0.0000000e+00, 1.0000000e+00, 1.2246468e-16, -1.0000000e+00, -2.4492936e-16]) We expect the array [0. 1. 0. -1. 0.] however there is (as always with floating point numbers) some rounding errors in the result. In numerical computing, we can interpret a number such as 10^{-16} 10^{-16} as 0 0 . Compute the values \\log_{10}(x) \\log_{10}(x) for x = 1,10,100,1000,10000 x = 1,10,100,1000,10000 : x = np.array([1,10,100,1000,10000]) print(x) [ 1 10 100 1000 10000] np.log10(x) array([0., 1., 2., 3., 4.]) Note that we can also evaluate mathematical functions with scalar values: np.sin(0) 0.0 NumPy also provides familiar mathematical constants such as \\pi \\pi and e e : np.pi 3.141592653589793 np.e 2.718281828459045 For example, verify the limit \\lim_{x \\to \\infty} \\arctan(x) = \\frac{\\pi}{2} \\lim_{x \\to \\infty} \\arctan(x) = \\frac{\\pi}{2} by evaluating \\arctan(x) \\arctan(x) for some (arbitrary) large value x x : np.arctan(10000) 1.5706963267952299 np.pi/2 1.5707963267948966 Random Number Generators The subpackage numpy.random contains functions to generate NumPy arrays of random numbers sampled from different distributions. The following is a partial list of distributions: Function Description numpy.random.rand(d1,...,dn) Create a NumPy array (with shape (d1,...,dn) ) with entries sampled uniformly from [0,1) numpy.random.randn(d1,...,dn) Create a NumPy array (with shape (d1,...,dn) ) with entries sampled from the standard normal distribution numpy.random.randint(a,b,size) Create a NumPy array (with shape size ) with integer entries from low (inclusive) to high (exclusive) Sample a random number from the uniform distribution : np.random.rand() 0.6695906195141056 Sample 3 random numbers: np.random.rand(3) array([0.40770395, 0.12158461, 0.72083088]) Create 2D NumPy array of random samples: np.random.rand(2,4) array([[0.61244625, 0.32645792, 0.55859886, 0.97613741], [0.57227614, 0.14315638, 0.49034299, 0.00099473]]) Random samples from the standard normal distribution : np.random.randn() 1.4440026351051256 np.random.randn(3) array([ 0.6172098 , -1.67631666, -2.20365265]) np.random.randn(3,1) array([[ 0.29643549], [-0.44039303], [-1.52246126]]) Random integers sampled uniformly from various intervals: np.random.randint(-10,10) 2 np.random.randint(0,2,(4,8)) array([[1, 0, 0, 1, 0, 0, 0, 0], [1, 1, 0, 0, 0, 0, 1, 0], [1, 0, 0, 0, 0, 0, 1, 0], [1, 0, 0, 0, 1, 1, 1, 1]]) np.random.randint(-9,10,(5,2)) array([[ 3, 9], [ 5, -6], [ 7, -7], [ 0, -5], [ 0, 0]]) Examples Brute Force Optimization Find the absolute maximum and minimum values of the function f(x) = x\\sin(x)+\\cos(4x) f(x) = x\\sin(x)+\\cos(4x) on the interval [0,2\\pi] [0,2\\pi] . We know that the maximum and minimum values must occur at either the endpoints x=0,2\\pi x=0,2\\pi or at critical points where f'(x)=0 f'(x)=0 . However, the derivative is given by f'(x) = \\sin(x) + x \\cos(x) - 4\\sin(4x) f'(x) = \\sin(x) + x \\cos(x) - 4\\sin(4x) and the equation f'(x) = 0 f'(x) = 0 is impossible to solve explicitly. Instead, create a 1D NumPy array of x x values from 0 0 to 2\\pi 2\\pi of length N N (for some arbitrarily large value N N ) and use the functions numpy.min and numpy.max to find maximum and minimum y y values, and the functions numpy.argmin and numpy.argmax to find the indices of the corresponding x x values. N = 10000 x = np.linspace(0,2*np.pi,N) y = x * np.sin(x) + np.cos(4*x) y_max = np.max(y) y_min = np.min(y) x_max = x[np.argmax(y)] x_min = x[np.argmin(y)] print('Absolute maximum value is y =',y_max,'at x =',x_max) print('Absolute minimum value is y =',y_min,'at x =',x_min) Absolute maximum value is y = 2.5992726072887007 at x = 1.628136126702901 Absolute minimum value is y = -5.129752039182 at x = 5.34187001663503 Riemann Sums Write a function called exp_int which takes input parameters b b and N N and returns the (left) Riemann sum \\int_0^b e^{-x^2} dx \\approx \\sum_{k=0}^{N-1} e^{-x_k^2} \\Delta x \\int_0^b e^{-x^2} dx \\approx \\sum_{k=0}^{N-1} e^{-x_k^2} \\Delta x for \\Delta x = b/N \\Delta x = b/N and the partition x_k=k \\, \\Delta x x_k=k \\, \\Delta x , k=0,\\dots,N k=0,\\dots,N . def exp_int(b,N): \"Compute left Riemann sum of exp(-x^2) from 0 to b with N subintervals.\" x = np.linspace(0,b,N+1) x_left_endpoints = x[:-1] Delta_x = b/N I = Delta_x * np.sum(np.exp(-x_left_endpoints**2)) return I The infinite integral satisfies the beautiful identity \\int_0^{\\infty} e^{-x^2} dx = \\frac{\\sqrt{\\pi}}{2} \\int_0^{\\infty} e^{-x^2} dx = \\frac{\\sqrt{\\pi}}{2} Compute the integral with large values of b b and N N : exp_int(100,100000) 0.886726925452758 Compare to the true value: np.pi**0.5/2 0.8862269254527579 Infinite Products The cosine function has the following infinite product representation \\cos x = \\prod_{k = 1}^{\\infty} \\left(1 - \\frac{4 x^2}{\\pi^2 (2k - 1)^2} \\right) \\cos x = \\prod_{k = 1}^{\\infty} \\left(1 - \\frac{4 x^2}{\\pi^2 (2k - 1)^2} \\right) Write a function called cos_product which takes input parameters x x and N N and returns the N N th partial product \\prod_{k = 1}^{N} \\left(1 - \\frac{4 x^2}{\\pi^2 (2k - 1)^2} \\right) \\prod_{k = 1}^{N} \\left(1 - \\frac{4 x^2}{\\pi^2 (2k - 1)^2} \\right) def cos_product(x,N): \"Compute the product \\prod_{k=1}^N (1 - 4x^2/(pi^2 (2k - 1)^2).\" k = np.arange(1,N+1) terms = 1 - 4*x**2 / (np.pi**2 * (2*k - 1)**2) return np.prod(terms) Verify our function using values for which we know the result. For example, \\cos(0)=1 \\cos(0)=1 , \\cos(\\pi)=-1 \\cos(\\pi)=-1 and \\cos(\\pi/4) = \\frac{1}{\\sqrt{2}} \\cos(\\pi/4) = \\frac{1}{\\sqrt{2}} . cos_product(0,10) 1.0 cos_product(np.pi,10000) -1.0001000050002433 cos_product(np.pi/4,10000000) 0.7071067856245614 1/2**0.5 0.7071067811865475 Matrix Multiplication Under construction Exercises The natural log satisfies the following definite integral \\int_1^e \\frac{\\ln x \\ dx}{(1 + \\ln x)^2} = \\frac{e}{2} - 1 \\int_1^e \\frac{\\ln x \\ dx}{(1 + \\ln x)^2} = \\frac{e}{2} - 1 Write a function called log_integral which takes input parameters c c and N N and returns the value of the (right) Riemann sum \\int_1^c \\frac{\\ln x \\ dx}{(1 + \\ln x)^2} \\approx \\sum_{k=1}^N \\frac{\\ln x_k \\ \\Delta x}{(1 + \\ln x_k)^2} \\ , \\ \\ \\Delta x = \\frac{c - 1}{N} \\int_1^c \\frac{\\ln x \\ dx}{(1 + \\ln x)^2} \\approx \\sum_{k=1}^N \\frac{\\ln x_k \\ \\Delta x}{(1 + \\ln x_k)^2} \\ , \\ \\ \\Delta x = \\frac{c - 1}{N} for the partition x_k = 1 + k \\Delta x x_k = 1 + k \\Delta x , for k = 0, \\dots , N k = 0, \\dots , N . Write a function called k_sum which takes input parameters k and N and returns the partial sum \\sum_{n=1}^{N} \\frac{1}{n^k} \\sum_{n=1}^{N} \\frac{1}{n^k} Verify your function by comparing to the infinite series identity \\sum_{n=1}^{\\infty} \\frac{(-1)^{n+1}}{n^2} = \\frac{\\pi^2}{12} \\sum_{n=1}^{\\infty} \\frac{(-1)^{n+1}}{n^2} = \\frac{\\pi^2}{12} Write a function called dot which takes 3 inputs M , i and j where M is a square NumPy array and the function returns the dot product of the i i th row and the j j th column of M M .","title":"NumPy"},{"location":"scipy/numpy/#numpy","text":"NumPy is the core Python package for numerical computing. The main features of NumPy are: N N -dimensional array object ndarray Vectorized operations and functions which broadcast across arrays for fast computation To get started with NumPy, let's adopt the standard convention and import it using the name np : import numpy as np","title":"NumPy"},{"location":"scipy/numpy/#numpy-arrays","text":"The fundamental object provided by the NumPy package is the ndarray . We can think of a 1D (1-dimensional) ndarray as a list, a 2D (2-dimensional) ndarray as a matrix, a 3D (3-dimensional) ndarray as a 3-tensor (or a \"cube\" of numbers), and so on. See the NumPy tutorial for more about NumPy arrays.","title":"NumPy Arrays"},{"location":"scipy/numpy/#creating-arrays","text":"The function numpy.array creates a NumPy array from a Python sequence such as a list, a tuple or a list of lists. For example, create a 1D NumPy array from a Python list: a = np.array([1,2,3,4,5]) print(a) [1 2 3 4 5] Notice that when we print a NumPy array it looks a lot like a Python list except that the entries are separated by spaces whereas entries in a Python list are separated by commas: print([1,2,3,4,5]) [1, 2, 3, 4, 5] Notice also that a NumPy array is displayed slightly differently when output by a cell (as opposed to being explicitly printed to output by the print function): a array([1, 2, 3, 4, 5]) Use the built-in function type to verify the type: type(a) numpy.ndarray Create a 2D NumPy array from a Python list of lists: M = np.array([[1,2,3],[4,5,6]]) print(M) [[1 2 3] [4 5 6]] type(M) numpy.ndarray Create an n n -dimensional NumPy array from nested Python lists. For example, the following is a 3D NumPy array: N = np.array([ [[1,2],[3,4]] , [[5,6],[7,8]] , [[9,10],[11,12]] ]) print(N) [[[ 1 2] [ 3 4]] [[ 5 6] [ 7 8]] [[ 9 10] [11 12]]] There are several NumPy functions for creating arrays : Function Description numpy.array(a) Create n n -dimensional NumPy array from sequence a numpy.linspace(a,b,N) Create 1D NumPy array with N equally spaced values from a to b (inclusively) numpy.arange(a,b,step) Create 1D NumPy array with values from a to b (exclusively) incremented by step numpy.zeros(N) Create 1D NumPy array of zeros of length N N numpy.zeros((n,m)) Create 2D NumPy array of zeros with n n rows and m m columns numpy.ones(N) Create 1D NumPy array of ones of length N N numpy.ones((n,m)) Create 2D NumPy array of ones with n n rows and m m columns numpy.eye(N) Create 2D NumPy array with N N rows and N N columns with ones on the diagonal (ie. the identity matrix of size N N ) Create a 1D NumPy array with 11 equally spaced values from 0 to 1: x = np.linspace(0,1,11) print(x) [0. 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ] Create a 1D NumPy array with values from 0 to 20 (exclusively) incremented by 2.5: y = np.arange(0,20,2.5) print(y) [ 0. 2.5 5. 7.5 10. 12.5 15. 17.5] These are the functions that we'll use most often when creating NumPy arrays. The function numpy.linspace works best when we know the number of points we want in the array, and numpy.arange works best when we know step size between values in the array. Create a 1D NumPy array of zeros of length 5: z = np.zeros(5) print(z) [0. 0. 0. 0. 0.] Create a 2D NumPy array of zeros with 2 rows and 5 columns: M = np.zeros((2,5)) print(M) [[0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]] Create a 1D NumPy array of ones of length 7: w = np.ones(7) print(w) [1. 1. 1. 1. 1. 1. 1.] Create a 2D NumPy array of ones with 3 rows and 2 columns: N = np.ones((3,2)) print(N) [[1. 1.] [1. 1.] [1. 1.]] Create the identity matrix of size 10: I = np.eye(10) print(I) [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]","title":"Creating Arrays"},{"location":"scipy/numpy/#array-datatype","text":"NumPy arrays are homogeneous : all entries in the array are the same datatype. We will only work with numeric arrays and our arrays will contain either integers, floats, complex numbers or booleans. There are different kinds of datatypes provided by NumPy for different applications but we'll mostly be working with the default integer type numpy.int64 and the default float type numpy.float64 . These are very similar to the built-in Python datatypes int and float but with some differences that we won't go into. Check out the NumPy documentation on numeric datatypes for more information. The most important point for now is to know how to determine if a NumPy array contains integers elements or float elements. We can access the datatype of a NumPy array by its .dtype attribute. For example, create a 2D NumPy array from a list of lists of integers: A = np.array([[1,2,3],[4,5,6]]) print(A) [[1 2 3] [4 5 6]] We expect the datatype of A to be integers and we verify: A.dtype dtype('int64') Most of the other NumPy functions which create arrays use the numpy.float64 datatype by default. For example, using numpy.linspace : u = np.linspace(0,1,5) print(u) [0. 0.25 0.5 0.75 1. ] u.dtype dtype('float64') Notice that numbers are printed with a decimal point when the datatype of the NumPy array is any kind of float.","title":"Array Datatype"},{"location":"scipy/numpy/#dimension-shape-and-size","text":"We can think of a 1D NumPy array as a list of numbers, a 2D NumPy array as a matrix, a 3D NumPy array as a cube of numbers, and so on. Given a NumPy array, we can find out how many dimensions it has by accessing its .ndim attribute. The result is a number telling us how many dimensions it has. For example, create a 2D NumPy array: A = np.array([[1,2],[3,4],[5,6]]) print(A) [[1 2] [3 4] [5 6]] A.ndim 2 The result tells us that A has 2 dimensions. The first dimension corresponds to the vertical direction counting the rows and the second dimension corresponds to the horizontal direction counting the columns. We can find out how many rows and columns A has by accessing its .shape attribute: A.shape (3, 2) The result is a tuple (3,2) of length 2 which means that A is a 2D array with 3 rows and 2 columns. We can also find out how many entries A has in total by accessing its .size attribute: A.size 6 This is the expected result since we know that A has 3 rows and 2 columns and therefore 2(3) = 6 total entries. Create a 1D NumPy array and inspect its dimension, shape and size: r = np.array([9,3,1,7]) print(r) [9 3 1 7] r.ndim 1 r.shape (4,) r.size 4 The variable r is assigned to a 1D NumPy array of length 4. Notice that r.shape is a tuple with a single entry (4,) .","title":"Dimension, Shape and Size"},{"location":"scipy/numpy/#slicing-and-indexing","text":"Accessing the entries in an array is called indexing and accessing rows and columns (or subarrays) is called slicing . See the NumPy documentation for more information about indexing and slicing . Create a 1D NumPy array: v = np.linspace(0,5,11) print(v) [0. 0.5 1. 1.5 2. 2.5 3. 3.5 4. 4.5 5. ] Access the entries in a 1D array using the square brackets notation just like a Python list. For example, access the entry at index 3: v[3] 1.5 Notice that NumPy array indices start at 0 just like Python sequences. Create a 2D array of integers: B = np.array([[6, 5, 3, 1, 1],[1, 0, 4, 0, 1],[5, 9, 2, 2, 9]]) print(B) [[6 5 3 1 1] [1 0 4 0 1] [5 9 2 2 9]] Access the entries in a 2D array using the square brackets with 2 indices. In particular, access the entry at row index 1 and column index 2: B[1,2] 4 Access the top left entry in the array: B[0,0] 6 Negative indices work for NumPy arrays as they do for Python sequences. Access the bottom right entry in the array: B[-1,-1] 9 Access the row at index 2 using the colon : syntax: B[2,:] array([5, 9, 2, 2, 9]) Access the column at index 3: B[:,3] array([1, 0, 2]) Select the subarray of rows at index 1 and 2, and columns at index 2, 3 and 4: subB = B[1:3,2:5] print(subB) [[4 0 1] [2 2 9]] Slices of NumPy arrays are again NumPy arrays but possibly of a different dimension: subB.ndim 2 subB.shape (2, 3) type(subB) numpy.ndarray The variable subB is assigned to a 2D NumPy array of shape 2 by 2. Let's do the same for the column at index 2: colB = B[:,2] print(colB) [3 4 2] colB.ndim 1 colB.shape (3,) type(colB) numpy.ndarray The variable colB is assigned to a 1D NumPy array of length 3.","title":"Slicing and Indexing"},{"location":"scipy/numpy/#stacking","text":"We can build bigger arrays out of smaller arrays by stacking along different dimensions using the functions numpy.hstack and numpy.vstack . Stack 3 different 1D NumPy arrays of length 3 vertically forming a 3 by 3 matrix: x = np.array([1,1,1]) y = np.array([2,2,2]) z = np.array([3,3,3]) vstacked = np.vstack((x,y,z)) print(vstacked) [[1 1 1] [2 2 2] [3 3 3]] Stack 1D NumPy arrays horizontally to create another 1D array: hstacked = np.hstack((x,y,z)) print(hstacked) [1 1 1 2 2 2 3 3 3] Use numpy.hstack and numpy.vstack to build the matrix T T where T = \\begin{bmatrix} 1 & 1 & 2 & 2 \\\\ 1 & 1 & 2 & 2 \\\\ 3 & 3 & 4 & 4 \\\\ 3 & 3 & 4 & 4 \\end{bmatrix} T = \\begin{bmatrix} 1 & 1 & 2 & 2 \\\\ 1 & 1 & 2 & 2 \\\\ 3 & 3 & 4 & 4 \\\\ 3 & 3 & 4 & 4 \\end{bmatrix} A = np.ones((2,2)) B = 2*np.ones((2,2)) C = 3*np.ones((2,2)) D = 4*np.ones((2,2)) A_B = np.hstack((A,B)) print(A_B) [[1. 1. 2. 2.] [1. 1. 2. 2.]] C_D = np.hstack((C,D)) print(C_D) [[3. 3. 4. 4.] [3. 3. 4. 4.]] T = np.vstack((A_B,C_D)) print(T) [[1. 1. 2. 2.] [1. 1. 2. 2.] [3. 3. 4. 4.] [3. 3. 4. 4.]]","title":"Stacking"},{"location":"scipy/numpy/#copies-versus-views","text":"Under construction","title":"Copies versus Views"},{"location":"scipy/numpy/#operations-and-functions","text":"","title":"Operations and Functions"},{"location":"scipy/numpy/#array-operations","text":"Arithmetic operators including addition + , subtraction - , multiplication * , division / and exponentiation ** are applied to arrays elementwise . For addition and substraction, these are the familiar vector operations we see in linear algebra: v = np.array([1,2,3]) w = np.array([1,0,-1]) v + w array([2, 2, 2]) v - w array([0, 2, 4]) In the same way, array multiplication and division are performed element by element: v * w array([ 1, 0, -3]) w / v array([ 1. , 0. , -0.33333333]) Notice that the datatype of both v and w is numpy.int64 however division w / v returns an array with datatype numpy.float64 . The exponent operator ** also acts element by element in the array: v ** 2 array([1, 4, 9]) Let's see these operations for 2D arrays: A = np.array([[3,1],[2,-1]]) B = np.array([[2,-2],[5,1]]) A + B array([[ 5, -1], [ 7, 0]]) A - B array([[ 1, 3], [-3, -2]]) A / B array([[ 1.5, -0.5], [ 0.4, -1. ]]) A * B array([[ 6, -2], [10, -1]]) A ** 2 array([[9, 1], [4, 1]]) Notice that array multiplication and exponentiation are performed elementwise. In Python 3.5+, the symbol @ computes matrix multiplication for NumPy arrays: A @ B array([[11, -5], [-1, -5]]) Matrix powers are performed by the function numpy.linalg.matrix_power . It's a long function name and so it's convenient to import it with a shorter name: from numpy.linalg import matrix_power as mpow Compute A^3 A^3 : mpow(A,3) array([[37, 9], [18, 1]]) Equivalently, use the @ operator to compute A^3 A^3 : A @ A @ A array([[37, 9], [18, 1]])","title":"Array Operations"},{"location":"scipy/numpy/#broadcasting","text":"We know from linear algebra that we can only add matrices of the same size. Braodcasting is a set of NumPy rules which relaxes this constraint and allows us to combine a smaller array with a bigger when it makes sense. For example, suppose we want to create a 1D NumPy array of y y values for x=0.0,0.25,0.5,0.75,1.0 x=0.0,0.25,0.5,0.75,1.0 for the function y = x^2 + 1 y = x^2 + 1 . From what we've seen so far, it makes sense to create x , then x**2 and then add an array of ones [1. 1. 1. 1. 1.] : x = np.array([0,0.25,0.5,0.75,1.0]) y = x**2 + np.array([1,1,1,1,1]) print(y) [1. 1.0625 1.25 1.5625 2. ] An example of broadcasting in NumPy is the following equivalent operation: x = np.array([0,0.25,0.5,0.75,1.0]) y = x**2 + 1 print(y) [1. 1.0625 1.25 1.5625 2. ] The number 1 is a scalar and we are adding it to a 1D NumPy array of length 5. The broadcasting rule in this case is to broadcast the scalar value 1 across the larger array. The result is a simpler syntax for a very comman operation. Let's try another example. What happens when we try to add a 1D NumPy array of length 4 to a 2D NumPy array of size 3 by 4? u = np.array([1,2,3,4]) print(u) [1 2 3 4] A = np.array([[1,1,1,1],[2,2,2,2],[3,3,3,3]]) print(A) [[1 1 1 1] [2 2 2 2] [3 3 3 3]] result = A + u print(result) [[2 3 4 5] [3 4 5 6] [4 5 6 7]] The 1D NumPy array is broadcast across the 2D array because the length of the first dimension in each array are equal!","title":"Broadcasting"},{"location":"scipy/numpy/#array-functions","text":"There are many array functions we can use to compute with NumPy arrays. The following is a partial list and we'll look closer at mathematical functions in the next section. numpy.sum numpy.prod numpy.mean numpy.max numpy.min numpy.std numpy.argmax numpy.argmin numpy.var Create a 1D NumPy array with random values and compute: arr = np.array([8,-2,4,7,-3]) print(arr) [ 8 -2 4 7 -3] Compute the mean of the values in the array: np.mean(arr) 2.8 Verify the mean once more: m = np.sum(arr) / arr.size print(m) 2.8 Find the index of the maximum element in the array: max_i = np.argmax(arr) print(max_i) 0 Verify the maximum value in the array: np.max(arr) 8 arr[max_i] 8 Array functions apply to 2D arrays as well (and N N -dimensional arrays in general) with the added feature that we can choose to apply array functions to the entire array, down the columns or across the rows (or any axis). Create a 2D NumPy array with random values and compute the sum of all the entries: M = np.array([[2,4,2],[2,1,1],[3,2,0],[0,6,2]]) print(M) [[2 4 2] [2 1 1] [3 2 0] [0 6 2]] np.sum(M) 25 The function numpy.sum also takes a keyword argument axis which determines along which dimension to compute the sum: np.sum(M,axis=0) # Sum of the columns array([ 7, 13, 5]) np.sum(M,axis=1) # Sum of the rows array([8, 4, 5, 8])","title":"Array Functions"},{"location":"scipy/numpy/#mathematical-functions","text":"Mathematical functions in NumPy are called universal functions and are vectorized . Vectorized functions operate elementwise on arrays producing arrays as output and are built to compute values across arrays very quickly. The following is a partial list of mathematical functions: numpy.sin numpy.cos numpy.tan numpy.exp numpy.log numpy.log10 numpy.arcsin numpy.arccos numpy.arctan Compute the values \\sin(2 \\pi x) \\sin(2 \\pi x) for x = 0,0.25,0.5\\dots,1.75 x = 0,0.25,0.5\\dots,1.75 : x = np.arange(0,1.25,0.25) print(x) [0. 0.25 0.5 0.75 1. ] np.sin(2*np.pi*x) array([ 0.0000000e+00, 1.0000000e+00, 1.2246468e-16, -1.0000000e+00, -2.4492936e-16]) We expect the array [0. 1. 0. -1. 0.] however there is (as always with floating point numbers) some rounding errors in the result. In numerical computing, we can interpret a number such as 10^{-16} 10^{-16} as 0 0 . Compute the values \\log_{10}(x) \\log_{10}(x) for x = 1,10,100,1000,10000 x = 1,10,100,1000,10000 : x = np.array([1,10,100,1000,10000]) print(x) [ 1 10 100 1000 10000] np.log10(x) array([0., 1., 2., 3., 4.]) Note that we can also evaluate mathematical functions with scalar values: np.sin(0) 0.0 NumPy also provides familiar mathematical constants such as \\pi \\pi and e e : np.pi 3.141592653589793 np.e 2.718281828459045 For example, verify the limit \\lim_{x \\to \\infty} \\arctan(x) = \\frac{\\pi}{2} \\lim_{x \\to \\infty} \\arctan(x) = \\frac{\\pi}{2} by evaluating \\arctan(x) \\arctan(x) for some (arbitrary) large value x x : np.arctan(10000) 1.5706963267952299 np.pi/2 1.5707963267948966","title":"Mathematical Functions"},{"location":"scipy/numpy/#random-number-generators","text":"The subpackage numpy.random contains functions to generate NumPy arrays of random numbers sampled from different distributions. The following is a partial list of distributions: Function Description numpy.random.rand(d1,...,dn) Create a NumPy array (with shape (d1,...,dn) ) with entries sampled uniformly from [0,1) numpy.random.randn(d1,...,dn) Create a NumPy array (with shape (d1,...,dn) ) with entries sampled from the standard normal distribution numpy.random.randint(a,b,size) Create a NumPy array (with shape size ) with integer entries from low (inclusive) to high (exclusive) Sample a random number from the uniform distribution : np.random.rand() 0.6695906195141056 Sample 3 random numbers: np.random.rand(3) array([0.40770395, 0.12158461, 0.72083088]) Create 2D NumPy array of random samples: np.random.rand(2,4) array([[0.61244625, 0.32645792, 0.55859886, 0.97613741], [0.57227614, 0.14315638, 0.49034299, 0.00099473]]) Random samples from the standard normal distribution : np.random.randn() 1.4440026351051256 np.random.randn(3) array([ 0.6172098 , -1.67631666, -2.20365265]) np.random.randn(3,1) array([[ 0.29643549], [-0.44039303], [-1.52246126]]) Random integers sampled uniformly from various intervals: np.random.randint(-10,10) 2 np.random.randint(0,2,(4,8)) array([[1, 0, 0, 1, 0, 0, 0, 0], [1, 1, 0, 0, 0, 0, 1, 0], [1, 0, 0, 0, 0, 0, 1, 0], [1, 0, 0, 0, 1, 1, 1, 1]]) np.random.randint(-9,10,(5,2)) array([[ 3, 9], [ 5, -6], [ 7, -7], [ 0, -5], [ 0, 0]])","title":"Random Number Generators"},{"location":"scipy/numpy/#examples","text":"","title":"Examples"},{"location":"scipy/numpy/#brute-force-optimization","text":"Find the absolute maximum and minimum values of the function f(x) = x\\sin(x)+\\cos(4x) f(x) = x\\sin(x)+\\cos(4x) on the interval [0,2\\pi] [0,2\\pi] . We know that the maximum and minimum values must occur at either the endpoints x=0,2\\pi x=0,2\\pi or at critical points where f'(x)=0 f'(x)=0 . However, the derivative is given by f'(x) = \\sin(x) + x \\cos(x) - 4\\sin(4x) f'(x) = \\sin(x) + x \\cos(x) - 4\\sin(4x) and the equation f'(x) = 0 f'(x) = 0 is impossible to solve explicitly. Instead, create a 1D NumPy array of x x values from 0 0 to 2\\pi 2\\pi of length N N (for some arbitrarily large value N N ) and use the functions numpy.min and numpy.max to find maximum and minimum y y values, and the functions numpy.argmin and numpy.argmax to find the indices of the corresponding x x values. N = 10000 x = np.linspace(0,2*np.pi,N) y = x * np.sin(x) + np.cos(4*x) y_max = np.max(y) y_min = np.min(y) x_max = x[np.argmax(y)] x_min = x[np.argmin(y)] print('Absolute maximum value is y =',y_max,'at x =',x_max) print('Absolute minimum value is y =',y_min,'at x =',x_min) Absolute maximum value is y = 2.5992726072887007 at x = 1.628136126702901 Absolute minimum value is y = -5.129752039182 at x = 5.34187001663503","title":"Brute Force Optimization"},{"location":"scipy/numpy/#riemann-sums","text":"Write a function called exp_int which takes input parameters b b and N N and returns the (left) Riemann sum \\int_0^b e^{-x^2} dx \\approx \\sum_{k=0}^{N-1} e^{-x_k^2} \\Delta x \\int_0^b e^{-x^2} dx \\approx \\sum_{k=0}^{N-1} e^{-x_k^2} \\Delta x for \\Delta x = b/N \\Delta x = b/N and the partition x_k=k \\, \\Delta x x_k=k \\, \\Delta x , k=0,\\dots,N k=0,\\dots,N . def exp_int(b,N): \"Compute left Riemann sum of exp(-x^2) from 0 to b with N subintervals.\" x = np.linspace(0,b,N+1) x_left_endpoints = x[:-1] Delta_x = b/N I = Delta_x * np.sum(np.exp(-x_left_endpoints**2)) return I The infinite integral satisfies the beautiful identity \\int_0^{\\infty} e^{-x^2} dx = \\frac{\\sqrt{\\pi}}{2} \\int_0^{\\infty} e^{-x^2} dx = \\frac{\\sqrt{\\pi}}{2} Compute the integral with large values of b b and N N : exp_int(100,100000) 0.886726925452758 Compare to the true value: np.pi**0.5/2 0.8862269254527579","title":"Riemann Sums"},{"location":"scipy/numpy/#infinite-products","text":"The cosine function has the following infinite product representation \\cos x = \\prod_{k = 1}^{\\infty} \\left(1 - \\frac{4 x^2}{\\pi^2 (2k - 1)^2} \\right) \\cos x = \\prod_{k = 1}^{\\infty} \\left(1 - \\frac{4 x^2}{\\pi^2 (2k - 1)^2} \\right) Write a function called cos_product which takes input parameters x x and N N and returns the N N th partial product \\prod_{k = 1}^{N} \\left(1 - \\frac{4 x^2}{\\pi^2 (2k - 1)^2} \\right) \\prod_{k = 1}^{N} \\left(1 - \\frac{4 x^2}{\\pi^2 (2k - 1)^2} \\right) def cos_product(x,N): \"Compute the product \\prod_{k=1}^N (1 - 4x^2/(pi^2 (2k - 1)^2).\" k = np.arange(1,N+1) terms = 1 - 4*x**2 / (np.pi**2 * (2*k - 1)**2) return np.prod(terms) Verify our function using values for which we know the result. For example, \\cos(0)=1 \\cos(0)=1 , \\cos(\\pi)=-1 \\cos(\\pi)=-1 and \\cos(\\pi/4) = \\frac{1}{\\sqrt{2}} \\cos(\\pi/4) = \\frac{1}{\\sqrt{2}} . cos_product(0,10) 1.0 cos_product(np.pi,10000) -1.0001000050002433 cos_product(np.pi/4,10000000) 0.7071067856245614 1/2**0.5 0.7071067811865475","title":"Infinite Products"},{"location":"scipy/numpy/#matrix-multiplication","text":"Under construction","title":"Matrix Multiplication"},{"location":"scipy/numpy/#exercises","text":"The natural log satisfies the following definite integral \\int_1^e \\frac{\\ln x \\ dx}{(1 + \\ln x)^2} = \\frac{e}{2} - 1 \\int_1^e \\frac{\\ln x \\ dx}{(1 + \\ln x)^2} = \\frac{e}{2} - 1 Write a function called log_integral which takes input parameters c c and N N and returns the value of the (right) Riemann sum \\int_1^c \\frac{\\ln x \\ dx}{(1 + \\ln x)^2} \\approx \\sum_{k=1}^N \\frac{\\ln x_k \\ \\Delta x}{(1 + \\ln x_k)^2} \\ , \\ \\ \\Delta x = \\frac{c - 1}{N} \\int_1^c \\frac{\\ln x \\ dx}{(1 + \\ln x)^2} \\approx \\sum_{k=1}^N \\frac{\\ln x_k \\ \\Delta x}{(1 + \\ln x_k)^2} \\ , \\ \\ \\Delta x = \\frac{c - 1}{N} for the partition x_k = 1 + k \\Delta x x_k = 1 + k \\Delta x , for k = 0, \\dots , N k = 0, \\dots , N . Write a function called k_sum which takes input parameters k and N and returns the partial sum \\sum_{n=1}^{N} \\frac{1}{n^k} \\sum_{n=1}^{N} \\frac{1}{n^k} Verify your function by comparing to the infinite series identity \\sum_{n=1}^{\\infty} \\frac{(-1)^{n+1}}{n^2} = \\frac{\\pi^2}{12} \\sum_{n=1}^{\\infty} \\frac{(-1)^{n+1}}{n^2} = \\frac{\\pi^2}{12} Write a function called dot which takes 3 inputs M , i and j where M is a square NumPy array and the function returns the dot product of the i i th row and the j j th column of M M .","title":"Exercises"},{"location":"scipy/scipy/","text":"SciPy Under construction","title":"SciPy"},{"location":"scipy/scipy/#scipy","text":"Under construction","title":"SciPy"},{"location":"secondyr_PHYS221/Multiplots/","text":"Molecular Speeds lab Python data analysis - multiple gas dataset processing Take a look at the example code you have been given - or start to workthrough from here. Let's begin by importing all the modules we will need at the top of the code and adding in the variables that we know we will need for the analysis. import numpy as np from matplotlib import pyplot as plt from math import log import math V=2.03*10**-3 A=5.55113*10**-8 ef_begin=0.26 What we are going to do here is run a for loop over all the code we wrote for all files in a specific folder. This will be the folder we are in, so make sure that's where you are and you have all the data from the workshop folder. To start with we need to import the other modules we are going to use. os (or Miscellaneous Operating system interfaces) Lets us look up file paths and folder locations Glob lets us find all files matching a pattern These are file organisation tools. You can look up more about them if you like. import os import glob The first thing we want to do is set the location of our folder which is where the script is stored i.e. CWD or current working directory. folder = os.getcwd() Now we know where the files are stored we need to set the pattern (or type of files) for Glob to look for. fileformat=folder+str('/*.csv') This will make the script only look for csv files in the correct folder. We now want to create an array of the filenames, these are named after the gasses and mass numbers. files = glob.glob(fileformat) Create an array of masses from filenames to use later, as filenames are strings we need to set them as intergers. Note that -ve indicies run from the end. masses = [int(f[-6:-4]) for f in files] It might not be totally clear what this is doing unless we print the output. print(files) ['C:\\\\Users\\\\plankna\\\\Desktop\\\\PythonWorkshop\\\\Intro_documents\\\\Multiple\\\\Argon 38.csv', 'C:\\\\Users\\\\plankna\\\\Desktop\\\\PythonWorkshop\\\\Intro_documents\\\\Multiple\\\\Carbon Dioxide 40.csv', 'C:\\\\Users\\\\plankna\\\\Desktop\\\\PythonWorkshop\\\\Intro_documents\\\\Multiple\\\\Chlorine 71.csv', 'C:\\\\Users\\\\plankna\\\\Desktop\\\\PythonWorkshop\\\\Intro_documents\\\\Multiple\\\\Fluorine 38.csv', 'C:\\\\Users\\\\plankna\\\\Desktop\\\\PythonWorkshop\\\\Intro_documents\\\\Multiple\\\\Krypton 84.csv', 'C:\\\\Users\\\\plankna\\\\Desktop\\\\PythonWorkshop\\\\Intro_documents\\\\Multiple\\\\Methane 16.csv', 'C:\\\\Users\\\\plankna\\\\Desktop\\\\PythonWorkshop\\\\Intro_documents\\\\Multiple\\\\Neon 17.csv', 'C:\\\\Users\\\\plankna\\\\Desktop\\\\PythonWorkshop\\\\Intro_documents\\\\Multiple\\\\Nitrogen 28.csv', 'C:\\\\Users\\\\plankna\\\\Desktop\\\\PythonWorkshop\\\\Intro_documents\\\\Multiple\\\\Oxygen 32.csv', 'C:\\\\Users\\\\plankna\\\\Desktop\\\\PythonWorkshop\\\\Intro_documents\\\\Multiple\\\\Sulphur Dioxide 64.csv'] argh!!! depending on your filing system this might look horrible... print(masses) [38, 40, 71, 38, 84, 16, 17, 28, 32, 64] but hopefully this helps to see what has gone on. We have taken the string from the file name and turned them into an integer. To do this we counted back from the end of the file name... We now need to find out how many files we have in the folder. We know how to do that already. n=len(files) We also need to create an empty array to populate later. v=np.zeros(n) We now want to simply run though the previous code (in the single gas experiment) for all of the files in the folder. for j in range(n): #we need to indent all this code and change the argument in genfromtext #to files[j] rawdata=np.genfromtxt(files[j], delimiter=',') time=rawdata[:,0] pressure=rawdata[:,1] baseP=min(rawdata[:,1]) P_minus_baseP=[i-0.99*baseP for i in pressure] res=[abs(i-ef_begin) for i in P_minus_baseP] minres=min(res) for i in range (len(res)): if res[i]==minres: Peff_index=i break LogP=[log(i) for i in P_minus_baseP] fit=np.polyfit(time[Peff_index:1400],LogP[Peff_index:1400],1) m=fit[0] c=fit[1] note, we no longer have cats... ;-) compare this to your previous code. It is the same, just compressed. Now I am adding on to this and plotting the data. for j in range(n): #we need to indent all this code and change the argument in genfromtext #to files[j] rawdata=np.genfromtxt(files[j], delimiter=',') time=rawdata[:,0] pressure=rawdata[:,1] baseP=min(rawdata[:,1]) P_minus_baseP=[i-0.99*baseP for i in pressure] res=[abs(i-ef_begin) for i in P_minus_baseP] minres=min(res) for i in range (len(res)): if res[i]==minres: Peff_index=i break LogP=[log(i) for i in P_minus_baseP] fit=np.polyfit(time[Peff_index:1400],LogP[Peff_index:1400],1) m=fit[0] c=fit[1] #now we put each of these in one of the spots in the vector v v[j]=-4*V*m/A #now lets print v ######################print(v) #we can then plot v as a function of mass number plt.scatter(masses,v) #we can now create a theoritical line to match these to #first we need a range of mass numbers <matplotlib.collections.PathCollection at 0x2501a8d68d0> #now we simply complete the theoritical calculation vtheory=[math.sqrt(8/math.pi*1.38*(10**-23)*300/i/(1.67*10**-27)) for i in range(10,90)] #and plot the result on our plot plt.plot(range(10,90),vtheory,'k--') #we can add some labels plt.xlabel('Mass Number') plt.ylabel('Velocity') Text(0, 0.5, 'Velocity') Putting these last two parts together we find (this will be what comes up in Spyder. for j in range(n): #we need to indent all this code and change the argument in genfromtext #to files[j] rawdata=np.genfromtxt(files[j], delimiter=',') time=rawdata[:,0] pressure=rawdata[:,1] baseP=min(rawdata[:,1]) P_minus_baseP=[i-0.99*baseP for i in pressure] res=[abs(i-ef_begin) for i in P_minus_baseP] minres=min(res) for i in range (len(res)): if res[i]==minres: Peff_index=i break LogP=[log(i) for i in P_minus_baseP] fit=np.polyfit(time[Peff_index:1400],LogP[Peff_index:1400],1) m=fit[0] c=fit[1] #now we put each of these in one of the spots in the vector v v[j]=-4*V*m/A #now lets print v ######################print(v) #we can then plot v as a function of mass number plt.scatter(masses,v) #we can now create a theoritical line to match these to #first we need a range of mass numbers #now we simply complete the theoritical calculation vtheory=[math.sqrt(8/math.pi*1.38*(10**-23)*300/i/(1.67*10**-27)) for i in range(10,90)] #and plot the result on our plot plt.plot(range(10,90),vtheory,'k--') #we can add some labels plt.xlabel('Mass Number') plt.ylabel('Velocity') Text(0, 0.5, 'Velocity')","title":"Molecular Speeds lab Python data analysis - multiple gas dataset processing"},{"location":"secondyr_PHYS221/Multiplots/#molecular-speeds-lab-python-data-analysis-multiple-gas-dataset-processing","text":"Take a look at the example code you have been given - or start to workthrough from here. Let's begin by importing all the modules we will need at the top of the code and adding in the variables that we know we will need for the analysis. import numpy as np from matplotlib import pyplot as plt from math import log import math V=2.03*10**-3 A=5.55113*10**-8 ef_begin=0.26 What we are going to do here is run a for loop over all the code we wrote for all files in a specific folder. This will be the folder we are in, so make sure that's where you are and you have all the data from the workshop folder. To start with we need to import the other modules we are going to use. os (or Miscellaneous Operating system interfaces) Lets us look up file paths and folder locations Glob lets us find all files matching a pattern These are file organisation tools. You can look up more about them if you like. import os import glob The first thing we want to do is set the location of our folder which is where the script is stored i.e. CWD or current working directory. folder = os.getcwd() Now we know where the files are stored we need to set the pattern (or type of files) for Glob to look for. fileformat=folder+str('/*.csv') This will make the script only look for csv files in the correct folder. We now want to create an array of the filenames, these are named after the gasses and mass numbers. files = glob.glob(fileformat) Create an array of masses from filenames to use later, as filenames are strings we need to set them as intergers. Note that -ve indicies run from the end. masses = [int(f[-6:-4]) for f in files] It might not be totally clear what this is doing unless we print the output. print(files) ['C:\\\\Users\\\\plankna\\\\Desktop\\\\PythonWorkshop\\\\Intro_documents\\\\Multiple\\\\Argon 38.csv', 'C:\\\\Users\\\\plankna\\\\Desktop\\\\PythonWorkshop\\\\Intro_documents\\\\Multiple\\\\Carbon Dioxide 40.csv', 'C:\\\\Users\\\\plankna\\\\Desktop\\\\PythonWorkshop\\\\Intro_documents\\\\Multiple\\\\Chlorine 71.csv', 'C:\\\\Users\\\\plankna\\\\Desktop\\\\PythonWorkshop\\\\Intro_documents\\\\Multiple\\\\Fluorine 38.csv', 'C:\\\\Users\\\\plankna\\\\Desktop\\\\PythonWorkshop\\\\Intro_documents\\\\Multiple\\\\Krypton 84.csv', 'C:\\\\Users\\\\plankna\\\\Desktop\\\\PythonWorkshop\\\\Intro_documents\\\\Multiple\\\\Methane 16.csv', 'C:\\\\Users\\\\plankna\\\\Desktop\\\\PythonWorkshop\\\\Intro_documents\\\\Multiple\\\\Neon 17.csv', 'C:\\\\Users\\\\plankna\\\\Desktop\\\\PythonWorkshop\\\\Intro_documents\\\\Multiple\\\\Nitrogen 28.csv', 'C:\\\\Users\\\\plankna\\\\Desktop\\\\PythonWorkshop\\\\Intro_documents\\\\Multiple\\\\Oxygen 32.csv', 'C:\\\\Users\\\\plankna\\\\Desktop\\\\PythonWorkshop\\\\Intro_documents\\\\Multiple\\\\Sulphur Dioxide 64.csv'] argh!!! depending on your filing system this might look horrible... print(masses) [38, 40, 71, 38, 84, 16, 17, 28, 32, 64] but hopefully this helps to see what has gone on. We have taken the string from the file name and turned them into an integer. To do this we counted back from the end of the file name... We now need to find out how many files we have in the folder. We know how to do that already. n=len(files) We also need to create an empty array to populate later. v=np.zeros(n) We now want to simply run though the previous code (in the single gas experiment) for all of the files in the folder. for j in range(n): #we need to indent all this code and change the argument in genfromtext #to files[j] rawdata=np.genfromtxt(files[j], delimiter=',') time=rawdata[:,0] pressure=rawdata[:,1] baseP=min(rawdata[:,1]) P_minus_baseP=[i-0.99*baseP for i in pressure] res=[abs(i-ef_begin) for i in P_minus_baseP] minres=min(res) for i in range (len(res)): if res[i]==minres: Peff_index=i break LogP=[log(i) for i in P_minus_baseP] fit=np.polyfit(time[Peff_index:1400],LogP[Peff_index:1400],1) m=fit[0] c=fit[1] note, we no longer have cats... ;-) compare this to your previous code. It is the same, just compressed. Now I am adding on to this and plotting the data. for j in range(n): #we need to indent all this code and change the argument in genfromtext #to files[j] rawdata=np.genfromtxt(files[j], delimiter=',') time=rawdata[:,0] pressure=rawdata[:,1] baseP=min(rawdata[:,1]) P_minus_baseP=[i-0.99*baseP for i in pressure] res=[abs(i-ef_begin) for i in P_minus_baseP] minres=min(res) for i in range (len(res)): if res[i]==minres: Peff_index=i break LogP=[log(i) for i in P_minus_baseP] fit=np.polyfit(time[Peff_index:1400],LogP[Peff_index:1400],1) m=fit[0] c=fit[1] #now we put each of these in one of the spots in the vector v v[j]=-4*V*m/A #now lets print v ######################print(v) #we can then plot v as a function of mass number plt.scatter(masses,v) #we can now create a theoritical line to match these to #first we need a range of mass numbers <matplotlib.collections.PathCollection at 0x2501a8d68d0> #now we simply complete the theoritical calculation vtheory=[math.sqrt(8/math.pi*1.38*(10**-23)*300/i/(1.67*10**-27)) for i in range(10,90)] #and plot the result on our plot plt.plot(range(10,90),vtheory,'k--') #we can add some labels plt.xlabel('Mass Number') plt.ylabel('Velocity') Text(0, 0.5, 'Velocity') Putting these last two parts together we find (this will be what comes up in Spyder. for j in range(n): #we need to indent all this code and change the argument in genfromtext #to files[j] rawdata=np.genfromtxt(files[j], delimiter=',') time=rawdata[:,0] pressure=rawdata[:,1] baseP=min(rawdata[:,1]) P_minus_baseP=[i-0.99*baseP for i in pressure] res=[abs(i-ef_begin) for i in P_minus_baseP] minres=min(res) for i in range (len(res)): if res[i]==minres: Peff_index=i break LogP=[log(i) for i in P_minus_baseP] fit=np.polyfit(time[Peff_index:1400],LogP[Peff_index:1400],1) m=fit[0] c=fit[1] #now we put each of these in one of the spots in the vector v v[j]=-4*V*m/A #now lets print v ######################print(v) #we can then plot v as a function of mass number plt.scatter(masses,v) #we can now create a theoritical line to match these to #first we need a range of mass numbers #now we simply complete the theoritical calculation vtheory=[math.sqrt(8/math.pi*1.38*(10**-23)*300/i/(1.67*10**-27)) for i in range(10,90)] #and plot the result on our plot plt.plot(range(10,90),vtheory,'k--') #we can add some labels plt.xlabel('Mass Number') plt.ylabel('Velocity') Text(0, 0.5, 'Velocity')","title":"Molecular Speeds lab Python data analysis - multiple gas dataset processing"},{"location":"secondyr_PHYS221/Single_exp/","text":"Molecular Speeds lab Python data analysis - single gas dataset processing Start a new Code in the folder that contains the file \u2018Nitrogen 28_2.csv\u2019 I have given you an example of the full code in the workshop folder. Remember that we can 'comment out' code by using a # so the program won't try to run it. As you read through you'll see lots of print commands commented out, these were included to check the code was working. The first thing we want to do is define some constants that we will use later on. These will be the Volume of the bulb, the area of the opening and the pressure at which the effusion regime begins. You were asked to calculate some of these in the pre-workshop exercise as I reminder of the PHYS223 lab. So let\u2019s write the first piece of the code and set up same values to use later on (note capital V we are using here). V=2.03*10**-3 A=5.55113*10**-8 ef_begin=0.26 Let\u2019s check that worked by printing one of the variables print(V) 0.0020299999999999997 To start of with we need to call up the packages that help us handle our data. packages are bunches of functions that can be imported all at the same time for later use. The package we want is called \u2018numpy\u2019 so let\u2019s import that now. import numpy as np Now we want to import a module to help with plotting. Some of this may be in a slightly different order to the example .py code. Does that matter? from matplotlib import pyplot as plt We also want to load up the data that we have in our CSVs. If you remember back to the experiment the data is pressure as a function of time. Now we want to use numpy to import our data, the command we are going to use is called \u2018genfromtext\u2019. We will import the data into a variable, called rawdata: rawdata=np.genfromtxt(\"Nitrogen 28_2.csv\", delimiter=\"cat\") Hold on... What's this cat? note that the delimiter argument tells Python how the data is separated, just to prove a point I\u2019ve replaced all the commas, which are normally used to separate data, with the word \u2018cat\u2019. This seems silly, does it really help me learn? Hopefully. And think back to this when you move onto the multiple data example next. Now let\u2019s print the variable \u2018rawdata\u2019 print(rawdata) [[0.00000000e+00 3.91587981e+00] [1.00000000e+00 3.90860622e+00] [2.00000000e+00 3.89163795e+00] ... [2.28100000e+03 6.10025760e-02] [2.28200000e+03 6.10025760e-02] [2.28300000e+03 6.24196670e-02]] This looks good and along the lines of what you expect. It really makes sense to throw in a few tests here and there to make sure that the code is doing what you expect. Now we want to split this array up into two vectors, one for time and one for pressure, we can do that using the indexing we learned before. time=rawdata[:,0] pressure=rawdata[:,1] This \" : \" means [ first_row:last_row , column_0 ]. If you have a 2-dimensional list/matrix/array, this notation will give you all the values in column 0 (from all rows). We should probably test what's happening here, just to be sure... print(time) print(pressure) [0.000e+00 1.000e+00 2.000e+00 ... 2.281e+03 2.282e+03 2.283e+03] [3.91587981 3.90860622 3.89163795 ... 0.06100258 0.06100258 0.06241967] It's quite tricky to see what's really going on here, so let's plot it out to get a better idea. plt.figure(1) plt.plot(time,pressure) plt.xlabel(\"time (s)\") plt.ylabel(\"Pressure (Pa)\") Text(0, 0.5, 'Pressure (Pa)') Note that I am planning on having multiple figures so I have given this one a number. This should help as we move along.I even remembered to label my axes and to put in units. If you remember back to the experiment and what we actually have to do to from the basis of our analysis here, we need to find the minimum pressure we reached. To do this we will use an inbuilt python function \u2018min\u2019 and set the result as a new variable \u2018baseP\u2019. baseP=min(rawdata[:,1]) print(baseP) 0.061002576 Have a bit of a think about what that function is doing. It is going from the first data point and last data point in our pressure column (here 1) and finding the minimum. If you want to know more you can easily google this function and see how it operates. We are now going to use a list comprehension to subtract the base pressure from each value in \u2018Pressure\u2019 as we will need to take the log of this later (everyone remembers the experiment and you all definitely read ahead to see where this is going...). We therefore want to avoid 0 values, and as baseP is in \u2018Pressure\u2019 it will return a zero, so we can just multiply it by 0.99 to avoid this. P_minus_baseP=[i-0.99*baseP for i in pressure] print(P_minus_baseP) - do this at your peril. It gives a big list... Now we have our pressure minus base pressure we need to find the point at which the effusion regime begins, to do this we are going to make a new vector of residuals. We already know the pressure at which the effusion regime begins, we called it \u2018ef_begin\u2019, what we don't know is the INDEX of this value in the pressure vector. We are going to find this using residuals. This vector \u2018Res\u2019 will be a vector where we take the value we are looking for \u2018ef_begin\u2019 from all values of the pressure vector the smallest value of this vector will have an index equal to that of when the effusion regime begins, in the vector \u2018Pressure\u2019. res=[abs(i-ef_begin) for i in P_minus_baseP] You should recognice the look comprehension in the line above. We've made a new array as described above. We now need to take the minimum value. minres=min(res) print(minres) 0.00043142575999999266 I get 0.00043142575999999266, you should get something similar\u2026. Or the same. We now need to find the index of the minimum value, for this we will use a for loop, we want the loop to run for as many entries as we have in res so we can make it run for \u2018len(res)\u2019 we then want to use an if statement, so when \u2018res[i]=minres\u2019 we assign that \u2018I\u2019 to a variable, then stop. Just take a moment and think that through. Can you write it yourself? for i in range (len(res)): if res[i]==minres: Peff_index=i break print(Peff_index) 691 Now we have the value of the index where the effusion regime begins we can move on. The next step is to take the log of our data, to do this we need to import another module called \u2018math\u2019. Maybe we could have added that to the top with numpy and matplotlib, but here we are. from math import log import math We are going to use another list comprehension to create a new vector with all the logged values LogP=[log(i) for i in P_minus_baseP] print(LogP) - if you want to check things. I find it better to plot. Especially as you have your own data that you can double check against. plt.figure(2) plt.plot(time,LogP) plt.xlabel(\"time (s)\") plt.ylabel(\"log Pressure (Pa)\") Text(0, 0.5, 'log Pressure (Pa)') We can also plot only the data after we reach the effusion regime, on the same figure, the \u2018r\u2019 makes it red. plt.plot(time[Peff_index:],LogP[Peff_index:],\"r\") [<matplotlib.lines.Line2D at 0x7fca48843e10>] Actually, in spyder that just plots ontop.. plt.figure(2) plt.plot(time,LogP) plt.xlabel(\"time (s)\") plt.ylabel(\"log Pressure (Pa)\") plt.plot(time[Peff_index:],LogP[Peff_index:],\"r\") [<matplotlib.lines.Line2D at 0x7fca88a9e790>] Here in the Jupyter environment I had to put them together in one code section. So if anyone is using Jupyter you will have to do what I just did here. Now I want to fit a trend line to the section of the data in the effusion regime. To do this I'll use a fitting tool and create a new variable. fit=np.polyfit(time[Peff_index:1400],LogP[Peff_index:1400],1) It is worth having a bit of a think about what this polyfit is doing. It is a numpy function. polyfit(x,y, degree of polynomial). What is 1400 representing? Why is that the cut-off? Maybe take a look at your own lab report. But the plot here is helpful too I think. Now is probably a good time for another print... print(fit[0]) print(fit[1]) -0.0032100701686121782 0.8597164594476661 We were fitting a straight line! The fit function returns two values, one is the gradient and one is the intercept, we can make these into their own variable. m=fit[0] c=fit[1] Now we can plot this. plt.plot(time[Peff_index:1400],time[Peff_index:1400]*m+c, \"k--\") [<matplotlib.lines.Line2D at 0x7fca68e3b250>] For me, I need to plot it ontop of the existing plots again. plt.figure(2) plt.plot(time,LogP) plt.xlabel(\"time (s)\") plt.ylabel(\"log Pressure (Pa)\") plt.plot(time[Peff_index:],LogP[Peff_index:],\"r\") plt.plot(time[Peff_index:1400],time[Peff_index:1400]*m+c, \"k--\") [<matplotlib.lines.Line2D at 0x7fca48899f90>] Hopefully you can see it all, and the small black dashes. You can look up the plot instructions to see what k means. We now can calculate the velocity of the nitrogen from the fit. Which remember, is the reason we\u2019ve done all this work... and let's print it. v=-4*V*m/A print(v) 469.5579056720142 Do you get the same? Does it agree with your lab report?","title":"Molecular Speeds lab Python data analysis - single gas dataset processing"},{"location":"secondyr_PHYS221/Single_exp/#molecular-speeds-lab-python-data-analysis-single-gas-dataset-processing","text":"Start a new Code in the folder that contains the file \u2018Nitrogen 28_2.csv\u2019 I have given you an example of the full code in the workshop folder. Remember that we can 'comment out' code by using a # so the program won't try to run it. As you read through you'll see lots of print commands commented out, these were included to check the code was working. The first thing we want to do is define some constants that we will use later on. These will be the Volume of the bulb, the area of the opening and the pressure at which the effusion regime begins. You were asked to calculate some of these in the pre-workshop exercise as I reminder of the PHYS223 lab. So let\u2019s write the first piece of the code and set up same values to use later on (note capital V we are using here). V=2.03*10**-3 A=5.55113*10**-8 ef_begin=0.26 Let\u2019s check that worked by printing one of the variables print(V) 0.0020299999999999997 To start of with we need to call up the packages that help us handle our data. packages are bunches of functions that can be imported all at the same time for later use. The package we want is called \u2018numpy\u2019 so let\u2019s import that now. import numpy as np Now we want to import a module to help with plotting. Some of this may be in a slightly different order to the example .py code. Does that matter? from matplotlib import pyplot as plt We also want to load up the data that we have in our CSVs. If you remember back to the experiment the data is pressure as a function of time. Now we want to use numpy to import our data, the command we are going to use is called \u2018genfromtext\u2019. We will import the data into a variable, called rawdata: rawdata=np.genfromtxt(\"Nitrogen 28_2.csv\", delimiter=\"cat\") Hold on... What's this cat? note that the delimiter argument tells Python how the data is separated, just to prove a point I\u2019ve replaced all the commas, which are normally used to separate data, with the word \u2018cat\u2019. This seems silly, does it really help me learn? Hopefully. And think back to this when you move onto the multiple data example next. Now let\u2019s print the variable \u2018rawdata\u2019 print(rawdata) [[0.00000000e+00 3.91587981e+00] [1.00000000e+00 3.90860622e+00] [2.00000000e+00 3.89163795e+00] ... [2.28100000e+03 6.10025760e-02] [2.28200000e+03 6.10025760e-02] [2.28300000e+03 6.24196670e-02]] This looks good and along the lines of what you expect. It really makes sense to throw in a few tests here and there to make sure that the code is doing what you expect. Now we want to split this array up into two vectors, one for time and one for pressure, we can do that using the indexing we learned before. time=rawdata[:,0] pressure=rawdata[:,1] This \" : \" means [ first_row:last_row , column_0 ]. If you have a 2-dimensional list/matrix/array, this notation will give you all the values in column 0 (from all rows). We should probably test what's happening here, just to be sure... print(time) print(pressure) [0.000e+00 1.000e+00 2.000e+00 ... 2.281e+03 2.282e+03 2.283e+03] [3.91587981 3.90860622 3.89163795 ... 0.06100258 0.06100258 0.06241967] It's quite tricky to see what's really going on here, so let's plot it out to get a better idea. plt.figure(1) plt.plot(time,pressure) plt.xlabel(\"time (s)\") plt.ylabel(\"Pressure (Pa)\") Text(0, 0.5, 'Pressure (Pa)') Note that I am planning on having multiple figures so I have given this one a number. This should help as we move along.I even remembered to label my axes and to put in units. If you remember back to the experiment and what we actually have to do to from the basis of our analysis here, we need to find the minimum pressure we reached. To do this we will use an inbuilt python function \u2018min\u2019 and set the result as a new variable \u2018baseP\u2019. baseP=min(rawdata[:,1]) print(baseP) 0.061002576 Have a bit of a think about what that function is doing. It is going from the first data point and last data point in our pressure column (here 1) and finding the minimum. If you want to know more you can easily google this function and see how it operates. We are now going to use a list comprehension to subtract the base pressure from each value in \u2018Pressure\u2019 as we will need to take the log of this later (everyone remembers the experiment and you all definitely read ahead to see where this is going...). We therefore want to avoid 0 values, and as baseP is in \u2018Pressure\u2019 it will return a zero, so we can just multiply it by 0.99 to avoid this. P_minus_baseP=[i-0.99*baseP for i in pressure] print(P_minus_baseP) - do this at your peril. It gives a big list... Now we have our pressure minus base pressure we need to find the point at which the effusion regime begins, to do this we are going to make a new vector of residuals. We already know the pressure at which the effusion regime begins, we called it \u2018ef_begin\u2019, what we don't know is the INDEX of this value in the pressure vector. We are going to find this using residuals. This vector \u2018Res\u2019 will be a vector where we take the value we are looking for \u2018ef_begin\u2019 from all values of the pressure vector the smallest value of this vector will have an index equal to that of when the effusion regime begins, in the vector \u2018Pressure\u2019. res=[abs(i-ef_begin) for i in P_minus_baseP] You should recognice the look comprehension in the line above. We've made a new array as described above. We now need to take the minimum value. minres=min(res) print(minres) 0.00043142575999999266 I get 0.00043142575999999266, you should get something similar\u2026. Or the same. We now need to find the index of the minimum value, for this we will use a for loop, we want the loop to run for as many entries as we have in res so we can make it run for \u2018len(res)\u2019 we then want to use an if statement, so when \u2018res[i]=minres\u2019 we assign that \u2018I\u2019 to a variable, then stop. Just take a moment and think that through. Can you write it yourself? for i in range (len(res)): if res[i]==minres: Peff_index=i break print(Peff_index) 691 Now we have the value of the index where the effusion regime begins we can move on. The next step is to take the log of our data, to do this we need to import another module called \u2018math\u2019. Maybe we could have added that to the top with numpy and matplotlib, but here we are. from math import log import math We are going to use another list comprehension to create a new vector with all the logged values LogP=[log(i) for i in P_minus_baseP] print(LogP) - if you want to check things. I find it better to plot. Especially as you have your own data that you can double check against. plt.figure(2) plt.plot(time,LogP) plt.xlabel(\"time (s)\") plt.ylabel(\"log Pressure (Pa)\") Text(0, 0.5, 'log Pressure (Pa)') We can also plot only the data after we reach the effusion regime, on the same figure, the \u2018r\u2019 makes it red. plt.plot(time[Peff_index:],LogP[Peff_index:],\"r\") [<matplotlib.lines.Line2D at 0x7fca48843e10>] Actually, in spyder that just plots ontop.. plt.figure(2) plt.plot(time,LogP) plt.xlabel(\"time (s)\") plt.ylabel(\"log Pressure (Pa)\") plt.plot(time[Peff_index:],LogP[Peff_index:],\"r\") [<matplotlib.lines.Line2D at 0x7fca88a9e790>] Here in the Jupyter environment I had to put them together in one code section. So if anyone is using Jupyter you will have to do what I just did here. Now I want to fit a trend line to the section of the data in the effusion regime. To do this I'll use a fitting tool and create a new variable. fit=np.polyfit(time[Peff_index:1400],LogP[Peff_index:1400],1) It is worth having a bit of a think about what this polyfit is doing. It is a numpy function. polyfit(x,y, degree of polynomial). What is 1400 representing? Why is that the cut-off? Maybe take a look at your own lab report. But the plot here is helpful too I think. Now is probably a good time for another print... print(fit[0]) print(fit[1]) -0.0032100701686121782 0.8597164594476661 We were fitting a straight line! The fit function returns two values, one is the gradient and one is the intercept, we can make these into their own variable. m=fit[0] c=fit[1] Now we can plot this. plt.plot(time[Peff_index:1400],time[Peff_index:1400]*m+c, \"k--\") [<matplotlib.lines.Line2D at 0x7fca68e3b250>] For me, I need to plot it ontop of the existing plots again. plt.figure(2) plt.plot(time,LogP) plt.xlabel(\"time (s)\") plt.ylabel(\"log Pressure (Pa)\") plt.plot(time[Peff_index:],LogP[Peff_index:],\"r\") plt.plot(time[Peff_index:1400],time[Peff_index:1400]*m+c, \"k--\") [<matplotlib.lines.Line2D at 0x7fca48899f90>] Hopefully you can see it all, and the small black dashes. You can look up the plot instructions to see what k means. We now can calculate the velocity of the nitrogen from the fit. Which remember, is the reason we\u2019ve done all this work... and let's print it. v=-4*V*m/A print(v) 469.5579056720142 Do you get the same? Does it agree with your lab report?","title":"Molecular Speeds lab Python data analysis - single gas dataset processing"}]}